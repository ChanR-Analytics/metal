{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging the `LabelModel` with deps + higher-order cliques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lfs/1/annhe/anaconda3/envs/metal/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append(\"../\") # go to parent dir\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import mpmath\n",
    "\n",
    "from synthetic.generate import SingleTaskTreeDepsGenerator\n",
    "from metal.label_model import LabelModel, CliqueTree\n",
    "from metal.label_model.utils import (\n",
    "    compute_mu,\n",
    "    compute_covariance,\n",
    "    compute_inv_covariance,\n",
    "    print_matrix,\n",
    "    visualize_matrix\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1)   [0.49239541]\n",
      "(1, 1)   [0.12333361]\n",
      "(2, 1)   [0.59469623]\n",
      "(3, 1)   [0.49179015]\n",
      "(4, 1)   [0.47833102]\n",
      "(5, 1)   [0.39730134]\n",
      "(6, 1)   [0.28418377]\n",
      "(7, 1)   [0.65734387]\n",
      "(8, 1)   [0.36968921]\n",
      "(9, 1)   [0.34014455]\n",
      "((0, 1), 1, 1)   [0.65902045]\n",
      "((1, 2), 1, 1)   [0.57622788]\n",
      "((2, 3), 1, 1)   [0.22112195]\n",
      "((3, 4), 1, 1)   [0.56222031]\n",
      "((4, 5), 1, 1)   [0.26599588]\n",
      "((5, 6), 1, 1)   [0.80680163]\n",
      "((6, 7), 1, 1)   [0.86857776]\n",
      "((7, 8), 1, 1)   [0.54481315]\n",
      "((8, 9), 1, 1)   [0.86190534]\n",
      "Labeler =  0\n",
      "P(L= 0 , Y= 1 ) =  0.277484719543213\n",
      "P(L= 1 , Y= 1 ) =  0.722515280456787\n",
      "Labeler =  1\n",
      "P(L= 0 , Y= 1 ) =  0.2678250016430602\n",
      "P(L= 1 , Y= 1 ) =  0.7321749983569398\n",
      "Labeler =  2\n",
      "P(L= 0 , Y= 1 ) =  0.23832420112429975\n",
      "P(L= 1 , Y= 1 ) =  0.7616757988757002\n",
      "Labeler =  3\n",
      "P(L= 0 , Y= 1 ) =  0.2564948790056145\n",
      "P(L= 1 , Y= 1 ) =  0.7435051209943855\n",
      "Labeler =  4\n",
      "P(L= 0 , Y= 1 ) =  0.2525536111911135\n",
      "P(L= 1 , Y= 1 ) =  0.7474463888088865\n",
      "Labeler =  5\n",
      "P(L= 0 , Y= 1 ) =  0.22492920043060005\n",
      "P(L= 1 , Y= 1 ) =  0.7750707995694001\n",
      "Labeler =  6\n",
      "P(L= 0 , Y= 1 ) =  0.1707157825440195\n",
      "P(L= 1 , Y= 1 ) =  0.8292842174559806\n",
      "Labeler =  7\n",
      "P(L= 0 , Y= 1 ) =  0.14691450756718816\n",
      "P(L= 1 , Y= 1 ) =  0.8530854924328118\n",
      "Labeler =  8\n",
      "P(L= 0 , Y= 1 ) =  0.19616992622570348\n",
      "P(L= 1 , Y= 1 ) =  0.8038300737742966\n",
      "Labeler =  9\n",
      "P(L= 0 , Y= 1 ) =  0.2673362011402971\n",
      "P(L= 1 , Y= 1 ) =  0.7326637988597031\n",
      "Labelers =  (0, 1)\n",
      "P(L_ 0 = 0 , L_ 1 = 0  | Y =  1 ) =  0.10159390585461901\n",
      "P(L_ 0 = 0 , L_ 1 = 1  | Y =  1 ) =  0.175890813688594\n",
      "P(L_ 0 = 1 , L_ 1 = 0  | Y =  1 ) =  0.16623109578844117\n",
      "P(L_ 0 = 1 , L_ 1 = 1  | Y =  1 ) =  0.5562841846683458\n",
      "Labelers =  (0, 2)\n",
      "P(L_ 0 = 0 , L_ 2 = 0  | Y =  1 ) =  0.06915053377232444\n",
      "P(L_ 0 = 0 , L_ 2 = 1  | Y =  1 ) =  0.20833418577088858\n",
      "P(L_ 0 = 1 , L_ 2 = 0  | Y =  1 ) =  0.16917366735197528\n",
      "P(L_ 0 = 1 , L_ 2 = 1  | Y =  1 ) =  0.5533416131048117\n",
      "Labelers =  (0, 3)\n",
      "P(L_ 0 = 0 , L_ 3 = 0  | Y =  1 ) =  0.07130410490039792\n",
      "P(L_ 0 = 0 , L_ 3 = 1  | Y =  1 ) =  0.20618061464281515\n",
      "P(L_ 0 = 1 , L_ 3 = 0  | Y =  1 ) =  0.18519077410521662\n",
      "P(L_ 0 = 1 , L_ 3 = 1  | Y =  1 ) =  0.5373245063515705\n",
      "Labelers =  (0, 4)\n",
      "P(L_ 0 = 0 , L_ 4 = 0  | Y =  1 ) =  0.07009442388584827\n",
      "P(L_ 0 = 0 , L_ 4 = 1  | Y =  1 ) =  0.2073902956573648\n",
      "P(L_ 0 = 1 , L_ 4 = 0  | Y =  1 ) =  0.1824591873052653\n",
      "P(L_ 0 = 1 , L_ 4 = 1  | Y =  1 ) =  0.5400560931515218\n",
      "Labelers =  (0, 5)\n",
      "P(L_ 0 = 0 , L_ 5 = 0  | Y =  1 ) =  0.062415118728315844\n",
      "P(L_ 0 = 0 , L_ 5 = 1  | Y =  1 ) =  0.2150696008148972\n",
      "P(L_ 0 = 1 , L_ 5 = 0  | Y =  1 ) =  0.1625140817022842\n",
      "P(L_ 0 = 1 , L_ 5 = 1  | Y =  1 ) =  0.5600011987545029\n",
      "Labelers =  (0, 6)\n",
      "P(L_ 0 = 0 , L_ 6 = 0  | Y =  1 ) =  0.04737111127063178\n",
      "P(L_ 0 = 0 , L_ 6 = 1  | Y =  1 ) =  0.2301136082725813\n",
      "P(L_ 0 = 1 , L_ 6 = 0  | Y =  1 ) =  0.12334467127338776\n",
      "P(L_ 0 = 1 , L_ 6 = 1  | Y =  1 ) =  0.5991706091833993\n",
      "Labelers =  (0, 7)\n",
      "P(L_ 0 = 0 , L_ 7 = 0  | Y =  1 ) =  0.040766542563315085\n",
      "P(L_ 0 = 0 , L_ 7 = 1  | Y =  1 ) =  0.23671817697989797\n",
      "P(L_ 0 = 1 , L_ 7 = 0  | Y =  1 ) =  0.10614796500387308\n",
      "P(L_ 0 = 1 , L_ 7 = 1  | Y =  1 ) =  0.616367315452914\n",
      "Labelers =  (0, 8)\n",
      "P(L_ 0 = 0 , L_ 8 = 0  | Y =  1 ) =  0.054434158070609986\n",
      "P(L_ 0 = 0 , L_ 8 = 1  | Y =  1 ) =  0.22305056147260302\n",
      "P(L_ 0 = 1 , L_ 8 = 0  | Y =  1 ) =  0.1417357681550935\n",
      "P(L_ 0 = 1 , L_ 8 = 1  | Y =  1 ) =  0.5807795123016934\n",
      "Labelers =  (0, 9)\n",
      "P(L_ 0 = 0 , L_ 9 = 0  | Y =  1 ) =  0.07418171100196595\n",
      "P(L_ 0 = 0 , L_ 9 = 1  | Y =  1 ) =  0.20330300854124714\n",
      "P(L_ 0 = 1 , L_ 9 = 0  | Y =  1 ) =  0.1931544901383311\n",
      "P(L_ 0 = 1 , L_ 9 = 1  | Y =  1 ) =  0.529360790318456\n",
      "Labelers =  (1, 2)\n",
      "P(L_ 1 = 0 , L_ 2 = 0  | Y =  1 ) =  0.0855346738158116\n",
      "P(L_ 1 = 0 , L_ 2 = 1  | Y =  1 ) =  0.1822903278272486\n",
      "P(L_ 1 = 1 , L_ 2 = 0  | Y =  1 ) =  0.15278952730848813\n",
      "P(L_ 1 = 1 , L_ 2 = 1  | Y =  1 ) =  0.5793854710484516\n",
      "Labelers =  (1, 3)\n",
      "P(L_ 1 = 0 , L_ 3 = 0  | Y =  1 ) =  0.06963532729788662\n",
      "P(L_ 1 = 0 , L_ 3 = 1  | Y =  1 ) =  0.19818967434517362\n",
      "P(L_ 1 = 1 , L_ 3 = 0  | Y =  1 ) =  0.1868595517077279\n",
      "P(L_ 1 = 1 , L_ 3 = 1  | Y =  1 ) =  0.5453154466492118\n",
      "Labelers =  (1, 4)\n",
      "P(L_ 1 = 0 , L_ 4 = 0  | Y =  1 ) =  0.06774553462635163\n",
      "P(L_ 1 = 0 , L_ 4 = 1  | Y =  1 ) =  0.2000794670167086\n",
      "P(L_ 1 = 1 , L_ 4 = 0  | Y =  1 ) =  0.18480807656476195\n",
      "P(L_ 1 = 1 , L_ 4 = 1  | Y =  1 ) =  0.5473669217921779\n",
      "Labelers =  (1, 5)\n",
      "P(L_ 1 = 0 , L_ 5 = 0  | Y =  1 ) =  0.060246714772337076\n",
      "P(L_ 1 = 0 , L_ 5 = 1  | Y =  1 ) =  0.20757828687072316\n",
      "P(L_ 1 = 1 , L_ 5 = 0  | Y =  1 ) =  0.16468248565826302\n",
      "P(L_ 1 = 1 , L_ 5 = 1  | Y =  1 ) =  0.567492512698677\n",
      "Labelers =  (1, 6)\n",
      "P(L_ 1 = 0 , L_ 6 = 0  | Y =  1 ) =  0.045722603414246284\n",
      "P(L_ 1 = 0 , L_ 6 = 1  | Y =  1 ) =  0.22210239822881397\n",
      "P(L_ 1 = 1 , L_ 6 = 0  | Y =  1 ) =  0.12499317912977324\n",
      "P(L_ 1 = 1 , L_ 6 = 1  | Y =  1 ) =  0.6071818192271666\n",
      "Labelers =  (1, 7)\n",
      "P(L_ 1 = 0 , L_ 7 = 0  | Y =  1 ) =  0.03934746187039449\n",
      "P(L_ 1 = 0 , L_ 7 = 1  | Y =  1 ) =  0.22847753977266572\n",
      "P(L_ 1 = 1 , L_ 7 = 0  | Y =  1 ) =  0.10756704569679368\n",
      "P(L_ 1 = 1 , L_ 7 = 1  | Y =  1 ) =  0.6246079526601462\n",
      "Labelers =  (1, 8)\n",
      "P(L_ 1 = 0 , L_ 8 = 0  | Y =  1 ) =  0.052539218786880476\n",
      "P(L_ 1 = 0 , L_ 8 = 1  | Y =  1 ) =  0.21528578285617972\n",
      "P(L_ 1 = 1 , L_ 8 = 0  | Y =  1 ) =  0.14363070743882303\n",
      "P(L_ 1 = 1 , L_ 8 = 1  | Y =  1 ) =  0.5885442909181167\n",
      "Labelers =  (1, 9)\n",
      "P(L_ 1 = 0 , L_ 9 = 0  | Y =  1 ) =  0.0715993199820025\n",
      "P(L_ 1 = 0 , L_ 9 = 1  | Y =  1 ) =  0.19622568166105778\n",
      "P(L_ 1 = 1 , L_ 9 = 0  | Y =  1 ) =  0.19573688115829455\n",
      "P(L_ 1 = 1 , L_ 9 = 1  | Y =  1 ) =  0.5364381171986453\n",
      "Labelers =  (2, 3)\n",
      "P(L_ 2 = 0 , L_ 3 = 0  | Y =  1 ) =  0.06898681215072335\n",
      "P(L_ 2 = 0 , L_ 3 = 1  | Y =  1 ) =  0.16933738897357642\n",
      "P(L_ 2 = 1 , L_ 3 = 0  | Y =  1 ) =  0.18750806685489116\n",
      "P(L_ 2 = 1 , L_ 3 = 1  | Y =  1 ) =  0.5741677320208091\n",
      "Labelers =  (2, 4)\n",
      "P(L_ 2 = 0 , L_ 4 = 0  | Y =  1 ) =  0.061070804098353526\n",
      "P(L_ 2 = 0 , L_ 4 = 1  | Y =  1 ) =  0.17725339702594622\n",
      "P(L_ 2 = 1 , L_ 4 = 0  | Y =  1 ) =  0.19148280709276003\n",
      "P(L_ 2 = 1 , L_ 4 = 1  | Y =  1 ) =  0.5701929917829403\n",
      "Labelers =  (2, 5)\n",
      "P(L_ 2 = 0 , L_ 5 = 0  | Y =  1 ) =  0.05364831663744939\n",
      "P(L_ 2 = 0 , L_ 5 = 1  | Y =  1 ) =  0.18467588448685038\n",
      "P(L_ 2 = 1 , L_ 5 = 0  | Y =  1 ) =  0.17128088379315068\n",
      "P(L_ 2 = 1 , L_ 5 = 1  | Y =  1 ) =  0.5903949150825496\n",
      "Labelers =  (2, 6)\n",
      "P(L_ 2 = 0 , L_ 6 = 0  | Y =  1 ) =  0.04069112743544266\n",
      "P(L_ 2 = 0 , L_ 6 = 1  | Y =  1 ) =  0.1976330736888571\n",
      "P(L_ 2 = 1 , L_ 6 = 0  | Y =  1 ) =  0.13002465510857686\n",
      "P(L_ 2 = 1 , L_ 6 = 1  | Y =  1 ) =  0.6316511437671234\n",
      "Labelers =  (2, 7)\n",
      "P(L_ 2 = 0 , L_ 7 = 0  | Y =  1 ) =  0.03501398213987054\n",
      "P(L_ 2 = 0 , L_ 7 = 1  | Y =  1 ) =  0.20331021898442925\n",
      "P(L_ 2 = 1 , L_ 7 = 0  | Y =  1 ) =  0.11190052542731763\n",
      "P(L_ 2 = 1 , L_ 7 = 1  | Y =  1 ) =  0.6497752734483827\n",
      "Labelers =  (2, 8)\n",
      "P(L_ 2 = 0 , L_ 8 = 0  | Y =  1 ) =  0.046752107632913056\n",
      "P(L_ 2 = 0 , L_ 8 = 1  | Y =  1 ) =  0.19157209349138668\n",
      "P(L_ 2 = 1 , L_ 8 = 0  | Y =  1 ) =  0.14941781859279044\n",
      "P(L_ 2 = 1 , L_ 8 = 1  | Y =  1 ) =  0.6122579802829098\n",
      "Labelers =  (2, 9)\n",
      "P(L_ 2 = 0 , L_ 9 = 0  | Y =  1 ) =  0.0637126988818393\n",
      "P(L_ 2 = 0 , L_ 9 = 1  | Y =  1 ) =  0.17461150224246053\n",
      "P(L_ 2 = 1 , L_ 9 = 0  | Y =  1 ) =  0.20362350225845777\n",
      "P(L_ 2 = 1 , L_ 9 = 1  | Y =  1 ) =  0.5580522966172425\n",
      "Labelers =  (3, 4)\n",
      "P(L_ 3 = 0 , L_ 4 = 0  | Y =  1 ) =  0.08616401592007601\n",
      "P(L_ 3 = 0 , L_ 4 = 1  | Y =  1 ) =  0.1703308630855385\n",
      "P(L_ 3 = 1 , L_ 4 = 0  | Y =  1 ) =  0.16638959527103753\n",
      "P(L_ 3 = 1 , L_ 4 = 1  | Y =  1 ) =  0.5771155257233478\n",
      "Labelers =  (3, 5)\n",
      "P(L_ 3 = 0 , L_ 5 = 0  | Y =  1 ) =  0.05871843647480071\n",
      "P(L_ 3 = 0 , L_ 5 = 1  | Y =  1 ) =  0.19777644253081383\n",
      "P(L_ 3 = 1 , L_ 5 = 0  | Y =  1 ) =  0.16621076395579934\n",
      "P(L_ 3 = 1 , L_ 5 = 1  | Y =  1 ) =  0.5772943570385862\n",
      "Labelers =  (3, 6)\n",
      "P(L_ 3 = 0 , L_ 6 = 0  | Y =  1 ) =  0.04391938360622883\n",
      "P(L_ 3 = 0 , L_ 6 = 1  | Y =  1 ) =  0.21257549539938567\n",
      "P(L_ 3 = 1 , L_ 6 = 0  | Y =  1 ) =  0.12679639893779068\n",
      "P(L_ 3 = 1 , L_ 6 = 1  | Y =  1 ) =  0.6167087220565948\n",
      "Labelers =  (3, 7)\n",
      "P(L_ 3 = 0 , L_ 7 = 0  | Y =  1 ) =  0.03769979499533799\n",
      "P(L_ 3 = 0 , L_ 7 = 1  | Y =  1 ) =  0.21879508401027656\n",
      "P(L_ 3 = 1 , L_ 7 = 0  | Y =  1 ) =  0.10921471257185014\n",
      "P(L_ 3 = 1 , L_ 7 = 1  | Y =  1 ) =  0.6342904084225354\n",
      "Labelers =  (3, 8)\n",
      "P(L_ 3 = 0 , L_ 8 = 0  | Y =  1 ) =  0.05031819978340552\n",
      "P(L_ 3 = 0 , L_ 8 = 1  | Y =  1 ) =  0.20617667922220895\n",
      "P(L_ 3 = 1 , L_ 8 = 0  | Y =  1 ) =  0.145851726442298\n",
      "P(L_ 3 = 1 , L_ 8 = 1  | Y =  1 ) =  0.5976533945520873\n",
      "Labelers =  (3, 9)\n",
      "P(L_ 3 = 0 , L_ 9 = 0  | Y =  1 ) =  0.06857066540487217\n",
      "P(L_ 3 = 0 , L_ 9 = 1  | Y =  1 ) =  0.18792421360074238\n",
      "P(L_ 3 = 1 , L_ 9 = 0  | Y =  1 ) =  0.19876553573542485\n",
      "P(L_ 3 = 1 , L_ 9 = 1  | Y =  1 ) =  0.5447395852589607\n",
      "Labelers =  (4, 5)\n",
      "P(L_ 4 = 0 , L_ 5 = 0  | Y =  1 ) =  0.06585665377273231\n",
      "P(L_ 4 = 0 , L_ 5 = 1  | Y =  1 ) =  0.18669695741838124\n",
      "P(L_ 4 = 1 , L_ 5 = 0  | Y =  1 ) =  0.15907254665786777\n",
      "P(L_ 4 = 1 , L_ 5 = 1  | Y =  1 ) =  0.5883738421510188\n",
      "Labelers =  (4, 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(L_ 4 = 0 , L_ 6 = 0  | Y =  1 ) =  0.04427706018601464\n",
      "P(L_ 4 = 0 , L_ 6 = 1  | Y =  1 ) =  0.20827655100509887\n",
      "P(L_ 4 = 1 , L_ 6 = 0  | Y =  1 ) =  0.12643872235800485\n",
      "P(L_ 4 = 1 , L_ 6 = 1  | Y =  1 ) =  0.6210076664508817\n",
      "Labelers =  (4, 7)\n",
      "P(L_ 4 = 0 , L_ 7 = 0  | Y =  1 ) =  0.03725363964606395\n",
      "P(L_ 4 = 0 , L_ 7 = 1  | Y =  1 ) =  0.2152999715450496\n",
      "P(L_ 4 = 1 , L_ 7 = 0  | Y =  1 ) =  0.10966086792112419\n",
      "P(L_ 4 = 1 , L_ 7 = 1  | Y =  1 ) =  0.6377855208877624\n",
      "Labelers =  (4, 8)\n",
      "P(L_ 4 = 0 , L_ 8 = 0  | Y =  1 ) =  0.049557708099677765\n",
      "P(L_ 4 = 0 , L_ 8 = 1  | Y =  1 ) =  0.20299590309143573\n",
      "P(L_ 4 = 1 , L_ 8 = 0  | Y =  1 ) =  0.14661221812602573\n",
      "P(L_ 4 = 1 , L_ 8 = 1  | Y =  1 ) =  0.6008341706828607\n",
      "Labelers =  (4, 9)\n",
      "P(L_ 4 = 0 , L_ 9 = 0  | Y =  1 ) =  0.0675193608873296\n",
      "P(L_ 4 = 0 , L_ 9 = 1  | Y =  1 ) =  0.18503425030378398\n",
      "P(L_ 4 = 1 , L_ 9 = 0  | Y =  1 ) =  0.19981684025296745\n",
      "P(L_ 4 = 1 , L_ 9 = 1  | Y =  1 ) =  0.5476295485559193\n",
      "Labelers =  (5, 6)\n",
      "P(L_ 5 = 0 , L_ 6 = 0  | Y =  1 ) =  0.060786727187192455\n",
      "P(L_ 5 = 0 , L_ 6 = 1  | Y =  1 ) =  0.1641424732434076\n",
      "P(L_ 5 = 1 , L_ 6 = 0  | Y =  1 ) =  0.10992905535682707\n",
      "P(L_ 5 = 1 , L_ 6 = 1  | Y =  1 ) =  0.6651417442125731\n",
      "Labelers =  (5, 7)\n",
      "P(L_ 5 = 0 , L_ 7 = 0  | Y =  1 ) =  0.03593203430473658\n",
      "P(L_ 5 = 0 , L_ 7 = 1  | Y =  1 ) =  0.18899716612586348\n",
      "P(L_ 5 = 1 , L_ 7 = 0  | Y =  1 ) =  0.11098247326245159\n",
      "P(L_ 5 = 1 , L_ 7 = 1  | Y =  1 ) =  0.6640883263069486\n",
      "Labelers =  (5, 8)\n",
      "P(L_ 5 = 0 , L_ 8 = 0  | Y =  1 ) =  0.04439952339878205\n",
      "P(L_ 5 = 0 , L_ 8 = 1  | Y =  1 ) =  0.18052967703181802\n",
      "P(L_ 5 = 1 , L_ 8 = 0  | Y =  1 ) =  0.15177040282692145\n",
      "P(L_ 5 = 1 , L_ 8 = 1  | Y =  1 ) =  0.6233003967424785\n",
      "Labelers =  (5, 9)\n",
      "P(L_ 5 = 0 , L_ 9 = 0  | Y =  1 ) =  0.06018253346922105\n",
      "P(L_ 5 = 0 , L_ 9 = 1  | Y =  1 ) =  0.16474666696137905\n",
      "P(L_ 5 = 1 , L_ 9 = 0  | Y =  1 ) =  0.20715366767107607\n",
      "P(L_ 5 = 1 , L_ 9 = 1  | Y =  1 ) =  0.5679171318983243\n",
      "Labelers =  (6, 7)\n",
      "P(L_ 6 = 0 , L_ 7 = 0  | Y =  1 ) =  0.04333486509557767\n",
      "P(L_ 6 = 0 , L_ 7 = 1  | Y =  1 ) =  0.12738091744844182\n",
      "P(L_ 6 = 1 , L_ 7 = 0  | Y =  1 ) =  0.10357964247161051\n",
      "P(L_ 6 = 1 , L_ 7 = 1  | Y =  1 ) =  0.7257045749843701\n",
      "Labelers =  (6, 8)\n",
      "P(L_ 6 = 0 , L_ 8 = 0  | Y =  1 ) =  0.03522943073721054\n",
      "P(L_ 6 = 0 , L_ 8 = 1  | Y =  1 ) =  0.13548635180680896\n",
      "P(L_ 6 = 1 , L_ 8 = 0  | Y =  1 ) =  0.16094049548849296\n",
      "P(L_ 6 = 1 , L_ 8 = 1  | Y =  1 ) =  0.6683437219674876\n",
      "Labelers =  (6, 9)\n",
      "P(L_ 6 = 0 , L_ 9 = 0  | Y =  1 ) =  0.04595984714986288\n",
      "P(L_ 6 = 0 , L_ 9 = 1  | Y =  1 ) =  0.12475593539415665\n",
      "P(L_ 6 = 1 , L_ 9 = 0  | Y =  1 ) =  0.2213763539904342\n",
      "P(L_ 6 = 1 , L_ 9 = 1  | Y =  1 ) =  0.6079078634655466\n",
      "Labelers =  (7, 8)\n",
      "P(L_ 7 = 0 , L_ 8 = 0  | Y =  1 ) =  0.040767645061777984\n",
      "P(L_ 7 = 0 , L_ 8 = 1  | Y =  1 ) =  0.10614686250541021\n",
      "P(L_ 7 = 1 , L_ 8 = 0  | Y =  1 ) =  0.15540228116392546\n",
      "P(L_ 7 = 1 , L_ 8 = 1  | Y =  1 ) =  0.6976832112688863\n",
      "Labelers =  (7, 9)\n",
      "P(L_ 7 = 0 , L_ 9 = 0  | Y =  1 ) =  0.041481823194346464\n",
      "P(L_ 7 = 0 , L_ 9 = 1  | Y =  1 ) =  0.10543268437284173\n",
      "P(L_ 7 = 1 , L_ 9 = 0  | Y =  1 ) =  0.22585437794595056\n",
      "P(L_ 7 = 1 , L_ 9 = 1  | Y =  1 ) =  0.6272311144868614\n",
      "Labelers =  (8, 9)\n",
      "P(L_ 8 = 0 , L_ 9 = 0  | Y =  1 ) =  0.08156242653870527\n",
      "P(L_ 8 = 0 , L_ 9 = 1  | Y =  1 ) =  0.11460749968699822\n",
      "P(L_ 8 = 1 , L_ 9 = 0  | Y =  1 ) =  0.18577377460159178\n",
      "P(L_ 8 = 1 , L_ 9 = 1  | Y =  1 ) =  0.6180562991727049\n",
      "[[0.72251528 0.55628418 0.55334161 0.53732451 0.54005609 0.5600012\n",
      "  0.59917061 0.61636732 0.58077951 0.52936079 0.41707623 0.41712091\n",
      "  0.44019937 0.42512063 0.55628418 0.52433272 0.44655512 0.50408679\n",
      "  0.48057568]\n",
      " [0.55628418 0.732175   0.57938547 0.54531545 0.54736692 0.56749251\n",
      "  0.60718182 0.62460795 0.58854429 0.53643812 0.42327887 0.43675333\n",
      "  0.57938547 0.43087556 0.55628418 0.53134331 0.45252538 0.51082627\n",
      "  0.48700449]\n",
      " [0.55334161 0.57938547 0.7616758  0.57416773 0.57019299 0.59039492\n",
      "  0.63165114 0.64977527 0.61225798 0.5580523  0.44567428 0.57416773\n",
      "  0.57938547 0.44884375 0.44019937 0.55275636 0.47075858 0.53140899\n",
      "  0.50665862]\n",
      " [0.53732451 0.54531545 0.57416773 0.74350512 0.57711553 0.57729436\n",
      "  0.61670872 0.63429041 0.59765339 0.54473959 0.57711553 0.57416773\n",
      "  0.43675333 0.45429302 0.41431401 0.53968028 0.45952927 0.51874492\n",
      "  0.49541613]\n",
      " [0.54005609 0.54736692 0.57019299 0.57711553 0.74744639 0.58837384\n",
      "  0.62100767 0.63778552 0.60083417 0.54762955 0.57711553 0.44567428\n",
      "  0.43372986 0.58837384 0.41587266 0.54344228 0.46197493 0.52160335\n",
      "  0.5049242 ]\n",
      " [0.5600012  0.56749251 0.59039492 0.57729436 0.58837384 0.7750708\n",
      "  0.66514174 0.66408833 0.6233004  0.56791713 0.45429302 0.44581239\n",
      "  0.44909689 0.58837384 0.43116347 0.5820639  0.47924897 0.54311471\n",
      "  0.66514174]\n",
      " [0.59917061 0.60718182 0.63165114 0.61670872 0.62100767 0.66514174\n",
      "  0.82928422 0.72570457 0.66834372 0.60790786 0.47949013 0.47624991\n",
      "  0.48047935 0.5049242  0.46131819 0.72570457 0.5138823  0.59350663\n",
      "  0.66514174]\n",
      " [0.61636732 0.62460795 0.64977527 0.63429041 0.63778552 0.66408833\n",
      "  0.72570457 0.85308549 0.69768321 0.62723111 0.49244458 0.48982727\n",
      "  0.49426587 0.50412453 0.47455803 0.72570457 0.53644112 0.69768321\n",
      "  0.5820639 ]\n",
      " [0.58077951 0.58854429 0.61225798 0.59765339 0.60083417 0.6233004\n",
      "  0.66834372 0.69768321 0.80383007 0.6180563  0.46391385 0.46153454\n",
      "  0.46572752 0.47316148 0.44715796 0.59350663 0.6180563  0.69768321\n",
      "  0.53605664]\n",
      " [0.52936079 0.53643812 0.5580523  0.54473959 0.54762955 0.56791713\n",
      "  0.60790786 0.62723111 0.6180563  0.7326638  0.42283369 0.42067214\n",
      "  0.42449477 0.43111879 0.40756929 0.53357429 0.6180563  0.53644112\n",
      "  0.48758301]\n",
      " [0.41707623 0.42327887 0.44567428 0.57711553 0.57711553 0.45429302\n",
      "  0.47949013 0.49244458 0.46391385 0.42283369 0.57711553 0.44567428\n",
      "  0.33901196 0.45429302 0.32159435 0.41960063 0.35669837 0.40273844\n",
      "  0.3898602 ]\n",
      " [0.41712091 0.43675333 0.57416773 0.57416773 0.44567428 0.44581239\n",
      "  0.47624991 0.48982727 0.46153454 0.42067214 0.44567428 0.57416773\n",
      "  0.43675333 0.35082528 0.33183183 0.41676512 0.35486894 0.40059791\n",
      "  0.38258238]\n",
      " [0.44019937 0.57938547 0.57938547 0.43675333 0.43372986 0.44909689\n",
      "  0.48047935 0.49426587 0.46572752 0.42449477 0.33901196 0.43675333\n",
      "  0.57938547 0.34142288 0.44019937 0.4204663  0.35809288 0.40422795\n",
      "  0.38540104]\n",
      " [0.42512063 0.43087556 0.44884375 0.45429302 0.58837384 0.58837384\n",
      "  0.5049242  0.50412453 0.47316148 0.43111879 0.45429302 0.35082528\n",
      "  0.34142288 0.58837384 0.32736608 0.44185792 0.36380878 0.4122907\n",
      "  0.5049242 ]\n",
      " [0.55628418 0.55628418 0.44019937 0.41431401 0.41587266 0.43116347\n",
      "  0.46131819 0.47455803 0.44715796 0.40756929 0.32159435 0.33183183\n",
      "  0.44019937 0.32736608 0.55628418 0.40369841 0.34381495 0.38811019\n",
      "  0.37001113]\n",
      " [0.52433272 0.53134331 0.55275636 0.53968028 0.54344228 0.5820639\n",
      "  0.72570457 0.72570457 0.59350663 0.53357429 0.41960063 0.41676512\n",
      "  0.4204663  0.44185792 0.40369841 0.72570457 0.45634087 0.59350663\n",
      "  0.5820639 ]\n",
      " [0.44655512 0.45252538 0.47075858 0.45952927 0.46197493 0.47924897\n",
      "  0.5138823  0.53644112 0.6180563  0.6180563  0.35669837 0.35486894\n",
      "  0.35809288 0.36380878 0.34381495 0.45634087 0.6180563  0.53644112\n",
      "  0.41216818]\n",
      " [0.50408679 0.51082627 0.53140899 0.51874492 0.52160335 0.54311471\n",
      "  0.59350663 0.69768321 0.69768321 0.53644112 0.40273844 0.40059791\n",
      "  0.40422795 0.4122907  0.38811019 0.59350663 0.53644112 0.69768321\n",
      "  0.47603226]\n",
      " [0.48057568 0.48700449 0.50665862 0.49541613 0.5049242  0.66514174\n",
      "  0.66514174 0.5820639  0.53605664 0.48758301 0.3898602  0.38258238\n",
      "  0.38540104 0.5049242  0.37001113 0.5820639  0.41216818 0.47603226\n",
      "  0.66514174]]\n",
      "\n",
      "Condition number =  1018.1699180955213 \n",
      "\n",
      "[[0.72251528]\n",
      " [0.732175  ]\n",
      " [0.7616758 ]\n",
      " [0.74350512]\n",
      " [0.74744639]\n",
      " [0.7750708 ]\n",
      " [0.82928422]\n",
      " [0.85308549]\n",
      " [0.80383007]\n",
      " [0.7326638 ]\n",
      " [0.57711553]\n",
      " [0.57416773]\n",
      " [0.57938547]\n",
      " [0.58837384]\n",
      " [0.55628418]\n",
      " [0.72570457]\n",
      " [0.6180563 ]\n",
      " [0.69768321]\n",
      " [0.66514174]]\n",
      "[1.]\n",
      "sig\n",
      " [[2.00486950e-01 2.72765604e-02 3.01920966e-03 1.30695335e-04\n",
      "  1.46559149e-05 7.02629752e-07 9.02298042e-08 1.16342046e-08\n",
      "  1.10905773e-09 2.04802397e-10 1.01446923e-04 2.27594571e-03\n",
      "  2.15845158e-02 1.15368233e-05 1.54360361e-01 7.89598793e-08\n",
      "  8.52742599e-10 9.51486012e-09 6.02975081e-07]\n",
      " [2.72765604e-02 1.96094770e-01 2.17054943e-02 9.39585907e-04\n",
      "  1.05363294e-04 5.05129744e-06 6.48673898e-07 8.36398231e-08\n",
      "  7.97316235e-09 1.47235291e-09 7.29315238e-04 1.63620722e-02\n",
      "  1.55173915e-01 8.29397360e-05 1.48986813e-01 5.67652929e-07\n",
      "  6.13047890e-09 6.84035784e-08 4.33486695e-06]\n",
      " [3.01920966e-03 2.17054943e-02 1.81525776e-01 7.85787502e-03\n",
      "  8.81166470e-04 4.22446353e-05 5.42494133e-06 6.99490351e-07\n",
      "  6.66805594e-08 1.23134728e-08 6.09935499e-03 1.36838066e-01\n",
      "  1.38081580e-01 6.93635436e-04 1.64911711e-02 4.74735279e-06\n",
      "  5.12699652e-08 5.72067722e-07 3.62530370e-05]\n",
      " [1.30695335e-04 9.39585907e-04 7.85787502e-03 1.90705256e-01\n",
      "  2.13853080e-02 1.02524843e-03 1.31659618e-04 1.69761527e-05\n",
      "  1.61829160e-06 2.98839571e-07 1.48027177e-01 1.47271083e-01\n",
      "  5.97726569e-03 1.68340579e-02 7.13868653e-04 1.15215007e-04\n",
      "  1.24428701e-06 1.38836926e-05 8.79836431e-04]\n",
      " [1.46559149e-05 1.05363294e-04 8.81166470e-04 2.13853080e-02\n",
      "  1.88770285e-01 9.04997194e-03 1.16217282e-03 1.49850224e-04\n",
      "  1.42848243e-05 2.63788723e-06 1.45752610e-01 1.65146862e-02\n",
      "  6.70278682e-04 1.48595939e-01 8.00518104e-05 1.01701457e-03\n",
      "  1.09834478e-05 1.22552764e-04 7.76640550e-03]\n",
      " [7.02629752e-07 5.05129744e-06 4.22446353e-05 1.02524843e-03\n",
      "  9.04997194e-03 1.74336055e-01 2.23877627e-02 2.88667159e-03\n",
      "  2.75178744e-04 5.08155006e-05 6.98763068e-03 7.91742446e-04\n",
      "  3.21343122e-05 1.32342458e-01 3.83782140e-06 1.95914760e-02\n",
      "  2.11581977e-04 2.36082118e-03 1.49609801e-01]\n",
      " [9.02298043e-08 6.48673898e-07 5.42494133e-06 1.31659618e-04\n",
      "  1.16217282e-03 2.23877627e-02 1.41571904e-01 1.82542400e-02\n",
      "  1.74012827e-03 3.21338370e-04 8.97332553e-04 1.01673415e-04\n",
      "  4.12660110e-06 1.69950590e-02 4.92842601e-07 1.23889224e-01\n",
      "  1.33796591e-03 1.49289571e-02 1.13550193e-01]\n",
      " [1.16342047e-08 8.36398231e-08 6.99490351e-07 1.69761527e-05\n",
      "  1.49850224e-04 2.88667159e-03 1.82542400e-02 1.25330635e-01\n",
      "  1.19474370e-02 2.20625685e-03 1.15701797e-04 1.31097404e-05\n",
      "  5.32082740e-07 2.19133794e-03 6.35469810e-08 1.06616530e-01\n",
      "  9.18625579e-03 1.02499785e-01 1.46411288e-02]\n",
      " [1.10905773e-09 7.97316224e-09 6.66805593e-08 1.61829160e-06\n",
      "  1.42848243e-05 2.75178744e-04 1.74012827e-03 1.19474370e-02\n",
      "  1.57687286e-01 2.91191037e-02 1.10295454e-05 1.24971677e-06\n",
      "  5.07220361e-08 2.08894433e-04 6.05776496e-09 1.01634710e-02\n",
      "  1.21244059e-01 1.36864464e-01 1.39569996e-03]\n",
      " [2.04802508e-10 1.47235291e-09 1.23134728e-08 2.98839571e-07\n",
      "  2.63788723e-06 5.08155006e-05 3.21338370e-04 2.20625685e-03\n",
      "  2.91191037e-02 1.95867557e-01 2.03675568e-06 2.30777212e-07\n",
      "  9.36651434e-09 3.85752003e-05 1.11864878e-09 1.87682325e-03\n",
      "  1.65228823e-01 2.52738861e-02 2.57734995e-04]\n",
      " [1.01446923e-04 7.29315238e-04 6.09935499e-03 1.48027177e-01\n",
      "  1.45752610e-01 6.98763068e-03 8.97332553e-04 1.15701797e-04\n",
      "  1.10295454e-05 2.03675568e-06 2.44053196e-01 1.14313172e-01\n",
      "  4.63960870e-03 1.14733343e-01 5.54111426e-04 7.85253506e-04\n",
      "  8.48049884e-06 9.46249845e-05 5.99656813e-03]\n",
      " [2.27594571e-03 1.63620722e-02 1.36838066e-01 1.47271083e-01\n",
      "  1.65146862e-02 7.91742446e-04 1.01673415e-04 1.31097404e-05\n",
      "  1.24971677e-06 2.30777212e-07 1.14313172e-01 2.44499148e-01\n",
      "  1.04088889e-01 1.30000085e-02 1.24314023e-02 8.89741545e-05\n",
      "  9.60893786e-07 1.07216051e-05 6.79448835e-04]\n",
      " [2.15845158e-02 1.55173915e-01 1.38081580e-01 5.97726569e-03\n",
      "  6.70278682e-04 3.21343122e-05 4.12660110e-06 5.32082740e-07\n",
      "  5.07220361e-08 9.36651434e-09 4.63960870e-03 1.04088889e-01\n",
      "  2.43697947e-01 5.27629070e-04 1.17896397e-01 3.61117845e-06\n",
      "  3.89996281e-08 4.35155911e-07 2.75766710e-05]\n",
      " [1.15368233e-05 8.29397360e-05 6.93635436e-04 1.68340579e-02\n",
      "  1.48595939e-01 1.32342458e-01 1.69950590e-02 2.19133794e-03\n",
      "  2.08894433e-04 3.85752003e-05 1.14733343e-01 1.30000085e-02\n",
      "  5.27629070e-04 2.42190064e-01 6.30150764e-05 1.48723342e-02\n",
      "  1.60616683e-04 1.79215296e-03 1.13572197e-01]\n",
      " [1.54360361e-01 1.48986813e-01 1.64911711e-02 7.13868653e-04\n",
      "  8.00518104e-05 3.83782140e-06 4.92842601e-07 6.35469810e-08\n",
      "  6.05776507e-09 1.11864873e-09 5.54111426e-04 1.24314023e-02\n",
      "  1.17896397e-01 6.30150764e-05 2.46832091e-01 4.31285345e-07\n",
      "  4.65775046e-09 5.19709480e-08 3.29349941e-06]\n",
      " [7.89598794e-08 5.67652929e-07 4.74735279e-06 1.15215007e-04\n",
      "  1.01701457e-03 1.95914760e-02 1.23889224e-01 1.06616530e-01\n",
      "  1.01634710e-02 1.87682325e-03 7.85253506e-04 8.89741545e-05\n",
      "  3.61117845e-06 1.48723342e-02 4.31285345e-07 1.99057445e-01\n",
      "  7.81458354e-03 8.71947347e-02 9.93674944e-02]\n",
      " [8.52742710e-10 6.13047896e-09 5.12699652e-08 1.24428701e-06\n",
      "  1.09834478e-05 2.11581977e-04 1.33796591e-03 9.18625579e-03\n",
      "  1.21244059e-01 1.65228823e-01 8.48049884e-06 9.60893786e-07\n",
      "  3.89996281e-08 1.60616683e-04 4.65775046e-09 7.81458354e-03\n",
      "  2.36062710e-01 1.05233615e-01 1.07313869e-03]\n",
      " [9.51486023e-09 6.84035784e-08 5.72067722e-07 1.38836926e-05\n",
      "  1.22552764e-04 2.36082118e-03 1.49289571e-02 1.02499785e-01\n",
      "  1.36864464e-01 2.52738861e-02 9.46249845e-05 1.07216051e-05\n",
      "  4.35155911e-07 1.79215296e-03 5.19709480e-08 8.71947347e-02\n",
      "  1.05233615e-01 2.10921348e-01 1.19740282e-02]\n",
      " [6.02975081e-07 4.33486695e-06 3.62530370e-05 8.79836431e-04\n",
      "  7.76640550e-03 1.49609801e-01 1.13550193e-01 1.46411288e-02\n",
      "  1.39569996e-03 2.57734995e-04 5.99656813e-03 6.79448835e-04\n",
      "  2.75766710e-05 1.13572197e-01 3.29349941e-06 9.93674944e-02\n",
      "  1.07313869e-03 1.19740282e-02 2.22728204e-01]]\n",
      "\n",
      "Condition number =  83.43970763124439 \n",
      "\n",
      "moment of truth!!!\n",
      "note this is with the joint form!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../synthetic/generate.py:610: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  p = np.ones(self.k+1) * (1 - prob_y - prob_0) / (self.k - 1)\n",
      "../synthetic/generate.py:610: RuntimeWarning: invalid value encountered in true_divide\n",
      "  p = np.ones(self.k+1) * (1 - prob_y - prob_0) / (self.k - 1)\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic dataset\n",
    "np.random.seed(2)\n",
    "N = 10000\n",
    "M = 10\n",
    "K = 1\n",
    "EDGE_PROB=1.0\n",
    "data = SingleTaskTreeDepsGenerator(N, M, k=K, edge_prob=EDGE_PROB)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjQAAAI3CAYAAACMH8GtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3X+wrXV9H/r3RwSsCOKRivwyMM0pE5obSXIGQad3NEaDxBHrNSmMNyUthmhjq3PTSTDt1V7TmWvaRptEq54KI2kVfyVEpqUiJWaMww89cFFBMBBC9ORQKGAAo6LnnM/9Y6/jbDZ7n3PYe6+9n7We12tmzV7Pj/V5nmevddb+nvf3+zxPdXcAAGbZUzZ7BwAA1kqDBgCYeRo0AMDM06ABAGaeBg0AMPM0aACAmadBAwDMPA0aAGDmadAAADPvqZu9AwDAxvqZlxzRDz60Z0O2ddOXH7u6u8+e9nY0aABgZB58aE++cPXzNmRbhxx35zEbsR1dTgDAzJPQAMDIdJK92bvZu7GuJDQAwMyT0ADA6HT2tIQGAGBQJDQAMDILY2h6s3djXUloAICZJ6EBgBFylhMAwMBIaABgZDqdPW0MDQDAoEhoAGCEnOUEADAwGjQAwMzT5QQAI9NJ9uhyAgAYFgkNAIyQQcEAAAMjoQGAkenEhfUAAIZGQgMAIzRft6aU0AAAc0BCAwAj02nXoQEAGBoJDQCMTSd75iugkdAAALNPQgMAI9NxlhMAwOBIaABgdCp7Upu9E+tKQgMAzDwNGgBg5ulyAoCR6SR7nbYNADAsEhoAGKF5GxSsQQMAbKqquifJo0n2JNnd3duqakuSjyU5Ock9SX6+u7+5Ug1dTgAwMp2FhGYjHk/CS7r79O7eNpm+OMm13b01ybWT6RVp0AAAQ3Rukssmzy9L8ur9razLCQBGaG8PagxNJ/lMVXWSD3T39iTHdve9SdLd91bVc/ZXQIMGAJimY6pqx6Lp7ZMGy2Iv6u5dk0bLNVV1x5PdiAYNAIzMvjE0G+SBReNiltXduyY/76+qK5KckeS+qjpuks4cl+T+/dUwhgYA2DRVdURVHbnveZKXJ7k1yZVJLpisdkGST+2vjoQGAEamU9kznEzj2CRXVFWy0C75SHd/uqq+mOTjVXVhkq8n+bn9FdGgAQA2TXffneT5y8x/MMlLD7aOBg0AjNDAznJas8HkTQAAqyWhAYCR2eCznDaEhAYAmHmDTGie+rQj+vAjtkyl9iHf2zuVuj/wre9Mtz4wenu2HDHV+oc89DdTrc8TfTd/k+/1Y/MVmWywQTZoDj9iS/7ez75lKrWPvOe7U6m7z1M+f8tU6wM8/LNnTrX+M//LDVOtzxPd2Ndu8BYre3q+Omnm62gAgFEaZEIDAExPJ9k7Z5nGfB0NADBKEhoAGCGnbQMADIyEBgBGpttZTo9TVWdX1deq6q6quniZ5YdX1ccmy2+sqpPXsj0AgOWsukFTVYckeW+SVyQ5Lcn5VXXaktUuTPLN7v7hJO9O8lur3R4AsH72pjbksVHWktCckeSu7r67u7+X5KNJzl2yzrlJLps8/2SSl1bVfI1CAgA23VrG0JyQ5BuLpncmecFK63T37qp6OMmzkzywhu0CAGuwcHNKY2j2WS5p6VWss7Bi1UVVtaOqdux+zH1EAICDt5aEZmeSkxZNn5hk1wrr7KyqpyZ5ZpKHlivW3duTbE+SI5590rKNHgBgPTjLabEvJtlaVadU1WFJzkty5ZJ1rkxyweT5a5P8cXdrrAAA62rVCc1kTMybklyd5JAkl3b3bVX1jiQ7uvvKJJck+c9VdVcWkpnz1mOnAYDVm8d7Oa3pwnrdfVWSq5bMe9ui599N8nNr2QYAwIHMV/MMABgltz4AgBHa0/N1WTgJDQAw8yQ0ADAynXJhPQCAoRlkQnPI9/bmyHu+O5Xad73usKnU3efkI7ZNtf5hV++Yan0Yiwd++ayp1j/mA9dPrXbtnVppRmSvC+sBAAzLIBMaAGB63JwSAGCAJDQAMDKdch0aAIChkdAAwAjN280p5+toAIBRktAAwMh0J3tchwYAYFgkNAAwOpW9cZYTAMCgaNAAADNPlxMAjEzHoGAAgMGR0ADACLk5JQDAwEhoAGBkOpW9bk4JADAsEhoAGCFjaAAABkZCAwAj00n2ug4NAMCwSGgAYHQqe+bs5pTDbNB86zt5yudvmUrpk4/YNpW6+3z9/9wz1frPPeoFU6v9jE/cOLXasBr/880vnFrtwx7tqdWetqM+csNm7wIMzjAbNADA1BhDAwAwQBIaABiheRtDI6EBAGaehAYARqa7jKEBABgaDRoAYObpcgKAEdqjywkAYFgkNAAwMp1kr9O2AQCGRUIDAKNTxtAAAAyNhAYARmbh5pTG0AAADIqEBgBGaM+cZRrzdTQAwChJaABgZDplDA0AwNBIaABghPbOWaax6qOpqpOq6rNVdXtV3VZVb15mnRdX1cNVdcvk8ba17S4AwBOtJaHZneRXu/vmqjoyyU1VdU13f3XJen/a3a9cw3YAgHXUnewxhmZBd9/b3TdPnj+a5PYkJ6zXjgEAHKx1GUNTVScn+fEkNy6z+Kyq+lKSXUn+RXfftkKNi5JclCRPy9PXY7eWddjVO6ZWO0mee9QLplr/f/0f35la7cMe2Ta12sn0f/dsvAdff9Z0NzDFLv4tl14/veLAhltzg6aqnpHkD5K8pbsfWbL45iQ/1N3fqqpzkvxRkq3L1enu7Um2J8lRtaXXul8AwMqctr1IVR2ahcbMh7v7D5cu7+5Huvtbk+dXJTm0qo5ZyzYBAJZadUJTVZXkkiS3d/e7VljnuUnu6+6uqjOy0IB6cLXbBADWbuHCevN12vZaupxelOQXknylqm6ZzPuNJM9Lku5+f5LXJnljVe1O8p0k53W37iQAYF2tukHT3Z9Pst8OuO5+T5L3rHYbAMB07Nn/n/CZM195EwAwSm59AAAj03GWEwDA4EhoAGB05u8sp/k6GgBglCQ0ADBCe53lBAAwLBIaABiZ7mSPs5wAAIZFQgMAI+QsJwCAgdGgAQBmni4nABiZTg3q1gdVdUiSHUn+qrtfWVWnJPloki1Jbk7yC939vf3VkNAAAJvtzUluXzT9W0ne3d1bk3wzyYUHKqBBAwAjtDe1IY8DqaoTk/xskg9OpivJTyX55GSVy5K8+kB1NGgAgGk6pqp2LHpctGT5f0jya0n2TqafneSvu3v3ZHpnkhMOtBFjaABgZDrZyDE0D3T3tuUWVNUrk9zf3TdV1Yv3zV5m1T7QRjRo1tkzPnHjVOsf9siyn4l1cd8vfXdqtZPkmVvOnFrtoy6/YWq12Y8DfsWszXPffd10NzBFu37thVOrffy/nd3fCyzxoiSvqqpzkjwtyVFZSGyOrqqnTlKaE5PsOlAhXU4AMEJ7+ykb8tif7n5rd5/Y3ScnOS/JH3f365J8NslrJ6tdkORTBzoeDRoAYGh+Pcn/VVV3ZWFMzSUHeoEuJwAYmx7WdWiSpLv/JMmfTJ7fneSMJ/N6CQ0AMPMkNAAwMp0c1DViZomEBgCYeRIaABihoY2hWSsJDQAw8yQ0ADAyG3yl4A0hoQEAZp4GDQAw83Q5AcAI6XICABgYCQ0AjExneLc+WCsJDQAw8yQ0ADBCbn0AADAwEhoAGJt2lhMAwOBIaABgZNz6AABggCQ0ADBCEhoAgIGR0MyYw67eMbXaz9xy5tRqJ8nWf/7VqdW+47CzplY7SZ512fVTrT+rnn2J38tKavdm7wHr7e53Tu975rHfvWFqtZfjSsEAAAMkoQGAEWoJDQDAsGjQAAAzT5cTAIyQm1MCAAyMhAYARqbdnBIAYHjWnNBU1T1JHk2yJ8nu7t62ZHkl+Z0k5yT5dpJf7O6b17pdAGD15u207fXqcnpJdz+wwrJXJNk6ebwgyfsmPwEA1sVGjKE5N8nvd3cnuaGqjq6q47r73g3YNgDwBG59sJxO8pmquqmqLlpm+QlJvrFoeudk3uNU1UVVtaOqdnw/j63DbgEAY7EeCc2LuntXVT0nyTVVdUd3f27R8uWagP2EGd3bk2xPkqNqyxOWAwDrZ97G0Kw5oenuXZOf9ye5IskZS1bZmeSkRdMnJtm11u0CAOyzpgZNVR1RVUfue57k5UluXbLalUn+US04M8nDxs8AwObpLFyHZiMeG2WtXU7HJrli4czsPDXJR7r701X1hiTp7vcnuSoLp2zflYXTtv/xGrcJAPA4a2rQdPfdSZ6/zPz3L3reSX5lLdsBANZRL1wteJ64UjAAMPPcywkARsjdtgEABkaDBgCYebqcAGBkOvN3YT0NGn7gqMtvmGr9Ow47a2q1/83//cGp1U6Stzzvl6ZW+6TfvG5qtdk8x71rdt/Xv/joj02t9innfXlqtaft0Een1wCovVMrPRoaNAAwOm5OCQAwOBIaABghF9YDABgYCQ0AjNC8neUkoQEAZp6EBgBGpltCAwAwOBIaABgh16EBABgYCQ0AjJDr0AAADIyEBgBGyFlOAAADo0EDAMw8XU4AMDKd0uUEADA0EhoAGKE5O2tbQgMAzD4JDQCMjZtTAgAMj4QGAMZozgbRSGgAgJknoWHDPOuy66dW+y3P+6Wp1U6Sr77xP06t9qmHv3FqtZPk5H81vd8782n3dw/d7F1YtTsv+4mp1d56wXVTq72r/2ZqtVdiDA0AwMBIaABghNoYGgCAYZHQAMDIdIyhAQAYHAkNAIxNJ5HQAAAMiwYNADDzdDkBwAg5bRsAYGAkNAAwRhIaAIBhkdAAwOiUC+sBAAyNhAYAxsgYGgCAYZHQAMDYtJtTAgAMjoQGAMbIGJoFVXVqVd2y6PFIVb1lyTovrqqHF63ztrXvMgDA4606oenuryU5PUmq6pAkf5XkimVW/dPufuVqtwMATIMxNMt5aZI/7+6/XKd6AAAHbb3G0JyX5PIVlp1VVV9KsivJv+ju29Zpm/ADJ/3mdVOtf+rhb5xa7X/+mv86tdpJ8onrzp5a7cOv+uLUarN5tv7iTVOr/eDrz5pa7SR5+pGPTLX+XDGG5vGq6rAkr0ryiWUW35zkh7r7+Ul+L8kf7afORVW1o6p2fD+PrXW3AIARWY8up1ckubm771u6oLsf6e5vTZ5fleTQqjpmuSLdvb27t3X3tkNz+DrsFgAwdFX1tKr6QlV9qapuq6r/ZzL/lKq6sarurKqPTQKUFa1Hg+b8rNDdVFXPraqaPD9jsr0H12GbAMBa9AY9DuyxJD816c05PcnZVXVmkt9K8u7u3prkm0ku3F+RNTVoqurpSV6W5A8XzXtDVb1hMvnaJLdOxtD8bpLzunvOeu0AgNXqBd+aTB46eXSSn0ryycn8y5K8en911jQouLu/neTZS+a9f9Hz9yR5z1q2AQCss06ycbc+OKaqdiya3t7d2xevMLn8y01JfjjJe5P8eZK/7u7dk1V2JjlhfxtxpWAAYJoe6O5t+1uhu/ckOb2qjs7CNe1+ZLnV9ldDgwYARmiIA0C6+6+r6k+SnJnk6Kp66iSlOTELl39ZkZtTAgCbpqr+9iSZSVX9rSQ/neT2JJ/NwljcJLkgyaf2V0dCAwBjNJyE5rgkl03G0Twlyce7+79W1VeTfLSq/k2S/y/JJfsrokEDAGya7v5ykh9fZv7dSc442DoaNAAwRht3ltOGMIYGAJh5EhoAGKEazhiadSGhAQBmnoQGAMbm4O+zNDMkNADAzJPQAMDolLOcAACGRoMGAJh5upwAYIwMCgYAGBYJDQCMkYQGAGBYJDRwEE7+V9dPrfYnrjt7arWT5MHTDp1a7eOvmlpp5tRjR0/3VOETXnPbVOvPFQkNAMCwSGgAYGw6LqwHADA0EhoAGKEyhgYAYFgkNAAwRhIaAIBh0aABAGaeBg0AMPOMoQGAEXKWEwDAwEhoAGCMXCkYAGBYNGgAgJmnywkAxqbjwnoAAEMjoQGAMZLQAAAMi4QGAEbIhfUAAAZGQgMAYyShAQAYFgnNjHnw9WdNr/iUW+vPvuT66W5gRh1+1RenWv/4q6ZX+y/+3yl+HpOc8lafmXlz/L+/brN3gX0kNAAAwyKhAYCRqXaWEwDA4EhoAGCMujZ7D9aVhAYAmHkSGgAYI2NoAACGRYMGAJh5B9WgqapLq+r+qrp10bwtVXVNVd05+fmsFV57wWSdO6vqgvXacQBg9faduj3tx0Y52ITmQ0nOXjLv4iTXdvfWJNdOph+nqrYkeXuSFyQ5I8nbV2r4AACs1kE1aLr7c0keWjL73CSXTZ5fluTVy7z0Z5Jc090Pdfc3k1yTJzaMAICN1hv02CBrGUNzbHffmySTn89ZZp0Tknxj0fTOybwnqKqLqmpHVe34fh5bw24BAGMz7dO2l7tqz7Ltte7enmR7khxVW+bsZDIAGBC3Pnic+6rquCSZ/Lx/mXV2Jjlp0fSJSXatYZsAAE+wlgbNlUn2nbV0QZJPLbPO1UleXlXPmgwGfvlkHgCwmcY4hqaqLk9yfZJTq2pnVV2Y5J1JXlZVdyZ52WQ6VbWtqj6YJN39UJLfTPLFyeMdk3kAAOvmoMbQdPf5Kyx66TLr7kjy+kXTlya5dFV7BwBMhzE0AADD4uaUADBCznICABgYDRoAYOZp0AAAM88YGgAYozkbQ6NBs87+55tfON0NTDFTe+67r5tecebSKW+9fqr17/ydM6dWe+ubb5habWDj6XICAGaehAYAxsbNKQEAhkdCAwBjJKEBABgWCQ0AjJGEBgBgWCQ0ADAyFWc5AQAMjoQGAMZIQgMAMCwSGgAYG1cKBgAYHgkNAIyRhAYAYFgkNAAwRhIaAIBh0aABAGaeLicAGCGnbQMADIyEBgDGSEIDADAso0toHvjls6Za/7BHp9vk3XLp9VOtD0Oy9c03TK32X7xzut8Fp1zs3yoD1pHQAAAMzegSGgDAWU4AAIMjoQGAMZLQAAAMi4QGAEbIGBoAgIGR0ADAGEloAADWR1WdVFWfrarbq+q2qnrzZP6Wqrqmqu6c/HzW/upo0ADA2PQGPg5sd5Jf7e4fSXJmkl+pqtOSXJzk2u7emuTayfSKNGgAgE3T3fd2982T548muT3JCUnOTXLZZLXLkrx6f3WMoQEApumYqtqxaHp7d29fbsWqOjnJjye5Mcmx3X1vstDoqarn7G8jGjQAMDI1eWyQB7p724FWqqpnJPmDJG/p7keqntwe6nICADZVVR2ahcbMh7v7Dyez76uq4ybLj0ty//5qaNAAwBgNZFBwLUQxlyS5vbvftWjRlUkumDy/IMmn9ldHlxMAsJlelOQXknylqm6ZzPuNJO9M8vGqujDJ15P83P6KaNAAwAgN5dYH3f35rDyk56UHW0eXEwAw8yQ0ADBGA0lo1ouEBgCYeQds0FTVpVV1f1Xdumjev6uqO6rqy1V1RVUdvcJr76mqr1TVLUsuqgMAbKaBnOW0Xg4moflQkrOXzLsmyY92948l+bMkb93P61/S3acfzEV1AABW44ANmu7+XJKHlsz7THfvnkzekOTEKewbADANvXCW00Y8Nsp6DAr+J0k+tsKyTvKZquokH1jp3g1JUlUXJbkoSZ6Wp6/Dbi3vmA9cP7Xas27Xr71wqvVr94HXWa3j3nXd9Iozl065eLrfBX/2H8+YWu2/+0+/MLXaMKvW1KCpqn+Zhdt+f3iFVV7U3bsmN5S6pqrumCQ+TzBp7GxPkqNqy5yNvQaAgZmzv7SrPsupqi5I8sokr+vuZX8t3b1r8vP+JFckmd5/WQCA0VpVg6aqzk7y60le1d3fXmGdI6rqyH3Pk7w8ya3LrQsAbKx5G0NzMKdtX57k+iSnVtXOyT0V3pPkyCx0I91SVe+frHt8VV01eemxST5fVV9K8oUk/627Pz2VowAARu2AY2i6+/xlZl+ywrq7kpwzeX53kuevae8AAA6CWx8AwBgZFAwAMCwSGgAYoY0csLsRJDQAwMyT0ADA2GzwjSM3goQGAJh5EhoAGCMJDQDAsEhoAGBkKs5yAgAYHAkNAIyRhAYAYFgkNAAwQtXzFdFIaACAmSehAYCxcaVgAIDh0aABAGbeILuc9mw5Ig//7JlTqV17p1L2B476yA3T3cAUHf9vr9vsXYC58Xf/6RemVvvrb3vh1GonyfPe4btgDFxYDwBgYAaZ0AAAUyahAQAYFgkNAIyQMTQAAAMjoQGAMZLQAAAMi4QGAMamjaEBABgcCQ0AjJGEBgBgWCQ0ADAyFWNoAAAGR0IDAGPU8xXRSGgAgJmnQQMAzDxdTgAwQgYFAwAMjIQGAMam48J6AABDI6EBgBGqvZu9B+tLQgMAzDwJDQCM0ZyNoRlkg+aQh/4mz/wvN2z2bjBD/uKjPzbV+ru/e+jUam/9xZumVpv59Lx3XDfV+j9y0/T+NNz+k7unVptxG2SDBgCYLtehAQAYGAkNAIxNx80pAQCGRkIDACNkDA0AwMBIaABgjMaW0FTVpVV1f1Xdumjev66qv6qqWyaPc1Z47dlV9bWququqLl7PHQcA2Odgupw+lOTsZea/u7tPnzyuWrqwqg5J8t4kr0hyWpLzq+q0tewsAMByDtig6e7PJXloFbXPSHJXd9/d3d9L8tEk566iDgCwjioLg4I34rFR1jIo+E1V9eVJl9Szlll+QpJvLJreOZkHALCuVtugeV+Sv5Pk9CT3JvntZdapZeat2FarqouqakdV7fh+HlvlbgEAB9S9cY8NsqoGTXff1917untvkv+Uhe6lpXYmOWnR9IlJdu2n5vbu3tbd2w7N4avZLQBgpFbVoKmq4xZN/oMkty6z2heTbK2qU6rqsCTnJblyNdsDANbXvI2hOeB1aKrq8iQvTnJMVe1M8vYkL66q07PQhXRPkl+erHt8kg929zndvbuq3pTk6iSHJLm0u2+bylEAAKN2wAZNd5+/zOxLVlh3V5JzFk1fleQJp3QDAJtsbBfWAwAYOrc+AIARcnNKAICBkdAAwNh0kr3zFdFIaACAmSehAYAxmq+ARoOG+XDKeV/e7F1YtQdff9ZU6z929HJ3IVkfx//766ZWm81z+0/unlrtO3/vBVOrnSRb/9mNU63PcGnQAMAIOcsJAGBgNGgAgJmnywkAxqjnq89JQgMAzDwJDQCMkEHBAAADI6EBgLHpzN2F9SQ0AMDMk9AAwMhUknKWEwDAsEhoAGCM9m72DqwvCQ0AMPMkNAAwQsbQAACsk6q6tKrur6pbF83bUlXXVNWdk5/POlAdDRoAGJvewMeBfSjJ2UvmXZzk2u7emuTayfR+adAAAJumuz+X5KEls89Nctnk+WVJXn2gOsbQAMDo9NDvtn1sd9+bJN19b1U950Av0KABAKbpmKrasWh6e3dvX++NaNAAwAht4N22H+jubU/yNfdV1XGTdOa4JPcf6AXG0AAAQ3Nlkgsmzy9I8qkDvUCDBgDYNFV1eZLrk5xaVTur6sIk70zysqq6M8nLJtP7pcsJAMZoIIOCu/v8FRa99MnU0aCBg3DnZT8xtdpPP/KRqdVOkhNec9tU68OTsfWf3TjV+qfuOHRqtb+27ftTq83aadAAwNh0Um5OCQAwLBIaABijgYyhWS8SGgBg5kloAGCM5iugkdAAALNPQgMAI1TG0AAADIuEBgDGSEIDADAsEhoAGJtO4krBAADDIqEBgJGptLOcAACGRoMGAJh5upwAYIx0OQEADIuEBgDGSEIDADAsB0xoqurSJK9Mcn93/+hk3seSnDpZ5egkf93dpy/z2nuSPJpkT5Ld3b1tnfYbAFitObyw3sF0OX0oyXuS/P6+Gd39D/c9r6rfTvLwfl7/ku5+YLU7CABwIAds0HT356rq5OWWVVUl+fkkP7W+uwUATNO8XVhvrYOC/36S+7r7zhWWd5LPVFUn+UB3b1/j9phhd7/zrKnVPvTRmlrtJNl6wXVTrQ+sj69t+/7Uav/lx/+3qdX+3q/7jlmrtTZozk9y+X6Wv6i7d1XVc5JcU1V3dPfnlluxqi5KclGSPC1PX+NuAQD7NWcJzarPcqqqpyZ5TZKPrbROd++a/Lw/yRVJztjPutu7e1t3bzs0h692twCAEVrLads/neSO7t653MKqOqKqjtz3PMnLk9y6hu0BAOuiFxKajXhskAM2aKrq8iTXJzm1qnZW1YWTRedlSXdTVR1fVVdNJo9N8vmq+lKSLyT5b9396fXbdQCABQdzltP5K8z/xWXm7UpyzuT53Umev8b9AwDWW8cYGgCAoXEvJwAYozm7UrCEBgCYeRo0AMDM0+UEACM0b7c+kNAAADNPQgMAYyShAQAYFgkNAIxNJ9kroQEAGBQJDQCMzsbeOHIjSGgAgJknoQGAMZLQAAAMi4QGAMZIQgMAMCwSGgAYG9ehAQAYnuoB9qFV1f9K8pcHufoxSR6Y4u4MiWOdT2M51rEcZ+JY59G0j/OHuvtvT7H+4zzz8GP7hce/bkO29el73n1Td2+b9nYG2eX0ZN7UqtqxEb+oIXCs82ksxzqW40wc6zway3HOMl1OAMDMG2RCAwBM2QCHnKzFPCQ02zd7BzaQY51PYznWsRxn4ljn0ViOc2YNclAwADA9zzzs2H7hc8/fkG19+hu/syGDguchoQEARs4YGgAYoznroZmZhKaqzq6qr1XVXVV18TLLD6+qj02W31hVJ2/8Xq5dVZ1UVZ+tqtur6raqevMy67y4qh6uqlsmj7dtxr6uh6q6p6q+MjmOHcssr6r63cn7+uWq+onN2M+1qKpTF71Xt1TVI1X1liXrzOx7WlWXVtX9VXXronlbquqaqrpz8vNZK7z2gsk6d1bVBRu316uzwrH+u6q6Y/L5vKKqjl7htfv9rA/NCsf6r6vqrxZ9Ts9Z4bX7/b4ekhWO82OLjvGeqrplhdfO1Hs672aiQVNVhyR5b5JXJDktyflVddqS1S5M8s3u/uEk707yWxu7l+tmd5Jf7e4fSXJmkl9Z5liT5E+7+/TJ4x0bu4vr7iWT41iuj/UVSbZOHhcled+G7tk66O6v7Xuvkvxkkm8nuWKZVWf1Pf1QkrOXzLs4ybXdvTXJtZPpx6mqLUnenuQFSc5I8vaVGj4D8qE88VivSfL3rBhUAAAF6ElEQVSj3f1jSf4syVv38/r9fdaH5kN54rEmybsXfU6vWrrwIL+vh+RDWXKc3f0PF/2b/YMkf7if18/Se/p43Rvz2CAz0aDJwpfdXd19d3d/L8lHk5y7ZJ1zk1w2ef7JJC+tqtrAfVwX3X1vd988ef5oktuTnLC5e7Wpzk3y+73ghiRHV9Vxm71Ta/DSJH/e3Qd7JezB6+7PJXloyezF/x4vS/LqZV76M0mu6e6HuvubWWgYLPcHdDCWO9bu/kx3755M3pDkxA3fsSlY4X09GAfzfT0Y+zvOyd+Qn09y+YbuFKsyKw2aE5J8Y9H0zjzxj/wP1pl8uTyc5NkbsndTMuk2+/EkNy6z+Kyq+lJV/feq+nsbumPrq5N8pqpuqqqLlll+MO/9LDkvK385zst7miTHdve9yUIjPclzllln3t7bJPknSf77CssO9FmfFW+adK9dukKiNk/v699Pcl9337nC8hl+TzconZHQPMFyScvS39LBrDMzquoZWYg639LdjyxZfHMW7vvx/CS/l+SPNnr/1tGLuvsnshBP/0pV/e9Lls/N+1pVhyV5VZJPLLN4nt7TgzU3722SVNW/zEKX8YdXWOVAn/VZ8L4kfyfJ6UnuTfLby6wzT+/r+dl/OjMP7+ncmJUGzc4kJy2aPjHJrpXWqaqnJnlmVheXbrqqOjQLjZkPd/cT+m67+5Hu/tbk+VVJDq2qYzZ4N9dFd++a/Lw/C+NKzliyysG897PiFUlu7u77li6Yp/d04r59XYOTn/cvs87cvLeTAc2vTPK6XuHiXgfxWR+87r6vu/d0994k/ynLH8NcvK+TvyOvSfKxldaZ6fe0k+zduzGPDTIrDZovJtlaVadM/pd7XpIrl6xzZZJ9Z0m8Nskfr/TFMmSTPttLktze3e9aYZ3n7hsfVFVnZOF9fHDj9nJ9VNURVXXkvudJXp7k1iWrXZnkH03OdjozycP7ujJm0Ir/25uX93SRxf8eL0jyqWXWuTrJy6vqWZOui5dP5s2Uqjo7ya8neVV3f3uFdQ7msz54S8av/YMsfwwH8309C346yR3dvXO5hfPyns6TmbgOTXfvrqo3ZeHL7pAkl3b3bVX1jiQ7uvvKLDQC/nNV3ZWFZOa8zdvjNXlRkl9I8pVFpwr+RpLnJUl3vz8LDbY3VtXuJN9Jct4sNt6SHJvkisnf8acm+Uh3f7qq3pD84FivSnJOkruycHbQP96kfV2Tqnp6kpcl+eVF8xYf58y+p1V1eZIXJzmmqnZm4cyldyb5eFVdmOTrSX5usu62JG/o7td390NV9ZtZ+AOYJO/o7kGnqisc61uTHJ7kmsln+YbufkNVHZ/kg919Tlb4rG/CIRy0FY71xVV1ehb+f39PJp/nxce60vf1JhzCQVnuOLv7kiwz3m3W39MnmI2vmIPm1gcAMDLPPPQ5/cJnv3ZDtvXp+963Ibc+mImEBgBYZ3MWaMzKGBoAgBVp0AAAM0+XEwCMTid7dTkBAAyKhAYAxqaThesjzg8JDQAw8yQ0ADBGxtAAAAyLhAYAxsiF9QAAhkVCAwBj053sdZYTAMCgSGgAYIyMoQEAGBYJDQCMUBtDAwAwLBIaABidNoYGAGBoNGgAgJmnywkAxqbj5pQAAEMjoQGAMWqnbQMADIqEBgBGppO0MTQAAMMioQGAsek2hgYAYGg0aABghHpvb8jjYFTV2VX1taq6q6ouXs3xaNAAAJumqg5J8t4kr0hyWpLzq+q0J1vHGBoAGKPhjKE5I8ld3X13klTVR5Ocm+SrT6aIhAYA2EwnJPnGoumdk3lPioQGAEbm0Xzz6v/Rnzxmgzb3tKrasWh6e3dvXzRdy7zmSV8kR4MGAEamu8/e7H1YZGeSkxZNn5hk15MtossJANhMX0yytapOqarDkpyX5MonW0RCAwBsmu7eXVVvSnJ1kkOSXNrdtz3ZOtU9X/dyAADGR5cTADDzNGgAgJmnQQMAzDwNGgBg5mnQAAAzT4MGAJh5GjQAwMzToAEAZt7/D1zSWTRkwV0gAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# mask the diagonals so we don't get influenced by them unfairly\n",
    "sg_no_diag = np.copy(data.sig_inv)\n",
    "# for i in range(M):\n",
    "#     sg_no_diag[i*2:i*2+2,i*2:i*2+2] = np.zeros([2,2])\n",
    "# for j in range(M-1):\n",
    "#     sg_no_diag[2*M+j*4:2*M+j*4+4,2*M+j*4:2*M+j*4+4] = np.zeros([4,4])\n",
    "\n",
    "# print(data.E)\n",
    "visualize_matrix(np.abs(sg_no_diag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([((0,), {'start_index': 0, 'end_index': 1, 'max_cliques': {5}, 'size': 1, 'members': {0}}), ((1,), {'start_index': 1, 'end_index': 2, 'max_cliques': {2, 5}, 'size': 1, 'members': {1}}), ((2,), {'start_index': 2, 'end_index': 3, 'max_cliques': {1, 2}, 'size': 1, 'members': {2}}), ((3,), {'start_index': 3, 'end_index': 4, 'max_cliques': {0, 1}, 'size': 1, 'members': {3}}), ((4,), {'start_index': 4, 'end_index': 5, 'max_cliques': {0, 3}, 'size': 1, 'members': {4}}), ((5,), {'start_index': 5, 'end_index': 6, 'max_cliques': {8, 3}, 'size': 1, 'members': {5}}), ((6,), {'start_index': 6, 'end_index': 7, 'max_cliques': {8, 4}, 'size': 1, 'members': {6}}), ((7,), {'start_index': 7, 'end_index': 8, 'max_cliques': {4, 7}, 'size': 1, 'members': {7}}), ((8,), {'start_index': 8, 'end_index': 9, 'max_cliques': {6, 7}, 'size': 1, 'members': {8}}), ((9,), {'start_index': 9, 'end_index': 10, 'max_cliques': {6}, 'size': 1, 'members': {9}})])\n"
     ]
    }
   ],
   "source": [
    "ctree = CliqueTree(M,K,data.E,False)\n",
    "print(ctree.c_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the `LabelModel`\n",
    "\n",
    "Note that:\n",
    "* The `train` method assembles other data structures, such as the dependencies junction tree, etc.\n",
    "* The `higher_order_cliques` kwarg controls whether or not to include them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LabelModel(k=data.k, class_balance=data.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.config['higher_order_cliques'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temporarily commented out\n"
     ]
    }
   ],
   "source": [
    "'''# Generate the \"correct\" mu\n",
    "lm._set_constants(data.L)\n",
    "lm._set_dependencies(data.E)\n",
    "mu = compute_mu(lm._get_augmented_label_matrix(data.L.todense()), data.Y, K, data.p)\n",
    "\n",
    "# Compute O, O_inv, P based on L\n",
    "lm._generate_O(data.L.todense())\n",
    "O = lm.O.numpy()\n",
    "print(O)\n",
    "d, d = O.shape\n",
    "O_inv = np.linalg.inv(O)\n",
    "P = np.diag(data.p)\n",
    "\n",
    "JJT = np.linalg.inv(np.linalg.inv(P) - mu.T @ O_inv @ mu)\n",
    "ZZT = O_inv @ mu @ JJT @ mu.T @ O_inv.T'''\n",
    "print('temporarily commented out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that JJT is indeed PSD ==> ZZT is rank k\n",
    "#np.linalg.eig(JJT)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.linalg.eig((ZZT + ZZT.T)/2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: O is ill-conditioned: kappa(O) = inf.\n",
      "Computing O^{-1}...\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "matrix is numerically singular",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-a85275368dc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0ml2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mO_inv_prec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;31m#O_inv=ZZT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m )\n",
      "\u001b[0;32m/lfs/1/annhe/metal/metal/label_model/label_model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, L, deps, O, c_tree, **kwargs)\u001b[0m\n\u001b[1;32m    385\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mO_inv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_O_inv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/1/annhe/metal/metal/label_model/label_model.py\u001b[0m in \u001b[0;36m_generate_O_inv\u001b[0;34m(self, L)\u001b[0m\n\u001b[1;32m    202\u001b[0m                 \u001b[0mO_unnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmpmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL_aug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mL_aug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                 \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmpmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmpf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mO_inv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mO_unnorm\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 self.O_inv = torch.from_numpy(\n\u001b[1;32m    206\u001b[0m                     np.array(O_inv.tolist(), dtype=float)).float()\n",
      "\u001b[0;32m/lfs/1/annhe/anaconda3/envs/metal/lib/python3.6/site-packages/mpmath/matrices/matrices.py\u001b[0m in \u001b[0;36m__pow__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mneg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/1/annhe/anaconda3/envs/metal/lib/python3.6/site-packages/mpmath/matrices/linalg.py\u001b[0m in \u001b[0;36minverse\u001b[0;34m(ctx, A, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;31m# get LU factorisation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m             \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLU_decomp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m             \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m             \u001b[0;31m# calculate unit vectors and solve corresponding system to get columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/1/annhe/anaconda3/envs/metal/lib/python3.6/site-packages/mpmath/matrices/linalg.py\u001b[0m in \u001b[0;36mLU_decomp\u001b[0;34m(ctx, A, overwrite, use_cache)\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabsmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabsmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mZeroDivisionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matrix is numerically singular'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m                 \u001b[0mcurrent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabsmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbiggest\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# TODO: what if equal?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: matrix is numerically singular"
     ]
    }
   ],
   "source": [
    "lm.train(\n",
    "    data.L,\n",
    "    deps=data.E,\n",
    "    all_unary_cliques=True,\n",
    "    higher_order_cliques=False,\n",
    "    n_epochs=50000,\n",
    "    print_every=5000,\n",
    "    lr=0.0001,\n",
    "    l2=0,\n",
    "    O_inv_prec=1024,\n",
    "    #O_inv=ZZT\n",
    ")\n",
    "\n",
    "lm._set_constants(data.L)\n",
    "lm._set_dependencies(data.E)\n",
    "mu = compute_mu(lm._get_augmented_label_matrix(data.L.todense()), data.Y, K, data.p)\n",
    "\n",
    "\n",
    "# Test against the true parameter values\n",
    "mu_est = lm.mu.detach().numpy()\n",
    "print(f\"Average absolute error: {np.mean(np.abs(mu_est - mu))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check that the true $Z$ gets lower loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(np.linalg.eig(O)[0])[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "O = lm.O.numpy()\n",
    "d, d = O.shape\n",
    "O_inv = lm.O_inv.numpy()\n",
    "mask = lm.mask.numpy()\n",
    "P = lm.P.numpy()\n",
    "\n",
    "JJT = np.linalg.inv(np.linalg.inv(P) - mu.T @ O_inv @ mu)\n",
    "ZZT = O_inv @ mu @ JJT @ mu.T @ O_inv.T\n",
    "\n",
    "np.linalg.norm((O_inv + ZZT) * mask)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seed=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_matrix(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize_matrix(np.abs((O_inv + ZZT) * mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.c_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_est = lm.Z.detach().numpy()\n",
    "visualize_matrix(np.abs((O_inv + Z_est @ Z_est.T) * mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seed=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_matrix(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_matrix(np.abs((O_inv + ZZT) * mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_est = lm.Z.detach().numpy()\n",
    "visualize_matrix(np.abs((O_inv + Z_est @ Z_est.T) * mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seed=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_matrix(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_matrix(np.abs((O_inv + ZZT) * mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_est = lm.Z.detach().numpy()\n",
    "visualize_matrix(np.abs((O_inv + Z_est @ Z_est.T) * mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_matrix(np.abs(mu_est - mu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_matrix(np.abs(mu_est - mu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.c_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying to solve with `scipy.optimize.minimize`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "O_inv = lm.O_inv.numpy()\n",
    "mask = lm.mask.numpy()\n",
    "\n",
    "z0 = np.random.randn(lm.d * lm.k)\n",
    "l import LabelModl import LabelModel\n",
    "from metal.label_model.utils import (\n",
    "    compute_mu,\n",
    "    compute_covariance,\n",
    "    compute_inv_covariance,\n",
    "    print_matrix,el\n",
    "from metal.label_model.utils import (\n",
    "    compute_mu,\n",
    "    compute_covariance,\n",
    "    compute_inv_covariance,\n",
    "    print_matrix,\n",
    "def objective_fn(z):\n",
    "    Z = z.reshape(-1, data.k)\n",
    "    return np.linalg.norm( (O_inv + Z @ Z.T) * mask )**2\n",
    "\n",
    "def gradient_fn(z):\n",
    "    Z = z.reshape(-1, data.k)\n",
    "    X = (O_inv + Z @ Z.T) * mask\n",
    "    return np.ravel(X @ Z)\n",
    "\n",
    "res = minimize(objective_fn, z0, jac=gradient_fn, method='BFGS')\n",
    "Z = res['x'].reshape(-1, data.k)\n",
    "res['fun']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "O = lm.O.numpy()\n",
    "P = lm.P.numpy()\n",
    "I_k = np.eye(data.k)\n",
    "Q = O @ Z @ np.linalg.inv(I_k + Z.T @ O @ Z) @ Z.T @ O\n",
    "\n",
    "mu0 = np.random.randn(lm.d * lm.k)\n",
    "\n",
    "def objective_fn_2(mu):\n",
    "    M = mu.reshape(-1, data.k)\n",
    "    return np.linalg.norm(Q - M @ P @ M.T)**2 + np.linalg.norm(np.sum(M @ P, 1) - np.diag(O))**2\n",
    "\n",
    "res_2 = minimize(objective_fn_2, mu0, method='BFGS')\n",
    "M = res_2['x'].reshape(-1, data.k)\n",
    "res_2['fun']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test against the true parameter values\n",
    "print(f\"Average absolute error: {np.mean(np.abs(M - mu))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the inverse covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = compute_inv_covariance(\n",
    "    lm._get_augmented_label_matrix(data.L.todense()),\n",
    "    data.Y,\n",
    "    data.k,\n",
    "    data.p\n",
    ")\n",
    "visualize_matrix(np.abs(J))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_matrix(lm.mask.numpy(), fig_size=[5,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "O_inv = lm.O_inv.numpy()\n",
    "Z = lm.Z.detach().numpy()\n",
    "mask = lm.mask.numpy()\n",
    "visualize_matrix(np.abs((O_inv + Z@Z.T) * mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at the internal 'bookkeeping' of cliques..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.c_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependency edge weights\n",
    "[((i,j), data.theta[(i,j)]) for i,j in data.E]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
