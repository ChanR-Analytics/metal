{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from synthetics import generate_single_task_unipolar, gaussian_bags_of_words, vocab1k\n",
    "\n",
    "N = 10000\n",
    "M = 30\n",
    "K = 2\n",
    "NUM_SPLITS = 3\n",
    "\n",
    "Ds = [] # data\n",
    "Xs = [] # features\n",
    "Ls = [] # noisy labels\n",
    "Ys = [] # true labels\n",
    "for _ in range(NUM_SPLITS):\n",
    "    L, Y, _ = generate_single_task_unipolar(\n",
    "        N, M, k=K, alpha_range=[0.6, 0.9], beta_range=[0.1, 0.2], \n",
    "        class_balance=[0.3, 0.7], seed=1)\n",
    "    \n",
    "    X, D = gaussian_bags_of_words(Y, vocab1k)\n",
    "    \n",
    "    Ls.append(L)\n",
    "    Ys.append(Y)\n",
    "    Ds.append(D)\n",
    "    Xs.append(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply LabelModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from metal.label_model import LabelModel\n",
    "\n",
    "lm = LabelModel(seed=2)\n",
    "lm.train(Ls[0], L_dev=Ls[1], Y_dev=Ys[1], n_epochs=1000, lr=0.01, print_at=100)\n",
    "Y_p = lm.score(Ls[1], Ys[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_p = lm.predict(Ls[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    'print_at': 200,\n",
    "    'n_epochs': 1000, # a single constant value\n",
    "    'l2': [0, 0.1, 0.01], # a list of discrete values\n",
    "    'lr': {'range': [0.01, 0.0001], 'scale': 'log'}, # a range and scale to interpolate by\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from metal.tuner import ModelTuner\n",
    "\n",
    "tuner = ModelTuner(LabelModel)\n",
    "init_args = []\n",
    "train_args = [Ls[0]]\n",
    "model, best_config = tuner.search(init_args, train_args, Ls[1], Ys[1], \n",
    "                                  search_space, max_search=5, metric='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate metrics in one of two ways.\n",
    "\n",
    "1. Use metric_score() and pass the metric name\n",
    "3. The the specific metric's function (e.g., accuracy_score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metal.metrics import metric_score, accuracy_score\n",
    "\n",
    "metric_score(Ys[1], Y_p, 'accuracy')\n",
    "accuracy_score(Ys[1], Y_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Built-in metrics include:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_score(Ys[1], Y_p, 'accuracy')\n",
    "metric_score(Ys[1], Y_p, 'coverage')\n",
    "metric_score(Ys[1], Y_p, 'precision')\n",
    "metric_score(Ys[1], Y_p, 'recall')\n",
    "metric_score(Ys[1], Y_p, 'f1')\n",
    "metric_score(Ys[1], Y_p, 'fbeta', beta=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from metal.analysis import confusion_matrix\n",
    "confusion_matrix(Y_p, Ys[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(Y_p, Ys[1], normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = confusion_matrix(Y_p, Ys[1], pretty_print=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metal.analysis import error_buckets\n",
    "\n",
    "buckets = error_buckets(Y_p, Ys[1], Ds[1])\n",
    "tp = buckets[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label matrix analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metal.analysis import (\n",
    "    item_coverage,\n",
    "    item_overlap,\n",
    "    item_conflict,\n",
    "    LF_accuracies,\n",
    "    LF_coverages,\n",
    "    LF_overlaps,\n",
    "    LF_conflicts,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_coverage(Ls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_overlap(Ls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_conflict(Ls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LF_accuracies(Ls[0], Ys[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LF_coverages(Ls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LF_overlaps(Ls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LF_conflicts(Ls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metal.analysis import (\n",
    "    view_label_matrix,\n",
    "    view_overlaps,\n",
    "    view_conflicts,\n",
    ")\n",
    "\n",
    "view_label_matrix(Ls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_overlaps(Ls[0], normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_conflicts(Ls[0], normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metal]",
   "language": "python",
   "name": "conda-env-metal-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
