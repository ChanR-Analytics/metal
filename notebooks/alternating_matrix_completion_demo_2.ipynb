{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append(\"../\") # go to parent dir\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import mpmath\n",
    "import math\n",
    "\n",
    "from amc_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_dist_det(m):\n",
    "    accs = [0.75 for _ in range(m)]\n",
    "    accs = np.asarray(accs)\n",
    "    var = np.multiply(accs,(1.0-accs))\n",
    "    mu = accs\n",
    "    print(\"mu: \", mu)\n",
    "    #mu = 2*np.array(accs) - 1\n",
    "    \n",
    "    ratio = np.max(np.divide(mu,var))/(np.min(np.divide(mu,var)))\n",
    "\n",
    "    return mu, var, ratio\n",
    "\n",
    "def get_observed_matrix_one_dep(mu,var,m):\n",
    "    sig = np.diag(var)\n",
    "    \n",
    "    sig[1,0] = 0.1\n",
    "    sig[0,1] = 0.1\n",
    "    mu = np.reshape(mu,[m,1])\n",
    "    \n",
    "    O = sig + mu @ mu.T\n",
    "    Oinv = np.linalg.inv(O)\n",
    "    return O, Oinv, sig\n",
    "\n",
    "def get_observed_matrix_half_deps(mu,var,m):\n",
    "    sig = np.diag(var)\n",
    "    half = math.floor(m/2)\n",
    "    for i in range(half):\n",
    "        sig[2*i,2*i+1] = 0.1\n",
    "        sig[2*i+1,2*i] = 0.1\n",
    "    mu = np.reshape(mu,[m,1])\n",
    "    \n",
    "    O = sig + mu @ mu.T\n",
    "    Oinv = np.linalg.inv(O)\n",
    "    return O, Oinv, sig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is alternating matrix completion?\n",
    "\n",
    "Let's say we have $$\\Sigma = O - \\mu \\mu^{T}$$\n",
    "where $\\Sigma$ is a covariance matrix and $\\mu$ are the means of some random variables. \n",
    "\n",
    "In this problem setting, we only have access to $O$ but we want to learn $\\mu$ and the structure of $\\Sigma$ (and also $\\Sigma$.)\n",
    "\n",
    "Let's say that we have a guess $\\Omega_{0}$ of initial dependencies in $\\Sigma$ (ideally a subset of the true $\\Omega$). Then we can solve the problem $$ \\lVert O^{-1} + zz^{T} \\rVert_{\\Omega_{0}}$$ (Where we can solve for $\\mu$ from $z$).\n",
    "\n",
    "After solving for $\\hat{\\mu}$ we can examine $$\\hat{\\Sigma} = O - \\hat{\\mu} \\hat{\\mu}^{T}$$. If we look at the entries of $\\hat{\\Sigma}$ that are not in $\\Omega_{0}$, then intuitively the largest entries will be those dependencies that we missed in our initial guess. \n",
    "\n",
    "We can add the entry corresponding to the largest value to our set, creating $\\Omega_{1}$. Then, we repeat the process until the maximum value of an entry of the inverse covariance that is not in $\\Omega_{t}$ is approximately zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dummy data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu:  [0.75 0.75 0.75 0.75 0.75 0.75]\n"
     ]
    }
   ],
   "source": [
    "m=6\n",
    "mu, var, _ = generate_synthetic_dist_det(m)\n",
    "mu_true = mu\n",
    "O, O_inv, sig = get_observed_matrix_half_deps(mu, var, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_inv = np.linalg.pinv(sig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure of the true inverse covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.45341615 -3.97515528  0.          0.          0.          0.        ]\n",
      " [-3.97515528  7.45341615  0.          0.          0.          0.        ]\n",
      " [ 0.          0.          7.45341615 -3.97515528  0.          0.        ]\n",
      " [ 0.          0.         -3.97515528  7.45341615  0.          0.        ]\n",
      " [ 0.          0.          0.          0.          7.45341615 -3.97515528]\n",
      " [ 0.          0.          0.          0.         -3.97515528  7.45341615]]\n"
     ]
    }
   ],
   "source": [
    "print(sig_inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First iteration of AMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.73765557 -3.69091586  0.          0.          0.          0.        ]\n",
      " [-3.69091586  7.73765557  0.          0.          0.          0.        ]\n",
      " [ 0.          0.          7.73765557 -3.69091586  0.          0.        ]\n",
      " [ 0.          0.         -3.69091586  7.73765557  0.          0.        ]\n",
      " [ 0.          0.          0.          0.          7.73765557 -3.69091586]\n",
      " [ 0.          0.          0.          0.         -3.69091586  7.73765557]]\n",
      "Index of largest value:  (4, 5)\n",
      "Largest value:  3.69091586108999\n"
     ]
    }
   ],
   "source": [
    "iterative_deps_mask = [(i,i) for i in range(m)]\n",
    "mu = solveMatrixCompletionWithMu(O_inv,O,iterative_deps_mask)\n",
    "C_synth = O - np.outer(mu, mu)\n",
    "J_synth = np.linalg.pinv(C_synth)\n",
    "J_clean = copy.deepcopy(J_synth)\n",
    "for i in range(m):\n",
    "    for j in range(m):\n",
    "        if abs(J_clean[i,j]) < 0.3:\n",
    "            J_clean[i,j] = 0.0\n",
    "print(J_clean)\n",
    "max_val, max_ind, J_clean = find_largest(O,mu,m,iterative_deps_mask,0.2)\n",
    "print(\"Index of largest value: \", max_ind)\n",
    "print(\"Largest value: \", max_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second iteration of AMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.82977315 -3.59879828  0.376357    0.376357    0.          0.        ]\n",
      " [-3.59879828  7.82977315  0.376357    0.376357    0.          0.        ]\n",
      " [ 0.376357    0.376357    7.82977315 -3.59879828  0.          0.        ]\n",
      " [ 0.376357    0.376357   -3.59879828  7.82977315  0.          0.        ]\n",
      " [ 0.          0.          0.          0.          7.45341615 -3.97515528]\n",
      " [ 0.          0.          0.          0.         -3.97515528  7.45341615]]\n",
      "Index of largest value:  (5, 4)\n",
      "Largest value:  3.975155279503102\n"
     ]
    }
   ],
   "source": [
    "iterative_deps_mask.append(max_ind)\n",
    "mu = solveMatrixCompletionWithMu(O_inv,O,iterative_deps_mask)\n",
    "C_synth = O - np.outer(mu, mu)\n",
    "J_synth = np.linalg.pinv(C_synth)\n",
    "J_clean = copy.deepcopy(J_synth)\n",
    "for i in range(m):\n",
    "    for j in range(m):\n",
    "        if abs(J_clean[i,j]) < 0.3:\n",
    "            J_clean[i,j] = 0.0\n",
    "print(J_clean)\n",
    "max_val, max_ind, J_clean = find_largest(O,mu,m,iterative_deps_mask,0.2)\n",
    "print(\"Index of largest value: \", max_ind)\n",
    "print(\"Largest value: \", max_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's turn this into an algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amc(O, O_inv, mu_true, thresh=0.2, nonzeros=3):\n",
    "    dim = np.shape(O)[0]\n",
    "    iterative_deps_mask = samplegrid(dim,dim,nonzeros)\n",
    "    try:\n",
    "        C_synth = O - np.outer(mu_true, mu_true)\n",
    "        J_synth = np.linalg.pinv(C_synth)\n",
    "    except:\n",
    "        print(\"Failed to invert J before loop\")\n",
    "        return np.zeros(np.shape(mu_true)), iterative_deps_mask\n",
    "    num_iters = 0\n",
    "    while(True):\n",
    "        num_iters = num_iters + 1\n",
    "        starttime = time.time()\n",
    "        mu = solveMatrixCompletionWithMu(O_inv,O,iterative_deps_mask)\n",
    "        max_val, max_ind, J_clean = find_largest(O,mu,dim,iterative_deps_mask,thresh)\n",
    "        #if max_val < 1e-6: return J_distances, mu_distances, max_vals, mu, num_iters\n",
    "        if max_val < 1e-6: \n",
    "            return mu, iterative_deps_mask\n",
    "\n",
    "        iterative_deps_mask.append(max_ind)\n",
    "    #return J_distances, mu_distances, max_vals, mu, num_iters\n",
    "    return mu, iterative_deps_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0), (1, 1), (2, 2), (3, 3), (4, 4), (5, 5), (4, 5), (5, 4), (2, 3), (3, 2), (1, 0), (0, 1)]\n"
     ]
    }
   ],
   "source": [
    "mu, end_deps = amc(O,O_inv,mu_true)\n",
    "print(end_deps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How will we incorporate this into Metal?\n",
    "\n",
    "Incorporate as a function of the Label Model class, which takes in an observation matrix and solves for mu based on a set of dependencies. Basically, AMC allows the use of Metal in cases where the dependencies are not predetermined. Caveat: Currently only solves the binary case single-task case."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metal]",
   "language": "python",
   "name": "conda-env-metal-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
