{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SoftCrossEntropyLoss(nn.Module):\n",
    "    \"\"\"Computes the CrossEntropyLoss while accepting soft (float) targets\n",
    "\n",
    "    Args:\n",
    "        weight: a tensor of relative weights to assign to each class.\n",
    "        size_average:\n",
    "        reduce:\n",
    "\n",
    "    Accepts:\n",
    "        input: An [n, K_t] float tensor of prediction logits (not probabilities)\n",
    "        target: An [n, K_t] float tensor of target probabilities\n",
    "    \"\"\"\n",
    "    def __init__(self, weight=None, size_average=True, reduce=True):\n",
    "        super().__init__()\n",
    "        assert(weight is None or isinstance(weight, torch.FloatTensor))\n",
    "        self.weight = weight\n",
    "        self.reduce = reduce\n",
    "        self.size_average = size_average and reduce\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        N, K_t = input.shape\n",
    "        total_loss = torch.tensor(0.0)\n",
    "        cum_losses = torch.zeros(N)\n",
    "        for y in range(K_t):\n",
    "            cls_idx = torch.full((N,), y, dtype=torch.long)\n",
    "            y_loss = F.cross_entropy(input, cls_idx, reduce=False)\n",
    "            if self.weight is not None:\n",
    "                y_loss = y_loss * self.weight[y]\n",
    "            cum_losses += target[:, y] * y_loss\n",
    "        if not self.reduce:\n",
    "            return cum_losses\n",
    "        elif self.size_average:\n",
    "            return cum_losses.mean()\n",
    "        else:\n",
    "            return cum_losses.sum()\n",
    "        \n",
    "def hard_to_soft(Y_h, k):\n",
    "    \"\"\"Converts a 1D tensor of hard labels into a 2D tensor of soft labels\n",
    "\n",
    "    Args:\n",
    "        Y_h: an [N], or [N,1] tensor of hard (int) labels >= 1\n",
    "        k: the target cardinality of the soft label matrix\n",
    "    \"\"\"\n",
    "    Y_h = Y_h.squeeze()\n",
    "    assert(Y_h.dim() == 1)\n",
    "    assert((Y_h >= 1).all())\n",
    "    N = Y_h.shape[0]\n",
    "    Y_s = torch.zeros(N, k, dtype=torch.float)\n",
    "    for i, j in enumerate(Y_h):\n",
    "        Y_s[i, j-1] = 1.0\n",
    "    return Y_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimum Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(66.6667)\n",
      "tensor(100.)\n",
      "tensor(100.)\n"
     ]
    }
   ],
   "source": [
    "input = torch.tensor([\n",
    "    [-100.,  100., -100.],\n",
    "    [-100.,  100., -100.]\n",
    "])\n",
    "target = torch.tensor([0,1], dtype=torch.long)\n",
    "soft_target = hard_to_soft(target + 1, k=3)\n",
    "weights = torch.tensor([1,2,1], dtype=torch.float)\n",
    "\n",
    "ce_noreduce = nn.CrossEntropyLoss(weight=weights, reduce=False)\n",
    "ce_reduce = nn.CrossEntropyLoss(weight=weights, reduce=True, size_average=True)\n",
    "sce = SoftCrossEntropyLoss(weight=weights, reduce=True, size_average=True)\n",
    "\n",
    "ce_loss = ce_noreduce(input, target)\n",
    "ce_loss_reduced = ce_reduce(input, target)\n",
    "sce_loss = sce(input, soft_target)\n",
    "\n",
    "print(ce_loss_reduced)\n",
    "print(ce_loss.mean())\n",
    "print(sce_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimum Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(133.3333)\n",
      "tensor(133.3333)\n"
     ]
    }
   ],
   "source": [
    "input = torch.tensor([\n",
    "    [-1,  1, -1],\n",
    "    [-1,  1, -1],\n",
    "    [-1,  1, -1],\n",
    "], dtype=torch.float) * 100\n",
    "target = torch.tensor([0,0,1], dtype=torch.long)\n",
    "weights = torch.tensor([1,10,1], dtype=torch.float)\n",
    "\n",
    "ce_noweights = nn.CrossEntropyLoss(weight=None, reduce=False)\n",
    "ce_weights = nn.CrossEntropyLoss(weight=weights, reduce=False)\n",
    "\n",
    "loss1 = ce_noweights(input, target)\n",
    "loss2 = ce_weights(input, target)\n",
    "\n",
    "print(loss1.mean())\n",
    "print(loss2.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  0,  1], dtype=torch.uint8)\n",
      "tensor([ 200.,  200.,   -0.])\n",
      "tensor(133.3333)\n",
      "tensor(57.1429)\n"
     ]
    }
   ],
   "source": [
    "input = torch.tensor([\n",
    "    [-1,  1, -1],\n",
    "    [-1,  1, -1],\n",
    "    [-1,  1, -1],\n",
    "], dtype=torch.float) * 100\n",
    "target = torch.tensor([0,0,1], dtype=torch.long)\n",
    "correctness = target == torch.max(input, dim=1)[1].type(torch.long)\n",
    "weights = torch.tensor([1,5,1], dtype=torch.float)\n",
    "\n",
    "ce_noreduce = nn.CrossEntropyLoss(weight=weights, reduce=False)\n",
    "ce_reduce = nn.CrossEntropyLoss(weight=weights, reduce=True, size_average=True)\n",
    "\n",
    "loss1 = ce_noreduce(input, target)\n",
    "loss2 = ce_reduce(input, target)\n",
    "\n",
    "print(correctness)\n",
    "print(loss1)\n",
    "print(loss1.mean())\n",
    "print(loss2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:babble]",
   "language": "python",
   "name": "conda-env-babble-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
