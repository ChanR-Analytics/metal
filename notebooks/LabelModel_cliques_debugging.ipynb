{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging the `LabelModel` with deps + higher-order cliques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from synthetic.generate import SingleTaskTreeDepsGenerator\n",
    "from metal.label_model import LabelModel\n",
    "from metal.label_model.utils import (\n",
    "    compute_mu,\n",
    "    compute_covariance,\n",
    "    compute_inv_covariance,\n",
    "    print_matrix,\n",
    "    visualize_matrix\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic dataset\n",
    "np.random.seed(2)\n",
    "N = 10000\n",
    "M = 20\n",
    "K = 2\n",
    "EDGE_PROB=0.25\n",
    "data = SingleTaskTreeDepsGenerator(N, M, k=K, edge_prob=EDGE_PROB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the `LabelModel`\n",
    "\n",
    "Note that:\n",
    "* The `train` method assembles other data structures, such as the dependencies junction tree, etc.\n",
    "* The `higher_order_cliques` kwarg controls whether or not to include them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing O^{-1}...\n",
      "Estimating Z...\n",
      "[Epoch 0] Loss: 14513.245117\n",
      "[Epoch 5000] Loss: 437.262787\n",
      "[Epoch 10000] Loss: 437.262787\n",
      "[Epoch 15000] Loss: 437.262787\n",
      "[Epoch 20000] Loss: 437.262787\n",
      "[Epoch 25000] Loss: 437.262787\n",
      "[Epoch 30000] Loss: 437.262787\n",
      "[Epoch 35000] Loss: 437.262787\n",
      "[Epoch 40000] Loss: 437.262787\n"
     ]
    }
   ],
   "source": [
    "lm = LabelModel(k=data.k, class_balance=data.p)\n",
    "\n",
    "lm.train(\n",
    "    data.L,\n",
    "    deps=data.E,\n",
    "    all_unary_cliques=True,\n",
    "    higher_order_cliques=True,\n",
    "    n_epochs=50000,\n",
    "    print_every=5000,\n",
    "    lr=0.0001,\n",
    "    l2=0\n",
    ")\n",
    "\n",
    "# Test against the true parameter values\n",
    "mu_est = lm.mu.detach().numpy()\n",
    "mu = compute_mu(lm._get_augmented_label_matrix(data.L.todense()), data.Y, K, data.p)\n",
    "print(f\"Average absolute error: {np.mean(np.abs(mu_est - mu))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Break symmetry by initializing $\\mu$ properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6447.408"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the condition number\n",
    "O = lm.O.numpy()\n",
    "np.linalg.cond(O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'start_index': 0, 'end_index': 2, 'max_cliques': {3}},\n",
       " 1: {'start_index': 2, 'end_index': 4, 'max_cliques': {3}},\n",
       " 2: {'start_index': 4, 'end_index': 6, 'max_cliques': {13}},\n",
       " 3: {'start_index': 6, 'end_index': 8, 'max_cliques': {5}},\n",
       " 4: {'start_index': 8, 'end_index': 10, 'max_cliques': {9}},\n",
       " 5: {'start_index': 10, 'end_index': 12, 'max_cliques': {7}},\n",
       " 6: {'start_index': 12, 'end_index': 14, 'max_cliques': {7}},\n",
       " 7: {'start_index': 14, 'end_index': 16, 'max_cliques': {13}},\n",
       " 8: {'start_index': 16, 'end_index': 18, 'max_cliques': {4}},\n",
       " 9: {'start_index': 18, 'end_index': 20, 'max_cliques': {2}},\n",
       " 10: {'start_index': 20, 'end_index': 22, 'max_cliques': {6}},\n",
       " 11: {'start_index': 22, 'end_index': 24, 'max_cliques': {0}},\n",
       " 12: {'start_index': 24, 'end_index': 26, 'max_cliques': {15}},\n",
       " 13: {'start_index': 26, 'end_index': 28, 'max_cliques': {10}},\n",
       " 14: {'start_index': 28, 'end_index': 30, 'max_cliques': {1}},\n",
       " 15: {'start_index': 30, 'end_index': 32, 'max_cliques': {12}},\n",
       " 16: {'start_index': 32, 'end_index': 34, 'max_cliques': {14}},\n",
       " 17: {'start_index': 34, 'end_index': 36, 'max_cliques': {9}},\n",
       " 18: {'start_index': 36, 'end_index': 38, 'max_cliques': {8}},\n",
       " 19: {'start_index': 38, 'end_index': 40, 'max_cliques': {11}},\n",
       " (0, 1): {'start_index': 40, 'end_index': 44, 'max_cliques': {3}},\n",
       " (5, 6): {'start_index': 44, 'end_index': 48, 'max_cliques': {7}},\n",
       " (17, 4): {'start_index': 48, 'end_index': 52, 'max_cliques': {9}},\n",
       " (2, 7): {'start_index': 52, 'end_index': 56, 'max_cliques': {13}}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.c_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying to solve with `scipy.optimize.minimize`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "O_inv = lm.O_inv.numpy()\n",
    "mask = lm.mask.numpy()\n",
    "\n",
    "z0 = np.random.randn(lm.d * lm.k)\n",
    "\n",
    "def objective_fn(z):\n",
    "    Z = z.reshape(-1, data.k)\n",
    "    return np.linalg.norm( (O_inv + Z @ Z.T) * mask )**2\n",
    "\n",
    "def gradient_fn(z):\n",
    "    Z = z.reshape(-1, data.k)\n",
    "    X = (O_inv + Z @ Z.T) * mask\n",
    "    return np.ravel(X @ Z)\n",
    "\n",
    "res = minimize(objective_fn, z0, jac=gradient_fn, method='BFGS')\n",
    "Z = res['x'].reshape(-1, data.k)\n",
    "res['fun']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "O = lm.O.numpy()\n",
    "P = lm.P.numpy()\n",
    "I_k = np.eye(data.k)\n",
    "Q = O @ Z @ np.linalg.inv(I_k + Z.T @ O @ Z) @ Z.T @ O\n",
    "\n",
    "mu0 = np.random.randn(lm.d * lm.k)\n",
    "\n",
    "def objective_fn_2(mu):\n",
    "    M = mu.reshape(-1, data.k)\n",
    "    return np.linalg.norm(Q - M @ P @ M.T)**2 + np.linalg.norm(np.sum(M @ P, 1) - np.diag(O))**2\n",
    "\n",
    "res_2 = minimize(objective_fn_2, mu0, method='BFGS')\n",
    "M = res_2['x'].reshape(-1, data.k)\n",
    "res_2['fun']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test against the true parameter values\n",
    "print(f\"Average absolute error: {np.mean(np.abs(M - mu))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the inverse covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = compute_inv_covariance(\n",
    "    lm._get_augmented_label_matrix(data.L.todense()),\n",
    "    data.Y,\n",
    "    data.k,\n",
    "    data.p\n",
    ")\n",
    "visualize_matrix(np.abs(J))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_matrix(lm.mask.numpy(), fig_size=[5,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "O_inv = lm.O_inv.numpy()\n",
    "Z = lm.Z.detach().numpy()\n",
    "mask = lm.mask.numpy()\n",
    "visualize_matrix(np.abs((O_inv + Z@Z.T) * mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at the internal 'bookkeeping' of cliques..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.c_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependency edge weights\n",
    "[((i,j), data.theta[(i,j)]) for i,j in data.E]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (MeTaL)",
   "language": "python",
   "name": "metal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
