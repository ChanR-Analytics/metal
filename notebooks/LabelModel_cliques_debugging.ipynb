{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging the `LabelModel` with deps + higher-order cliques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import mpmath\n",
    "\n",
    "from synthetic.generate import SingleTaskTreeDepsGenerator\n",
    "from metal.label_model import LabelModel\n",
    "from metal.label_model.utils import (\n",
    "    compute_mu,\n",
    "    compute_covariance,\n",
    "    compute_inv_covariance,\n",
    "    print_matrix,\n",
    "    visualize_matrix\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic dataset\n",
    "np.random.seed(1)\n",
    "N = 10000\n",
    "M = 20\n",
    "K = 2\n",
    "EDGE_PROB=0.5\n",
    "data = SingleTaskTreeDepsGenerator(N, M, k=K, edge_prob=EDGE_PROB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the `LabelModel`\n",
    "\n",
    "Note that:\n",
    "* The `train` method assembles other data structures, such as the dependencies junction tree, etc.\n",
    "* The `higher_order_cliques` kwarg controls whether or not to include them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing O^{-1}...\n",
      "Warning: O is ill-conditioned: kappa(O) = 10673.45.\n",
      "Estimating Z...\n",
      "[Epoch 0] Loss: 458357.343750\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Loss is NaN. Consider reducing learning rate.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ef351bbedae2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0ml2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/metal/metal/label_model/label_model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, L, deps, **kwargs)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'verbose'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Estimating Z...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_inv_Z\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_Q\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/metal/metal/label_model/label_model.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, loss_fn)\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'l2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss is NaN. Consider reducing learning rate.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Loss is NaN. Consider reducing learning rate."
     ]
    }
   ],
   "source": [
    "lm = LabelModel(k=data.k, class_balance=data.p)\n",
    "\n",
    "lm.train(\n",
    "    data.L,\n",
    "    deps=data.E,\n",
    "    all_unary_cliques=True,\n",
    "    higher_order_cliques=True,\n",
    "    n_epochs=50000,\n",
    "    print_every=5000,\n",
    "    lr=0.001,\n",
    "    l2=0\n",
    ")\n",
    "\n",
    "# Test against the true parameter values\n",
    "mu_est = lm.mu.detach().numpy()\n",
    "mu = compute_mu(lm._get_augmented_label_matrix(data.L.todense()), data.Y, K, data.p)\n",
    "print(f\"Average absolute error: {np.mean(np.abs(mu_est - mu))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODOs:\n",
    "* Break symmetry by initializing $\\mu$ properly\n",
    "* Try shuffling order of cliques?\n",
    "* Try splitting into just nodes, just maximal cliques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "311.33572"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the condition number\n",
    "O = lm.O.numpy()\n",
    "np.linalg.cond(O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.c_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying to solve with `scipy.optimize.minimize`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "O_inv = lm.O_inv.numpy()\n",
    "mask = lm.mask.numpy()\n",
    "\n",
    "z0 = np.random.randn(lm.d * lm.k)\n",
    "\n",
    "def objective_fn(z):\n",
    "    Z = z.reshape(-1, data.k)\n",
    "    return np.linalg.norm( (O_inv + Z @ Z.T) * mask )**2\n",
    "\n",
    "def gradient_fn(z):\n",
    "    Z = z.reshape(-1, data.k)\n",
    "    X = (O_inv + Z @ Z.T) * mask\n",
    "    return np.ravel(X @ Z)\n",
    "\n",
    "res = minimize(objective_fn, z0, jac=gradient_fn, method='BFGS')\n",
    "Z = res['x'].reshape(-1, data.k)\n",
    "res['fun']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "O = lm.O.numpy()\n",
    "P = lm.P.numpy()\n",
    "I_k = np.eye(data.k)\n",
    "Q = O @ Z @ np.linalg.inv(I_k + Z.T @ O @ Z) @ Z.T @ O\n",
    "\n",
    "mu0 = np.random.randn(lm.d * lm.k)\n",
    "\n",
    "def objective_fn_2(mu):\n",
    "    M = mu.reshape(-1, data.k)\n",
    "    return np.linalg.norm(Q - M @ P @ M.T)**2 + np.linalg.norm(np.sum(M @ P, 1) - np.diag(O))**2\n",
    "\n",
    "res_2 = minimize(objective_fn_2, mu0, method='BFGS')\n",
    "M = res_2['x'].reshape(-1, data.k)\n",
    "res_2['fun']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test against the true parameter values\n",
    "print(f\"Average absolute error: {np.mean(np.abs(M - mu))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the inverse covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = compute_inv_covariance(\n",
    "    lm._get_augmented_label_matrix(data.L.todense()),\n",
    "    data.Y,\n",
    "    data.k,\n",
    "    data.p\n",
    ")\n",
    "visualize_matrix(np.abs(J))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_matrix(lm.mask.numpy(), fig_size=[5,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "O_inv = lm.O_inv.numpy()\n",
    "Z = lm.Z.detach().numpy()\n",
    "mask = lm.mask.numpy()\n",
    "visualize_matrix(np.abs((O_inv + Z@Z.T) * mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at the internal 'bookkeeping' of cliques..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.c_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependency edge weights\n",
    "[((i,j), data.theta[(i,j)]) for i,j in data.E]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (MeTaL)",
   "language": "python",
   "name": "metal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
