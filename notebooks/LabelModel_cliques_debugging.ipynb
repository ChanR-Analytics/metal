{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging the `LabelModel` with deps + higher-order cliques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append(\"../\") # go to parent dir\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import mpmath\n",
    "\n",
    "from synthetic.generate import SingleTaskTreeDepsGenerator\n",
    "from metal.label_model import LabelModel\n",
    "from metal.label_model.utils import (\n",
    "    compute_mu,\n",
    "    compute_covariance,\n",
    "    compute_inv_covariance,\n",
    "    print_matrix,\n",
    "    visualize_matrix\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1)   [0.92256582 0.51148433]\n",
      "(0, 2)   [0.48762871 0.94521501]\n",
      "(1, 1)   [0.80055031 0.74437346]\n",
      "(1, 2)   [0.82248175 0.18352073]\n",
      "(2, 1)   [0.56633729 0.87851823]\n",
      "(2, 2)   [0.84623222 0.84664302]\n",
      "(3, 1)   [0.34574498 0.15331888]\n",
      "(3, 2)   [0.70347524 0.63375897]\n",
      "(4, 1)   [0.70448869 0.47060909]\n",
      "(4, 2)   [0.27779581 0.36066668]\n",
      "(5, 1)   [0.22790812 0.80498303]\n",
      "(5, 2)   [0.47128496 0.13075418]\n",
      "(6, 1)   [0.66162699 0.69457216]\n",
      "(6, 2)   [0.36864577 0.50152106]\n",
      "(7, 1)   [0.29991209 0.16602775]\n",
      "(7, 2)   [0.52231467 0.18655503]\n",
      "(8, 1)   [0.91303315 0.20754142]\n",
      "(8, 2)   [0.57231944 0.1752607 ]\n",
      "(9, 1)   [0.9251752  0.91940354]\n",
      "(9, 2)   [0.3690371  0.62595021]\n",
      "((0, 1), 1, 1)   [0.60932082 0.65254449]\n",
      "((0, 1), 1, 2)   [0.96088209 0.33488108]\n",
      "((0, 1), 2, 1)   [0.30791388 0.58010364]\n",
      "((0, 1), 2, 2)   [0.95494432 0.54375363]\n",
      "((1, 2), 1, 1)   [0.58654046 0.78893659]\n",
      "((1, 2), 1, 2)   [0.14081116 0.22596951]\n",
      "((1, 2), 2, 1)   [0.81316323 0.12682122]\n",
      "((1, 2), 2, 2)   [0.89481293 0.58670937]\n",
      "((0, 3), 1, 1)   [0.50318216 0.90292228]\n",
      "((0, 3), 1, 2)   [0.43982591 0.58458222]\n",
      "((0, 3), 2, 1)   [0.68706899 0.42513492]\n",
      "((0, 3), 2, 2)   [0.61390771 0.67405284]\n",
      "((0, 4), 1, 1)   [0.2136834  0.72118413]\n",
      "((0, 4), 1, 2)   [0.68297446 0.41854518]\n",
      "((0, 4), 2, 1)   [0.78690975 0.42087855]\n",
      "((0, 4), 2, 2)   [0.77750952 0.89320765]\n",
      "((4, 5), 1, 1)   [0.11050227 0.54829816]\n",
      "((4, 5), 1, 2)   [0.16641281 0.80825633]\n",
      "((4, 5), 2, 1)   [0.1576606  0.41977933]\n",
      "((4, 5), 2, 2)   [0.94765325 0.44182296]\n",
      "((2, 6), 1, 1)   [0.78662807 0.7944355 ]\n",
      "((2, 6), 1, 2)   [0.37122445 0.79546523]\n",
      "((2, 6), 2, 1)   [0.23763684 0.62077054]\n",
      "((2, 6), 2, 2)   [0.1081072  0.73813827]\n",
      "((5, 7), 1, 1)   [0.52357673 0.78813331]\n",
      "((5, 7), 1, 2)   [0.52065341 0.34210095]\n",
      "((5, 7), 2, 1)   [0.84852333 0.59619245]\n",
      "((5, 7), 2, 2)   [0.16307335 0.52522753]\n",
      "((3, 8), 1, 1)   [0.76848835 0.27276047]\n",
      "((3, 8), 1, 2)   [0.51788035 0.30732653]\n",
      "((3, 8), 2, 1)   [0.55742278 0.28771148]\n",
      "((3, 8), 2, 2)   [0.14437382 0.56697569]\n",
      "((2, 9), 1, 1)   [0.25505052 0.45668196]\n",
      "((2, 9), 1, 2)   [0.19662877 0.55882925]\n",
      "((2, 9), 2, 1)   [0.19192171 0.35984605]\n",
      "((2, 9), 2, 2)   [0.30858262 0.97090114]\n",
      "Labeler =  0\n",
      "P(L= 0 , Y= 1 ) =  0.04047851671854997\n",
      "P(L= 1 , Y= 1 ) =  0.5004241979692685\n",
      "P(L= 2 , Y= 1 ) =  0.45909728531218147\n",
      "Labeler =  1\n",
      "P(L= 0 , Y= 1 ) =  0.054972922407379936\n",
      "P(L= 1 , Y= 1 ) =  0.2710054320807368\n",
      "P(L= 2 , Y= 1 ) =  0.674021645511883\n",
      "Labeler =  2\n",
      "P(L= 0 , Y= 1 ) =  0.07072115597568643\n",
      "P(L= 1 , Y= 1 ) =  0.49940802970620424\n",
      "P(L= 2 , Y= 1 ) =  0.4298708143181091\n",
      "Labeler =  3\n",
      "P(L= 0 , Y= 1 ) =  0.09958232192021327\n",
      "P(L= 1 , Y= 1 ) =  0.43708518030482224\n",
      "P(L= 2 , Y= 1 ) =  0.4633324977749643\n",
      "Labeler =  4\n",
      "P(L= 0 , Y= 1 ) =  0.1075667575860416\n",
      "P(L= 1 , Y= 1 ) =  0.3890364818324785\n",
      "P(L= 2 , Y= 1 ) =  0.5033967605814799\n",
      "Labeler =  5\n",
      "P(L= 0 , Y= 1 ) =  0.13785683117342726\n",
      "P(L= 1 , Y= 1 ) =  0.29401041809295425\n",
      "P(L= 2 , Y= 1 ) =  0.5681327507336182\n",
      "Labeler =  6\n",
      "P(L= 0 , Y= 1 ) =  0.16887700571159062\n",
      "P(L= 1 , Y= 1 ) =  0.528816366599669\n",
      "P(L= 2 , Y= 1 ) =  0.30230662768874017\n",
      "Labeler =  7\n",
      "P(L= 0 , Y= 1 ) =  0.1747944488539912\n",
      "P(L= 1 , Y= 1 ) =  0.4475099107315628\n",
      "P(L= 2 , Y= 1 ) =  0.3776956404144459\n",
      "Labeler =  8\n",
      "P(L= 0 , Y= 1 ) =  0.1282929169056262\n",
      "P(L= 1 , Y= 1 ) =  0.5708641052357463\n",
      "P(L= 2 , Y= 1 ) =  0.30084297785862735\n",
      "Labeler =  9\n",
      "P(L= 0 , Y= 1 ) =  0.1685965425639786\n",
      "P(L= 1 , Y= 1 ) =  0.524162032503679\n",
      "P(L= 2 , Y= 1 ) =  0.3072414249323423\n",
      "Labeler =  0\n",
      "P(L= 0 , Y= 2 ) =  0.04619718615143314\n",
      "P(L= 1 , Y= 2 ) =  0.3875630033513791\n",
      "P(L= 2 , Y= 2 ) =  0.5662398104971877\n",
      "Labeler =  1\n",
      "P(L= 0 , Y= 2 ) =  0.1004293579541635\n",
      "P(L= 1 , Y= 2 ) =  0.6312496480416631\n",
      "P(L= 2 , Y= 2 ) =  0.26832099400417325\n",
      "Labeler =  2\n",
      "P(L= 0 , Y= 2 ) =  0.042897632854839274\n",
      "P(L= 1 , Y= 2 ) =  0.5306996873390036\n",
      "P(L= 2 , Y= 2 ) =  0.4264026798061569\n",
      "Labeler =  3\n",
      "P(L= 0 , Y= 2 ) =  0.1190234997557316\n",
      "P(L= 1 , Y= 2 ) =  0.31247510515335425\n",
      "P(L= 2 , Y= 2 ) =  0.5685013950909141\n",
      "Labeler =  4\n",
      "P(L= 0 , Y= 2 ) =  0.10150876056234127\n",
      "P(L= 1 , Y= 2 ) =  0.4818760258678046\n",
      "P(L= 2 , Y= 2 ) =  0.416615213569854\n",
      "Labeler =  5\n",
      "P(L= 0 , Y= 2 ) =  0.1063365657154413\n",
      "P(L= 1 , Y= 2 ) =  0.5681935540579359\n",
      "P(L= 2 , Y= 2 ) =  0.3254698802266227\n",
      "Labeler =  6\n",
      "P(L= 0 , Y= 2 ) =  0.11971841885445308\n",
      "P(L= 1 , Y= 2 ) =  0.4714441639097386\n",
      "P(L= 2 , Y= 2 ) =  0.4088374172358082\n",
      "Labeler =  7\n",
      "P(L= 0 , Y= 2 ) =  0.20157697214889508\n",
      "P(L= 1 , Y= 2 ) =  0.4504349295456766\n",
      "P(L= 2 , Y= 2 ) =  0.3479880983054284\n",
      "Labeler =  8\n",
      "P(L= 0 , Y= 2 ) =  0.22842999577645826\n",
      "P(L= 1 , Y= 2 ) =  0.35876896097418376\n",
      "P(L= 2 , Y= 2 ) =  0.4128010432493579\n",
      "Labeler =  9\n",
      "P(L= 0 , Y= 2 ) =  0.11720213300958968\n",
      "P(L= 1 , Y= 2 ) =  0.4361198435413552\n",
      "P(L= 2 , Y= 2 ) =  0.44667802344905494\n",
      "Labelers =  (0, 1)\n",
      "P(L_ 0 = 0 , L_ 1 = 0  | Y =  1 ) =  0.00443476016844756\n",
      "P(L_ 0 = 0 , L_ 1 = 1  | Y =  1 ) =  0.014089265143218519\n",
      "P(L_ 0 = 0 , L_ 1 = 2  | Y =  1 ) =  0.021954491406883887\n",
      "P(L_ 0 = 1 , L_ 1 = 0  | Y =  1 ) =  0.025294604507622036\n",
      "P(L_ 0 = 1 , L_ 1 = 1  | Y =  1 ) =  0.14779875277995552\n",
      "P(L_ 0 = 1 , L_ 1 = 2  | Y =  1 ) =  0.3273308406816909\n",
      "P(L_ 0 = 2 , L_ 1 = 0  | Y =  1 ) =  0.02524355773131033\n",
      "P(L_ 0 = 2 , L_ 1 = 1  | Y =  1 ) =  0.10911741415756274\n",
      "P(L_ 0 = 2 , L_ 1 = 2  | Y =  1 ) =  0.32473631342330833\n",
      "Labelers =  (0, 2)\n",
      "P(L_ 0 = 0 , L_ 2 = 0  | Y =  1 ) =  0.003110713023071187\n",
      "P(L_ 0 = 0 , L_ 2 = 1  | Y =  1 ) =  0.020495732974109754\n",
      "P(L_ 0 = 0 , L_ 2 = 2  | Y =  1 ) =  0.016872070721369023\n",
      "P(L_ 0 = 1 , L_ 2 = 0  | Y =  1 ) =  0.035612429851754855\n",
      "P(L_ 0 = 1 , L_ 2 = 1  | Y =  1 ) =  0.25119294846612034\n",
      "P(L_ 0 = 1 , L_ 2 = 2  | Y =  1 ) =  0.2136188196513932\n",
      "P(L_ 0 = 2 , L_ 2 = 0  | Y =  1 ) =  0.03199801310086039\n",
      "P(L_ 0 = 2 , L_ 2 = 1  | Y =  1 ) =  0.22771934826597412\n",
      "P(L_ 0 = 2 , L_ 2 = 2  | Y =  1 ) =  0.19937992394534693\n",
      "Labelers =  (0, 3)\n",
      "P(L_ 0 = 0 , L_ 3 = 0  | Y =  1 ) =  0.006375022734045105\n",
      "P(L_ 0 = 0 , L_ 3 = 1  | Y =  1 ) =  0.015997322374831688\n",
      "P(L_ 0 = 0 , L_ 3 = 2  | Y =  1 ) =  0.018106171609673174\n",
      "P(L_ 0 = 1 , L_ 3 = 0  | Y =  1 ) =  0.05234761658379594\n",
      "P(L_ 0 = 1 , L_ 3 = 1  | Y =  1 ) =  0.2172659698581512\n",
      "P(L_ 0 = 1 , L_ 3 = 2  | Y =  1 ) =  0.23081061152732132\n",
      "P(L_ 0 = 2 , L_ 3 = 0  | Y =  1 ) =  0.04085968260237223\n",
      "P(L_ 0 = 2 , L_ 3 = 1  | Y =  1 ) =  0.20382188807183937\n",
      "P(L_ 0 = 2 , L_ 3 = 2  | Y =  1 ) =  0.21441571463796985\n",
      "Labelers =  (0, 4)\n",
      "P(L_ 0 = 0 , L_ 4 = 0  | Y =  1 ) =  0.007194492243447212\n",
      "P(L_ 0 = 0 , L_ 4 = 1  | Y =  1 ) =  0.016361506173999483\n",
      "P(L_ 0 = 0 , L_ 4 = 2  | Y =  1 ) =  0.01692251830110327\n",
      "P(L_ 0 = 1 , L_ 4 = 0  | Y =  1 ) =  0.05906359642230384\n",
      "P(L_ 0 = 1 , L_ 4 = 1  | Y =  1 ) =  0.16632002429940565\n",
      "P(L_ 0 = 1 , L_ 4 = 2  | Y =  1 ) =  0.2750405772475589\n",
      "P(L_ 0 = 2 , L_ 4 = 0  | Y =  1 ) =  0.041308668920290545\n",
      "P(L_ 0 = 2 , L_ 4 = 1  | Y =  1 ) =  0.2063549513590734\n",
      "P(L_ 0 = 2 , L_ 4 = 2  | Y =  1 ) =  0.21143366503281757\n",
      "Labelers =  (0, 5)\n",
      "P(L_ 0 = 0 , L_ 5 = 0  | Y =  1 ) =  0.00585132549839498\n",
      "P(L_ 0 = 0 , L_ 5 = 1  | Y =  1 ) =  0.012321822174600764\n",
      "P(L_ 0 = 0 , L_ 5 = 2  | Y =  1 ) =  0.022305369045554215\n",
      "P(L_ 0 = 1 , L_ 5 = 0  | Y =  1 ) =  0.06767376693857013\n",
      "P(L_ 0 = 1 , L_ 5 = 1  | Y =  1 ) =  0.14437000026865252\n",
      "P(L_ 0 = 1 , L_ 5 = 2  | Y =  1 ) =  0.28838043076204584\n",
      "P(L_ 0 = 2 , L_ 5 = 0  | Y =  1 ) =  0.06433173873646218\n",
      "P(L_ 0 = 2 , L_ 5 = 1  | Y =  1 ) =  0.13731859564970098\n",
      "P(L_ 0 = 2 , L_ 5 = 2  | Y =  1 ) =  0.25744695092601827\n",
      "Labelers =  (0, 6)\n",
      "P(L_ 0 = 0 , L_ 6 = 0  | Y =  1 ) =  0.006826355788001187\n",
      "P(L_ 0 = 0 , L_ 6 = 1  | Y =  1 ) =  0.021421440063256914\n",
      "P(L_ 0 = 0 , L_ 6 = 2  | Y =  1 ) =  0.012230720867291862\n",
      "P(L_ 0 = 1 , L_ 6 = 0  | Y =  1 ) =  0.0844387412148925\n",
      "P(L_ 0 = 1 , L_ 6 = 1  | Y =  1 ) =  0.2647430453784932\n",
      "P(L_ 0 = 1 , L_ 6 = 2  | Y =  1 ) =  0.15124241137588273\n",
      "P(L_ 0 = 2 , L_ 6 = 0  | Y =  1 ) =  0.07761190870869694\n",
      "P(L_ 0 = 2 , L_ 6 = 1  | Y =  1 ) =  0.24265188115791894\n",
      "P(L_ 0 = 2 , L_ 6 = 2  | Y =  1 ) =  0.13883349544556553\n",
      "Labelers =  (0, 7)\n",
      "P(L_ 0 = 0 , L_ 7 = 0  | Y =  1 ) =  0.0070986694734814365\n",
      "P(L_ 0 = 0 , L_ 7 = 1  | Y =  1 ) =  0.018006524515068845\n",
      "P(L_ 0 = 0 , L_ 7 = 2  | Y =  1 ) =  0.01537332272999968\n",
      "P(L_ 0 = 1 , L_ 7 = 0  | Y =  1 ) =  0.08735833440534942\n",
      "P(L_ 0 = 1 , L_ 7 = 1  | Y =  1 ) =  0.22456995155379214\n",
      "P(L_ 0 = 1 , L_ 7 = 2  | Y =  1 ) =  0.18849591201012697\n",
      "P(L_ 0 = 2 , L_ 7 = 0  | Y =  1 ) =  0.08033744497516035\n",
      "P(L_ 0 = 2 , L_ 7 = 1  | Y =  1 ) =  0.20493343466270197\n",
      "P(L_ 0 = 2 , L_ 7 = 2  | Y =  1 ) =  0.17382640567431923\n",
      "Labelers =  (0, 8)\n",
      "P(L_ 0 = 0 , L_ 8 = 0  | Y =  1 ) =  0.005369359407646461\n",
      "P(L_ 0 = 0 , L_ 8 = 1  | Y =  1 ) =  0.022861290845813863\n",
      "P(L_ 0 = 0 , L_ 8 = 2  | Y =  1 ) =  0.01224786646508964\n",
      "P(L_ 0 = 1 , L_ 8 = 0  | Y =  1 ) =  0.06437988314790367\n",
      "P(L_ 0 = 1 , L_ 8 = 1  | Y =  1 ) =  0.28540515421917645\n",
      "P(L_ 0 = 1 , L_ 8 = 2  | Y =  1 ) =  0.1506391606021884\n",
      "P(L_ 0 = 2 , L_ 8 = 0  | Y =  1 ) =  0.058543674350076055\n",
      "P(L_ 0 = 2 , L_ 8 = 1  | Y =  1 ) =  0.2625976601707561\n",
      "P(L_ 0 = 2 , L_ 8 = 2  | Y =  1 ) =  0.1379559507913493\n",
      "Labelers =  (0, 9)\n",
      "P(L_ 0 = 0 , L_ 9 = 0  | Y =  1 ) =  0.006833363966856995\n",
      "P(L_ 0 = 0 , L_ 9 = 1  | Y =  1 ) =  0.021226917655723827\n",
      "P(L_ 0 = 0 , L_ 9 = 2  | Y =  1 ) =  0.01241823509596914\n",
      "P(L_ 0 = 1 , L_ 9 = 0  | Y =  1 ) =  0.0843779510902171\n",
      "P(L_ 0 = 1 , L_ 9 = 1  | Y =  1 ) =  0.26234675342491265\n",
      "P(L_ 0 = 1 , L_ 9 = 2  | Y =  1 ) =  0.15369949345413864\n",
      "P(L_ 0 = 2 , L_ 9 = 0  | Y =  1 ) =  0.07738522750690448\n",
      "P(L_ 0 = 2 , L_ 9 = 1  | Y =  1 ) =  0.24058836142304235\n",
      "P(L_ 0 = 2 , L_ 9 = 2  | Y =  1 ) =  0.14112369638223451\n",
      "Labelers =  (1, 2)\n",
      "P(L_ 1 = 0 , L_ 2 = 0  | Y =  1 ) =  0.007007230577925494\n",
      "P(L_ 1 = 0 , L_ 2 = 1  | Y =  1 ) =  0.02506556475825018\n",
      "P(L_ 1 = 0 , L_ 2 = 2  | Y =  1 ) =  0.022900127071204264\n",
      "P(L_ 1 = 1 , L_ 2 = 0  | Y =  1 ) =  0.024212072119523052\n",
      "P(L_ 1 = 1 , L_ 2 = 1  | Y =  1 ) =  0.15570204939296367\n",
      "P(L_ 1 = 1 , L_ 2 = 2  | Y =  1 ) =  0.09109131056825005\n",
      "P(L_ 1 = 2 , L_ 2 = 0  | Y =  1 ) =  0.03950185327823789\n",
      "P(L_ 1 = 2 , L_ 2 = 1  | Y =  1 ) =  0.31864041555499034\n",
      "P(L_ 1 = 2 , L_ 2 = 2  | Y =  1 ) =  0.31587937667865484\n",
      "Labelers =  (1, 3)\n",
      "P(L_ 1 = 0 , L_ 3 = 0  | Y =  1 ) =  0.005591094724544213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(L_ 1 = 0 , L_ 3 = 1  | Y =  1 ) =  0.023941825012383323\n",
      "P(L_ 1 = 0 , L_ 3 = 2  | Y =  1 ) =  0.025440002670452395\n",
      "P(L_ 1 = 1 , L_ 3 = 0  | Y =  1 ) =  0.02739110334323508\n",
      "P(L_ 1 = 1 , L_ 3 = 1  | Y =  1 ) =  0.11818100820689492\n",
      "P(L_ 1 = 1 , L_ 3 = 2  | Y =  1 ) =  0.12543332053060682\n",
      "P(L_ 1 = 2 , L_ 3 = 0  | Y =  1 ) =  0.06660012385243398\n",
      "P(L_ 1 = 2 , L_ 3 = 1  | Y =  1 ) =  0.294962347085544\n",
      "P(L_ 1 = 2 , L_ 3 = 2  | Y =  1 ) =  0.31245917457390515\n",
      "Labelers =  (1, 4)\n",
      "P(L_ 1 = 0 , L_ 4 = 0  | Y =  1 ) =  0.0060450301739202504\n",
      "P(L_ 1 = 0 , L_ 4 = 1  | Y =  1 ) =  0.02154587503702306\n",
      "P(L_ 1 = 0 , L_ 4 = 2  | Y =  1 ) =  0.027382017196436622\n",
      "P(L_ 1 = 1 , L_ 4 = 0  | Y =  1 ) =  0.029766592544020008\n",
      "P(L_ 1 = 1 , L_ 4 = 1  | Y =  1 ) =  0.10386309390092835\n",
      "P(L_ 1 = 1 , L_ 4 = 2  | Y =  1 ) =  0.13737574563578847\n",
      "P(L_ 1 = 2 , L_ 4 = 0  | Y =  1 ) =  0.07175513486810133\n",
      "P(L_ 1 = 2 , L_ 4 = 1  | Y =  1 ) =  0.26362751289452707\n",
      "P(L_ 1 = 2 , L_ 4 = 2  | Y =  1 ) =  0.33863899774925477\n",
      "Labelers =  (1, 5)\n",
      "P(L_ 1 = 0 , L_ 5 = 0  | Y =  1 ) =  0.007599015685502336\n",
      "P(L_ 1 = 0 , L_ 5 = 1  | Y =  1 ) =  0.016197822714434894\n",
      "P(L_ 1 = 0 , L_ 5 = 2  | Y =  1 ) =  0.031176084007442692\n",
      "P(L_ 1 = 1 , L_ 5 = 0  | Y =  1 ) =  0.03731414870035586\n",
      "P(L_ 1 = 1 , L_ 5 = 1  | Y =  1 ) =  0.07956570155914894\n",
      "P(L_ 1 = 1 , L_ 5 = 2  | Y =  1 ) =  0.154125581821232\n",
      "P(L_ 1 = 2 , L_ 5 = 0  | Y =  1 ) =  0.0929436667875691\n",
      "P(L_ 1 = 2 , L_ 5 = 1  | Y =  1 ) =  0.19824689381937038\n",
      "P(L_ 1 = 2 , L_ 5 = 2  | Y =  1 ) =  0.38283108490494355\n",
      "Labelers =  (1, 6)\n",
      "P(L_ 1 = 0 , L_ 6 = 0  | Y =  1 ) =  0.009526136592582881\n",
      "P(L_ 1 = 0 , L_ 6 = 1  | Y =  1 ) =  0.028712493193954768\n",
      "P(L_ 1 = 0 , L_ 6 = 2  | Y =  1 ) =  0.016734292620842285\n",
      "P(L_ 1 = 1 , L_ 6 = 0  | Y =  1 ) =  0.04467484582787258\n",
      "P(L_ 1 = 1 , L_ 6 = 1  | Y =  1 ) =  0.14500972314039762\n",
      "P(L_ 1 = 1 , L_ 6 = 2  | Y =  1 ) =  0.08132086311246653\n",
      "P(L_ 1 = 2 , L_ 6 = 0  | Y =  1 ) =  0.11467602329113516\n",
      "P(L_ 1 = 2 , L_ 6 = 1  | Y =  1 ) =  0.35509415026531654\n",
      "P(L_ 1 = 2 , L_ 6 = 2  | Y =  1 ) =  0.20425147195543134\n",
      "Labelers =  (1, 7)\n",
      "P(L_ 1 = 0 , L_ 7 = 0  | Y =  1 ) =  0.009610732229828\n",
      "P(L_ 1 = 0 , L_ 7 = 1  | Y =  1 ) =  0.024592257970255226\n",
      "P(L_ 1 = 0 , L_ 7 = 2  | Y =  1 ) =  0.020769932207296712\n",
      "P(L_ 1 = 1 , L_ 7 = 0  | Y =  1 ) =  0.0473662929046579\n",
      "P(L_ 1 = 1 , L_ 7 = 1  | Y =  1 ) =  0.12130174561120088\n",
      "P(L_ 1 = 1 , L_ 7 = 2  | Y =  1 ) =  0.10233739356487802\n",
      "P(L_ 1 = 2 , L_ 7 = 0  | Y =  1 ) =  0.11781742371950527\n",
      "P(L_ 1 = 2 , L_ 7 = 1  | Y =  1 ) =  0.3016159071501067\n",
      "P(L_ 1 = 2 , L_ 7 = 2  | Y =  1 ) =  0.2545883146422711\n",
      "Labelers =  (1, 8)\n",
      "P(L_ 1 = 0 , L_ 8 = 0  | Y =  1 ) =  0.007061460645884922\n",
      "P(L_ 1 = 0 , L_ 8 = 1  | Y =  1 ) =  0.031369813391323186\n",
      "P(L_ 1 = 0 , L_ 8 = 2  | Y =  1 ) =  0.016541648370171826\n",
      "P(L_ 1 = 1 , L_ 8 = 0  | Y =  1 ) =  0.03479785668409725\n",
      "P(L_ 1 = 1 , L_ 8 = 1  | Y =  1 ) =  0.15466455272728383\n",
      "P(L_ 1 = 1 , L_ 8 = 2  | Y =  1 ) =  0.08154302266935576\n",
      "P(L_ 1 = 2 , L_ 8 = 0  | Y =  1 ) =  0.08643359957564402\n",
      "P(L_ 1 = 2 , L_ 8 = 1  | Y =  1 ) =  0.38482973911713936\n",
      "P(L_ 1 = 2 , L_ 8 = 2  | Y =  1 ) =  0.20275830681909968\n",
      "Labelers =  (1, 9)\n",
      "P(L_ 1 = 0 , L_ 9 = 0  | Y =  1 ) =  0.009377713209707062\n",
      "P(L_ 1 = 0 , L_ 9 = 1  | Y =  1 ) =  0.028735140529409755\n",
      "P(L_ 1 = 0 , L_ 9 = 2  | Y =  1 ) =  0.01686006866826312\n",
      "P(L_ 1 = 1 , L_ 9 = 0  | Y =  1 ) =  0.045873960948062606\n",
      "P(L_ 1 = 1 , L_ 9 = 1  | Y =  1 ) =  0.14274314502957478\n",
      "P(L_ 1 = 1 , L_ 9 = 2  | Y =  1 ) =  0.08238832610309937\n",
      "P(L_ 1 = 2 , L_ 9 = 0  | Y =  1 ) =  0.1133448684062089\n",
      "P(L_ 1 = 2 , L_ 9 = 1  | Y =  1 ) =  0.35268374694469434\n",
      "P(L_ 1 = 2 , L_ 9 = 2  | Y =  1 ) =  0.2079930301609798\n",
      "Labelers =  (2, 3)\n",
      "P(L_ 2 = 0 , L_ 3 = 0  | Y =  1 ) =  0.007063026870678213\n",
      "P(L_ 2 = 0 , L_ 3 = 1  | Y =  1 ) =  0.030896902354096062\n",
      "P(L_ 2 = 0 , L_ 3 = 2  | Y =  1 ) =  0.03276122675091217\n",
      "P(L_ 2 = 1 , L_ 3 = 0  | Y =  1 ) =  0.04977134945438835\n",
      "P(L_ 2 = 1 , L_ 3 = 1  | Y =  1 ) =  0.21825766165588092\n",
      "P(L_ 2 = 1 , L_ 3 = 2  | Y =  1 ) =  0.2313790185959349\n",
      "P(L_ 2 = 2 , L_ 3 = 0  | Y =  1 ) =  0.04274794559514671\n",
      "P(L_ 2 = 2 , L_ 3 = 1  | Y =  1 ) =  0.18793061629484523\n",
      "P(L_ 2 = 2 , L_ 3 = 2  | Y =  1 ) =  0.19919225242811725\n",
      "Labelers =  (2, 4)\n",
      "P(L_ 2 = 0 , L_ 4 = 0  | Y =  1 ) =  0.007635234410073192\n",
      "P(L_ 2 = 0 , L_ 4 = 1  | Y =  1 ) =  0.027475896020710364\n",
      "P(L_ 2 = 0 , L_ 4 = 2  | Y =  1 ) =  0.03561002554490288\n",
      "P(L_ 2 = 1 , L_ 4 = 0  | Y =  1 ) =  0.05378013405743952\n",
      "P(L_ 2 = 1 , L_ 4 = 1  | Y =  1 ) =  0.19412567091365873\n",
      "P(L_ 2 = 1 , L_ 4 = 2  | Y =  1 ) =  0.2515022247351059\n",
      "P(L_ 2 = 2 , L_ 4 = 0  | Y =  1 ) =  0.046151389118528875\n",
      "P(L_ 2 = 2 , L_ 4 = 1  | Y =  1 ) =  0.16743491489810935\n",
      "P(L_ 2 = 2 , L_ 4 = 2  | Y =  1 ) =  0.21628451030147097\n",
      "Labelers =  (2, 5)\n",
      "P(L_ 2 = 0 , L_ 5 = 0  | Y =  1 ) =  0.009749406835011661\n",
      "P(L_ 2 = 0 , L_ 5 = 1  | Y =  1 ) =  0.020791716816139314\n",
      "P(L_ 2 = 0 , L_ 5 = 2  | Y =  1 ) =  0.04018003232453546\n",
      "P(L_ 2 = 1 , L_ 5 = 0  | Y =  1 ) =  0.06884180021310699\n",
      "P(L_ 2 = 1 , L_ 5 = 1  | Y =  1 ) =  0.14681909905015614\n",
      "P(L_ 2 = 1 , L_ 5 = 2  | Y =  1 ) =  0.283747130442941\n",
      "P(L_ 2 = 2 , L_ 5 = 0  | Y =  1 ) =  0.05926562412530864\n",
      "P(L_ 2 = 2 , L_ 5 = 1  | Y =  1 ) =  0.12639960222665875\n",
      "P(L_ 2 = 2 , L_ 5 = 2  | Y =  1 ) =  0.2442055879661417\n",
      "Labelers =  (2, 6)\n",
      "P(L_ 2 = 0 , L_ 6 = 0  | Y =  1 ) =  0.016132687724777568\n",
      "P(L_ 2 = 0 , L_ 6 = 1  | Y =  1 ) =  0.03126422570075099\n",
      "P(L_ 2 = 0 , L_ 6 = 2  | Y =  1 ) =  0.023324242550157873\n",
      "P(L_ 2 = 1 , L_ 6 = 0  | Y =  1 ) =  0.06793423366189898\n",
      "P(L_ 2 = 1 , L_ 6 = 1  | Y =  1 ) =  0.28910650194937937\n",
      "P(L_ 2 = 1 , L_ 6 = 2  | Y =  1 ) =  0.1423672940949259\n",
      "P(L_ 2 = 2 , L_ 6 = 0  | Y =  1 ) =  0.08481008432491408\n",
      "P(L_ 2 = 2 , L_ 6 = 1  | Y =  1 ) =  0.2084456389495386\n",
      "P(L_ 2 = 2 , L_ 6 = 2  | Y =  1 ) =  0.13661509104365643\n",
      "Labelers =  (2, 7)\n",
      "P(L_ 2 = 0 , L_ 7 = 0  | Y =  1 ) =  0.012361665929262505\n",
      "P(L_ 2 = 0 , L_ 7 = 1  | Y =  1 ) =  0.031648562812607514\n",
      "P(L_ 2 = 0 , L_ 7 = 2  | Y =  1 ) =  0.026710927233816413\n",
      "P(L_ 2 = 1 , L_ 7 = 0  | Y =  1 ) =  0.0872933192938185\n",
      "P(L_ 2 = 1 , L_ 7 = 1  | Y =  1 ) =  0.22349264436843003\n",
      "P(L_ 2 = 1 , L_ 7 = 2  | Y =  1 ) =  0.18862206604395568\n",
      "P(L_ 2 = 2 , L_ 7 = 0  | Y =  1 ) =  0.07513946363091016\n",
      "P(L_ 2 = 2 , L_ 7 = 1  | Y =  1 ) =  0.1923687035505253\n",
      "P(L_ 2 = 2 , L_ 7 = 2  | Y =  1 ) =  0.16236264713667367\n",
      "Labelers =  (2, 8)\n",
      "P(L_ 2 = 0 , L_ 8 = 0  | Y =  1 ) =  0.009074546299726545\n",
      "P(L_ 2 = 0 , L_ 8 = 1  | Y =  1 ) =  0.04037001251301695\n",
      "P(L_ 2 = 0 , L_ 8 = 2  | Y =  1 ) =  0.021276597162942938\n",
      "P(L_ 2 = 1 , L_ 8 = 0  | Y =  1 ) =  0.06407339598899692\n",
      "P(L_ 2 = 1 , L_ 8 = 1  | Y =  1 ) =  0.2850899751632335\n",
      "P(L_ 2 = 1 , L_ 8 = 2  | Y =  1 ) =  0.1502446585539738\n",
      "P(L_ 2 = 2 , L_ 8 = 0  | Y =  1 ) =  0.05514497461690272\n",
      "P(L_ 2 = 2 , L_ 8 = 1  | Y =  1 ) =  0.24540411755949598\n",
      "P(L_ 2 = 2 , L_ 8 = 2  | Y =  1 ) =  0.12932172214171048\n",
      "Labelers =  (2, 9)\n",
      "P(L_ 2 = 0 , L_ 9 = 0  | Y =  1 ) =  0.014233471083507202\n",
      "P(L_ 2 = 0 , L_ 9 = 1  | Y =  1 ) =  0.03590122834311547\n",
      "P(L_ 2 = 0 , L_ 9 = 2  | Y =  1 ) =  0.020586456549063766\n",
      "P(L_ 2 = 1 , L_ 9 = 0  | Y =  1 ) =  0.083017047965294\n",
      "P(L_ 2 = 1 , L_ 9 = 1  | Y =  1 ) =  0.2702295281061424\n",
      "P(L_ 2 = 1 , L_ 9 = 2  | Y =  1 ) =  0.1461614536347678\n",
      "P(L_ 2 = 2 , L_ 9 = 0  | Y =  1 ) =  0.07134602351517741\n",
      "P(L_ 2 = 2 , L_ 9 = 1  | Y =  1 ) =  0.21803127605442102\n",
      "P(L_ 2 = 2 , L_ 9 = 2  | Y =  1 ) =  0.14049351474851074\n",
      "Labelers =  (3, 4)\n",
      "P(L_ 3 = 0 , L_ 4 = 0  | Y =  1 ) =  0.010987980401522327\n",
      "P(L_ 3 = 0 , L_ 4 = 1  | Y =  1 ) =  0.03834055307329566\n",
      "P(L_ 3 = 0 , L_ 4 = 2  | Y =  1 ) =  0.0502537884453953\n",
      "P(L_ 3 = 1 , L_ 4 = 0  | Y =  1 ) =  0.046826056381208146\n",
      "P(L_ 3 = 1 , L_ 4 = 1  | Y =  1 ) =  0.17029007261064535\n",
      "P(L_ 3 = 1 , L_ 4 = 2  | Y =  1 ) =  0.2199690513129687\n",
      "P(L_ 3 = 2 , L_ 4 = 0  | Y =  1 ) =  0.04975272080331113\n",
      "P(L_ 3 = 2 , L_ 4 = 1  | Y =  1 ) =  0.1804058561485375\n",
      "P(L_ 3 = 2 , L_ 4 = 2  | Y =  1 ) =  0.23317392082311578\n",
      "Labelers =  (3, 5)\n",
      "P(L_ 3 = 0 , L_ 5 = 0  | Y =  1 ) =  0.013726177146763798\n",
      "P(L_ 3 = 0 , L_ 5 = 1  | Y =  1 ) =  0.029263982970927933\n",
      "P(L_ 3 = 0 , L_ 5 = 2  | Y =  1 ) =  0.05659216180252155\n",
      "P(L_ 3 = 1 , L_ 5 = 0  | Y =  1 ) =  0.06025482752984056\n",
      "P(L_ 3 = 1 , L_ 5 = 1  | Y =  1 ) =  0.12851412742194576\n",
      "P(L_ 3 = 1 , L_ 5 = 2  | Y =  1 ) =  0.24831622535303588\n",
      "P(L_ 3 = 2 , L_ 5 = 0  | Y =  1 ) =  0.06387582649682291\n",
      "P(L_ 3 = 2 , L_ 5 = 1  | Y =  1 ) =  0.13623230770008052\n",
      "P(L_ 3 = 2 , L_ 5 = 2  | Y =  1 ) =  0.26322436357806095\n",
      "Labelers =  (3, 6)\n",
      "P(L_ 3 = 0 , L_ 6 = 0  | Y =  1 ) =  0.016815397005235686\n",
      "P(L_ 3 = 0 , L_ 6 = 1  | Y =  1 ) =  0.05266356469231764\n",
      "P(L_ 3 = 0 , L_ 6 = 2  | Y =  1 ) =  0.03010336022265995\n",
      "P(L_ 3 = 1 , L_ 6 = 0  | Y =  1 ) =  0.07381480100199458\n",
      "P(L_ 3 = 1 , L_ 6 = 1  | Y =  1 ) =  0.23113594646685054\n",
      "P(L_ 3 = 1 , L_ 6 = 2  | Y =  1 ) =  0.132134432835977\n",
      "P(L_ 3 = 2 , L_ 6 = 0  | Y =  1 ) =  0.07824680770436035\n",
      "P(L_ 3 = 2 , L_ 6 = 1  | Y =  1 ) =  0.24501685544050078\n",
      "P(L_ 3 = 2 , L_ 6 = 2  | Y =  1 ) =  0.14006883463010317\n",
      "Labelers =  (3, 7)\n",
      "P(L_ 3 = 0 , L_ 7 = 0  | Y =  1 ) =  0.017406265352885343\n",
      "P(L_ 3 = 0 , L_ 7 = 1  | Y =  1 ) =  0.04456643460322895\n",
      "P(L_ 3 = 0 , L_ 7 = 2  | Y =  1 ) =  0.03760962196409899\n",
      "P(L_ 3 = 1 , L_ 7 = 0  | Y =  1 ) =  0.07640003723977835\n",
      "P(L_ 3 = 1 , L_ 7 = 1  | Y =  1 ) =  0.19559909061805097\n",
      "P(L_ 3 = 1 , L_ 7 = 2  | Y =  1 ) =  0.16508605244699298\n",
      "P(L_ 3 = 2 , L_ 7 = 0  | Y =  1 ) =  0.0809881462613275\n",
      "P(L_ 3 = 2 , L_ 7 = 1  | Y =  1 ) =  0.20734438551028303\n",
      "P(L_ 3 = 2 , L_ 7 = 2  | Y =  1 ) =  0.1749999660033539\n",
      "Labelers =  (3, 8)\n",
      "P(L_ 3 = 0 , L_ 8 = 0  | Y =  1 ) =  0.018916742915877548\n",
      "P(L_ 3 = 0 , L_ 8 = 1  | Y =  1 ) =  0.04713805083917836\n",
      "P(L_ 3 = 0 , L_ 8 = 2  | Y =  1 ) =  0.033527528165157354\n",
      "P(L_ 3 = 1 , L_ 8 = 0  | Y =  1 ) =  0.04675410757338524\n",
      "P(L_ 3 = 1 , L_ 8 = 1  | Y =  1 ) =  0.2512437570033407\n",
      "P(L_ 3 = 1 , L_ 8 = 2  | Y =  1 ) =  0.1390873157280963\n",
      "P(L_ 3 = 2 , L_ 8 = 0  | Y =  1 ) =  0.0626220664163634\n",
      "P(L_ 3 = 2 , L_ 8 = 1  | Y =  1 ) =  0.27248229739322727\n",
      "P(L_ 3 = 2 , L_ 8 = 2  | Y =  1 ) =  0.12822813396537366\n",
      "Labelers =  (3, 9)\n",
      "P(L_ 3 = 0 , L_ 9 = 0  | Y =  1 ) =  0.016789967053702885\n",
      "P(L_ 3 = 0 , L_ 9 = 1  | Y =  1 ) =  0.05219860801996536\n",
      "P(L_ 3 = 0 , L_ 9 = 2  | Y =  1 ) =  0.030593746846545023\n",
      "P(L_ 3 = 1 , L_ 9 = 0  | Y =  1 ) =  0.0736905399034982\n",
      "P(L_ 3 = 1 , L_ 9 = 1  | Y =  1 ) =  0.22910256248194671\n",
      "P(L_ 3 = 1 , L_ 9 = 2  | Y =  1 ) =  0.13429207791937725\n",
      "P(L_ 3 = 2 , L_ 9 = 0  | Y =  1 ) =  0.07811603560677748\n",
      "P(L_ 3 = 2 , L_ 9 = 1  | Y =  1 ) =  0.24286086200176676\n",
      "P(L_ 3 = 2 , L_ 9 = 2  | Y =  1 ) =  0.14235560016642004\n",
      "Labelers =  (4, 5)\n",
      "P(L_ 4 = 0 , L_ 5 = 0  | Y =  1 ) =  0.020143711144067048\n",
      "P(L_ 4 = 0 , L_ 5 = 1  | Y =  1 ) =  0.03834205781238426\n",
      "P(L_ 4 = 0 , L_ 5 = 2  | Y =  1 ) =  0.04908098862959029\n",
      "P(L_ 4 = 1 , L_ 5 = 0  | Y =  1 ) =  0.06480136502184404\n",
      "P(L_ 4 = 1 , L_ 5 = 1  | Y =  1 ) =  0.13775602887442281\n",
      "P(L_ 4 = 1 , L_ 5 = 2  | Y =  1 ) =  0.18647908793621162\n",
      "P(L_ 4 = 2 , L_ 5 = 0  | Y =  1 ) =  0.05291175500751622\n",
      "P(L_ 4 = 2 , L_ 5 = 1  | Y =  1 ) =  0.11791233140614717\n",
      "P(L_ 4 = 2 , L_ 5 = 2  | Y =  1 ) =  0.33257267416781644\n",
      "Labelers =  (4, 6)\n",
      "P(L_ 4 = 0 , L_ 6 = 0  | Y =  1 ) =  0.018162712499619267\n",
      "P(L_ 4 = 0 , L_ 6 = 1  | Y =  1 ) =  0.05688754356182601\n",
      "P(L_ 4 = 0 , L_ 6 = 2  | Y =  1 ) =  0.0325165015245963\n",
      "P(L_ 4 = 1 , L_ 6 = 0  | Y =  1 ) =  0.06570811024630711\n",
      "P(L_ 4 = 1 , L_ 6 = 1  | Y =  1 ) =  0.20571519967598428\n",
      "P(L_ 4 = 1 , L_ 6 = 2  | Y =  1 ) =  0.11761317191018707\n",
      "P(L_ 4 = 2 , L_ 6 = 0  | Y =  1 ) =  0.08500618296566426\n",
      "P(L_ 4 = 2 , L_ 6 = 1  | Y =  1 ) =  0.2662136233618588\n",
      "P(L_ 4 = 2 , L_ 6 = 2  | Y =  1 ) =  0.1521769542539568\n",
      "Labelers =  (4, 7)\n",
      "P(L_ 4 = 0 , L_ 7 = 0  | Y =  1 ) =  0.01925701348185254\n",
      "P(L_ 4 = 0 , L_ 7 = 1  | Y =  1 ) =  0.046235861299082054\n",
      "P(L_ 4 = 0 , L_ 7 = 2  | Y =  1 ) =  0.04207388280510701\n",
      "P(L_ 4 = 1 , L_ 7 = 0  | Y =  1 ) =  0.06896290407750161\n",
      "P(L_ 4 = 1 , L_ 7 = 1  | Y =  1 ) =  0.16879415841027404\n",
      "P(L_ 4 = 1 , L_ 7 = 2  | Y =  1 ) =  0.15127941934470288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(L_ 4 = 2 , L_ 7 = 0  | Y =  1 ) =  0.08657453129463706\n",
      "P(L_ 4 = 2 , L_ 7 = 1  | Y =  1 ) =  0.23247989102220679\n",
      "P(L_ 4 = 2 , L_ 7 = 2  | Y =  1 ) =  0.184342338264636\n",
      "Labelers =  (4, 8)\n",
      "P(L_ 4 = 0 , L_ 8 = 0  | Y =  1 ) =  0.01382054152267628\n",
      "P(L_ 4 = 0 , L_ 8 = 1  | Y =  1 ) =  0.06137682680093568\n",
      "P(L_ 4 = 0 , L_ 8 = 2  | Y =  1 ) =  0.03236938926242964\n",
      "P(L_ 4 = 1 , L_ 8 = 0  | Y =  1 ) =  0.04988167960516181\n",
      "P(L_ 4 = 1 , L_ 8 = 1  | Y =  1 ) =  0.22212963388263723\n",
      "P(L_ 4 = 1 , L_ 8 = 2  | Y =  1 ) =  0.11702516834467945\n",
      "P(L_ 4 = 2 , L_ 8 = 0  | Y =  1 ) =  0.06459069577778812\n",
      "P(L_ 4 = 2 , L_ 8 = 1  | Y =  1 ) =  0.2873576445521735\n",
      "P(L_ 4 = 2 , L_ 8 = 2  | Y =  1 ) =  0.15144842025151825\n",
      "Labelers =  (4, 9)\n",
      "P(L_ 4 = 0 , L_ 9 = 0  | Y =  1 ) =  0.01813638689832147\n",
      "P(L_ 4 = 0 , L_ 9 = 1  | Y =  1 ) =  0.0563844711836837\n",
      "P(L_ 4 = 0 , L_ 9 = 2  | Y =  1 ) =  0.03304589950403641\n",
      "P(L_ 4 = 1 , L_ 9 = 0  | Y =  1 ) =  0.06558885025981166\n",
      "P(L_ 4 = 1 , L_ 9 = 1  | Y =  1 ) =  0.20391263588429914\n",
      "P(L_ 4 = 1 , L_ 9 = 2  | Y =  1 ) =  0.1195349956883676\n",
      "P(L_ 4 = 2 , L_ 9 = 0  | Y =  1 ) =  0.08487130540584545\n",
      "P(L_ 4 = 2 , L_ 9 = 1  | Y =  1 ) =  0.263864925435696\n",
      "P(L_ 4 = 2 , L_ 9 = 2  | Y =  1 ) =  0.15466052973993827\n",
      "Labelers =  (5, 6)\n",
      "P(L_ 5 = 0 , L_ 6 = 0  | Y =  1 ) =  0.02328115606333602\n",
      "P(L_ 5 = 0 , L_ 6 = 1  | Y =  1 ) =  0.07290047729198303\n",
      "P(L_ 5 = 0 , L_ 6 = 2  | Y =  1 ) =  0.04167519781810823\n",
      "P(L_ 5 = 1 , L_ 6 = 0  | Y =  1 ) =  0.04965230610865076\n",
      "P(L_ 5 = 1 , L_ 6 = 1  | Y =  1 ) =  0.15547643155579746\n",
      "P(L_ 5 = 1 , L_ 6 = 2  | Y =  1 ) =  0.08888168042850601\n",
      "P(L_ 5 = 2 , L_ 6 = 0  | Y =  1 ) =  0.09594354353960385\n",
      "P(L_ 5 = 2 , L_ 6 = 1  | Y =  1 ) =  0.3004394577518886\n",
      "P(L_ 5 = 2 , L_ 6 = 2  | Y =  1 ) =  0.17174974944212593\n",
      "Labelers =  (5, 7)\n",
      "P(L_ 5 = 0 , L_ 7 = 0  | Y =  1 ) =  0.034159626431652164\n",
      "P(L_ 5 = 0 , L_ 7 = 1  | Y =  1 ) =  0.04610661931947464\n",
      "P(L_ 5 = 0 , L_ 7 = 2  | Y =  1 ) =  0.05759058542230048\n",
      "P(L_ 5 = 1 , L_ 7 = 0  | Y =  1 ) =  0.04807185134696156\n",
      "P(L_ 5 = 1 , L_ 7 = 1  | Y =  1 ) =  0.10952859036556749\n",
      "P(L_ 5 = 1 , L_ 7 = 2  | Y =  1 ) =  0.13640997638042524\n",
      "P(L_ 5 = 2 , L_ 7 = 0  | Y =  1 ) =  0.09256297107537745\n",
      "P(L_ 5 = 2 , L_ 7 = 1  | Y =  1 ) =  0.2918747010465207\n",
      "P(L_ 5 = 2 , L_ 7 = 2  | Y =  1 ) =  0.1836950786117202\n",
      "Labelers =  (5, 8)\n",
      "P(L_ 5 = 0 , L_ 8 = 0  | Y =  1 ) =  0.017685959297850443\n",
      "P(L_ 5 = 0 , L_ 8 = 1  | Y =  1 ) =  0.0786977422314125\n",
      "P(L_ 5 = 0 , L_ 8 = 2  | Y =  1 ) =  0.041473129644164344\n",
      "P(L_ 5 = 1 , L_ 8 = 0  | Y =  1 ) =  0.037718488685094184\n",
      "P(L_ 5 = 1 , L_ 8 = 1  | Y =  1 ) =  0.16784154334035178\n",
      "P(L_ 5 = 1 , L_ 8 = 2  | Y =  1 ) =  0.0884503860675083\n",
      "P(L_ 5 = 2 , L_ 8 = 0  | Y =  1 ) =  0.07288846892268157\n",
      "P(L_ 5 = 2 , L_ 8 = 1  | Y =  1 ) =  0.32432481966398213\n",
      "P(L_ 5 = 2 , L_ 8 = 2  | Y =  1 ) =  0.1709194621469547\n",
      "Labelers =  (5, 9)\n",
      "P(L_ 5 = 0 , L_ 9 = 0  | Y =  1 ) =  0.023242184238985213\n",
      "P(L_ 5 = 0 , L_ 9 = 1  | Y =  1 ) =  0.07225914705992398\n",
      "P(L_ 5 = 0 , L_ 9 = 2  | Y =  1 ) =  0.04235549987451806\n",
      "P(L_ 5 = 1 , L_ 9 = 0  | Y =  1 ) =  0.04956910013449886\n",
      "P(L_ 5 = 1 , L_ 9 = 1  | Y =  1 ) =  0.15410868890179694\n",
      "P(L_ 5 = 1 , L_ 9 = 2  | Y =  1 ) =  0.09033262905665843\n",
      "P(L_ 5 = 2 , L_ 9 = 0  | Y =  1 ) =  0.09578525819049451\n",
      "P(L_ 5 = 2 , L_ 9 = 1  | Y =  1 ) =  0.29779419654195793\n",
      "P(L_ 5 = 2 , L_ 9 = 2  | Y =  1 ) =  0.17455329600116581\n",
      "Labelers =  (6, 7)\n",
      "P(L_ 6 = 0 , L_ 7 = 0  | Y =  1 ) =  0.029518789617419734\n",
      "P(L_ 6 = 0 , L_ 7 = 1  | Y =  1 ) =  0.07557397882927151\n",
      "P(L_ 6 = 0 , L_ 7 = 2  | Y =  1 ) =  0.06378423726489937\n",
      "P(L_ 6 = 1 , L_ 7 = 0  | Y =  1 ) =  0.09243412471842913\n",
      "P(L_ 6 = 1 , L_ 7 = 1  | Y =  1 ) =  0.2366508033533719\n",
      "P(L_ 6 = 1 , L_ 7 = 2  | Y =  1 ) =  0.19973143852786793\n",
      "P(L_ 6 = 2 , L_ 7 = 0  | Y =  1 ) =  0.052841534518142316\n",
      "P(L_ 6 = 2 , L_ 7 = 1  | Y =  1 ) =  0.13528512854891941\n",
      "P(L_ 6 = 2 , L_ 7 = 2  | Y =  1 ) =  0.11417996462167847\n",
      "Labelers =  (6, 8)\n",
      "P(L_ 6 = 0 , L_ 8 = 0  | Y =  1 ) =  0.021665593976656603\n",
      "P(L_ 6 = 0 , L_ 8 = 1  | Y =  1 ) =  0.09640600807607974\n",
      "P(L_ 6 = 0 , L_ 8 = 2  | Y =  1 ) =  0.050805403658854276\n",
      "P(L_ 6 = 1 , L_ 8 = 0  | Y =  1 ) =  0.06784359996005858\n",
      "P(L_ 6 = 1 , L_ 8 = 1  | Y =  1 ) =  0.3018819849139723\n",
      "P(L_ 6 = 1 , L_ 8 = 2  | Y =  1 ) =  0.1590907817256381\n",
      "P(L_ 6 = 2 , L_ 8 = 0  | Y =  1 ) =  0.03878372296891099\n",
      "P(L_ 6 = 2 , L_ 8 = 1  | Y =  1 ) =  0.17257611224569433\n",
      "P(L_ 6 = 2 , L_ 8 = 2  | Y =  1 ) =  0.09094679247413483\n",
      "Labelers =  (6, 9)\n",
      "P(L_ 6 = 0 , L_ 9 = 0  | Y =  1 ) =  0.028615665305093504\n",
      "P(L_ 6 = 0 , L_ 9 = 1  | Y =  1 ) =  0.08796470024309401\n",
      "P(L_ 6 = 0 , L_ 9 = 2  | Y =  1 ) =  0.05229664016340311\n",
      "P(L_ 6 = 1 , L_ 9 = 0  | Y =  1 ) =  0.08894663051532413\n",
      "P(L_ 6 = 1 , L_ 9 = 1  | Y =  1 ) =  0.27803057514141666\n",
      "P(L_ 6 = 1 , L_ 9 = 2  | Y =  1 ) =  0.1618391609429281\n",
      "P(L_ 6 = 2 , L_ 9 = 0  | Y =  1 ) =  0.051034246743560954\n",
      "P(L_ 6 = 2 , L_ 9 = 1  | Y =  1 ) =  0.15816675711916814\n",
      "P(L_ 6 = 2 , L_ 9 = 2  | Y =  1 ) =  0.09310562382601104\n",
      "Labelers =  (7, 8)\n",
      "P(L_ 7 = 0 , L_ 8 = 0  | Y =  1 ) =  0.02242488102269446\n",
      "P(L_ 7 = 0 , L_ 8 = 1  | Y =  1 ) =  0.09978389669233402\n",
      "P(L_ 7 = 0 , L_ 8 = 2  | Y =  1 ) =  0.052585671138962724\n",
      "P(L_ 7 = 1 , L_ 8 = 0  | Y =  1 ) =  0.05741250528041583\n",
      "P(L_ 7 = 1 , L_ 8 = 1  | Y =  1 ) =  0.2554670855687163\n",
      "P(L_ 7 = 1 , L_ 8 = 2  | Y =  1 ) =  0.1346303198824308\n",
      "P(L_ 7 = 2 , L_ 8 = 0  | Y =  1 ) =  0.04845553060251591\n",
      "P(L_ 7 = 2 , L_ 8 = 1  | Y =  1 ) =  0.21561312297469618\n",
      "P(L_ 7 = 2 , L_ 8 = 2  | Y =  1 ) =  0.11362698683723386\n",
      "Labelers =  (7, 9)\n",
      "P(L_ 7 = 0 , L_ 9 = 0  | Y =  1 ) =  0.02946973963962854\n",
      "P(L_ 7 = 0 , L_ 9 = 1  | Y =  1 ) =  0.09162059893760091\n",
      "P(L_ 7 = 0 , L_ 9 = 2  | Y =  1 ) =  0.053704110276761696\n",
      "P(L_ 7 = 1 , L_ 9 = 0  | Y =  1 ) =  0.07544862949262306\n",
      "P(L_ 7 = 1 , L_ 9 = 1  | Y =  1 ) =  0.23456779262642785\n",
      "P(L_ 7 = 1 , L_ 9 = 2  | Y =  1 ) =  0.1374934886125119\n",
      "P(L_ 7 = 2 , L_ 9 = 0  | Y =  1 ) =  0.063678173431727\n",
      "P(L_ 7 = 2 , L_ 9 = 1  | Y =  1 ) =  0.19797364093965011\n",
      "P(L_ 7 = 2 , L_ 9 = 2  | Y =  1 ) =  0.11604382604306868\n",
      "Labelers =  (8, 9)\n",
      "P(L_ 8 = 0 , L_ 9 = 0  | Y =  1 ) =  0.02162979672063379\n",
      "P(L_ 8 = 0 , L_ 9 = 1  | Y =  1 ) =  0.06724637448757376\n",
      "P(L_ 8 = 0 , L_ 9 = 2  | Y =  1 ) =  0.039416745697418626\n",
      "P(L_ 8 = 1 , L_ 9 = 0  | Y =  1 ) =  0.09624563721957277\n",
      "P(L_ 8 = 1 , L_ 9 = 1  | Y =  1 ) =  0.29922514829429886\n",
      "P(L_ 8 = 1 , L_ 9 = 2  | Y =  1 ) =  0.17539331972187455\n",
      "P(L_ 8 = 2 , L_ 9 = 0  | Y =  1 ) =  0.050721108623772\n",
      "P(L_ 8 = 2 , L_ 9 = 1  | Y =  1 ) =  0.15769050972180615\n",
      "P(L_ 8 = 2 , L_ 9 = 2  | Y =  1 ) =  0.09243135951304912\n",
      "Labelers =  (0, 1)\n",
      "P(L_ 0 = 0 , L_ 1 = 0  | Y =  2 ) =  0.007379398046895549\n",
      "P(L_ 0 = 0 , L_ 1 = 1  | Y =  2 ) =  0.026069297638547727\n",
      "P(L_ 0 = 0 , L_ 1 = 2  | Y =  2 ) =  0.012748490465989862\n",
      "P(L_ 0 = 1 , L_ 1 = 0  | Y =  2 ) =  0.037999867563542546\n",
      "P(L_ 0 = 1 , L_ 1 = 1  | Y =  2 ) =  0.2578023940585031\n",
      "P(L_ 0 = 1 , L_ 1 = 2  | Y =  2 ) =  0.09176074172933342\n",
      "P(L_ 0 = 2 , L_ 1 = 0  | Y =  2 ) =  0.05505009234372541\n",
      "P(L_ 0 = 2 , L_ 1 = 1  | Y =  2 ) =  0.34737795634461227\n",
      "P(L_ 0 = 2 , L_ 1 = 2  | Y =  2 ) =  0.16381176180885\n",
      "Labelers =  (0, 2)\n",
      "P(L_ 0 = 0 , L_ 2 = 0  | Y =  2 ) =  0.002055638954401455\n",
      "P(L_ 0 = 0 , L_ 2 = 1  | Y =  2 ) =  0.024033736275445198\n",
      "P(L_ 0 = 0 , L_ 2 = 2  | Y =  2 ) =  0.020107810921586488\n",
      "P(L_ 0 = 1 , L_ 2 = 0  | Y =  2 ) =  0.016522654823208062\n",
      "P(L_ 0 = 1 , L_ 2 = 1  | Y =  2 ) =  0.20878558625071802\n",
      "P(L_ 0 = 1 , L_ 2 = 2  | Y =  2 ) =  0.162254762277453\n",
      "P(L_ 0 = 2 , L_ 2 = 0  | Y =  2 ) =  0.024319339077229756\n",
      "P(L_ 0 = 2 , L_ 2 = 1  | Y =  2 ) =  0.29788036481284047\n",
      "P(L_ 0 = 2 , L_ 2 = 2  | Y =  2 ) =  0.24404010660711756\n",
      "Labelers =  (0, 3)\n",
      "P(L_ 0 = 0 , L_ 3 = 0  | Y =  2 ) =  0.009139911174983913\n",
      "P(L_ 0 = 0 , L_ 3 = 1  | Y =  2 ) =  0.013190516081477636\n",
      "P(L_ 0 = 0 , L_ 3 = 2  | Y =  2 ) =  0.02386675889497159\n",
      "P(L_ 0 = 1 , L_ 3 = 0  | Y =  2 ) =  0.041920104425321236\n",
      "P(L_ 0 = 1 , L_ 3 = 1  | Y =  2 ) =  0.14923693957589626\n",
      "P(L_ 0 = 1 , L_ 3 = 2  | Y =  2 ) =  0.19640595935016159\n",
      "P(L_ 0 = 2 , L_ 3 = 0  | Y =  2 ) =  0.06796348415542644\n",
      "P(L_ 0 = 2 , L_ 3 = 1  | Y =  2 ) =  0.15004764949598035\n",
      "P(L_ 0 = 2 , L_ 3 = 2  | Y =  2 ) =  0.34822867684578096\n",
      "Labelers =  (0, 4)\n",
      "P(L_ 0 = 0 , L_ 4 = 0  | Y =  2 ) =  0.007844950613034751\n",
      "P(L_ 0 = 0 , L_ 4 = 1  | Y =  2 ) =  0.022064913683927732\n",
      "P(L_ 0 = 0 , L_ 4 = 2  | Y =  2 ) =  0.016287321854470658\n",
      "P(L_ 0 = 1 , L_ 4 = 0  | Y =  2 ) =  0.03898855019420802\n",
      "P(L_ 0 = 1 , L_ 4 = 1  | Y =  2 ) =  0.22555652376229532\n",
      "P(L_ 0 = 1 , L_ 4 = 2  | Y =  2 ) =  0.12301792939487577\n",
      "P(L_ 0 = 2 , L_ 4 = 0  | Y =  2 ) =  0.05467525975509851\n",
      "P(L_ 0 = 2 , L_ 4 = 1  | Y =  2 ) =  0.23425458842158164\n",
      "P(L_ 0 = 2 , L_ 4 = 2  | Y =  2 ) =  0.27730996232050753\n",
      "Labelers =  (0, 5)\n",
      "P(L_ 0 = 0 , L_ 5 = 0  | Y =  2 ) =  0.005072603085584942\n",
      "P(L_ 0 = 0 , L_ 5 = 1  | Y =  2 ) =  0.026165718037244774\n",
      "P(L_ 0 = 0 , L_ 5 = 2  | Y =  2 ) =  0.014958865028603427\n",
      "P(L_ 0 = 1 , L_ 5 = 0  | Y =  2 ) =  0.04043846299552396\n",
      "P(L_ 0 = 1 , L_ 5 = 1  | Y =  2 ) =  0.21877971186765233\n",
      "P(L_ 0 = 1 , L_ 5 = 2  | Y =  2 ) =  0.1283448284882028\n",
      "P(L_ 0 = 2 , L_ 5 = 0  | Y =  2 ) =  0.060825499634332404\n",
      "P(L_ 0 = 2 , L_ 5 = 1  | Y =  2 ) =  0.3232481241530389\n",
      "P(L_ 0 = 2 , L_ 5 = 2  | Y =  2 ) =  0.18216618670981646\n",
      "Labelers =  (0, 6)\n",
      "P(L_ 0 = 0 , L_ 6 = 0  | Y =  2 ) =  0.0055434123957499425\n",
      "P(L_ 0 = 0 , L_ 6 = 1  | Y =  2 ) =  0.021762021691540248\n",
      "P(L_ 0 = 0 , L_ 6 = 2  | Y =  2 ) =  0.018891752064142946\n",
      "P(L_ 0 = 1 , L_ 6 = 0  | Y =  2 ) =  0.04635087404410608\n",
      "P(L_ 0 = 1 , L_ 6 = 1  | Y =  2 ) =  0.1828166533822908\n",
      "P(L_ 0 = 1 , L_ 6 = 2  | Y =  2 ) =  0.15839547592498224\n",
      "P(L_ 0 = 2 , L_ 6 = 0  | Y =  2 ) =  0.06782413241459707\n",
      "P(L_ 0 = 2 , L_ 6 = 1  | Y =  2 ) =  0.2668654888359076\n",
      "P(L_ 0 = 2 , L_ 6 = 2  | Y =  2 ) =  0.23155018924668305\n",
      "Labelers =  (0, 7)\n",
      "P(L_ 0 = 0 , L_ 7 = 0  | Y =  2 ) =  0.009329019441654441\n",
      "P(L_ 0 = 0 , L_ 7 = 1  | Y =  2 ) =  0.02079202509850055\n",
      "P(L_ 0 = 0 , L_ 7 = 2  | Y =  2 ) =  0.016076141611278155\n",
      "P(L_ 0 = 1 , L_ 7 = 0  | Y =  2 ) =  0.07805047605467409\n",
      "P(L_ 0 = 1 , L_ 7 = 1  | Y =  2 ) =  0.17451214805634527\n",
      "P(L_ 0 = 1 , L_ 7 = 2  | Y =  2 ) =  0.13500037924035974\n",
      "P(L_ 0 = 2 , L_ 7 = 0  | Y =  2 ) =  0.11419747665256648\n",
      "P(L_ 0 = 2 , L_ 7 = 1  | Y =  2 ) =  0.25513075639083077\n",
      "P(L_ 0 = 2 , L_ 7 = 2  | Y =  2 ) =  0.19691157745379045\n",
      "Labelers =  (0, 8)\n",
      "P(L_ 0 = 0 , L_ 8 = 0  | Y =  2 ) =  0.010817614095678083\n",
      "P(L_ 0 = 0 , L_ 8 = 1  | Y =  2 ) =  0.016579233448213115\n",
      "P(L_ 0 = 0 , L_ 8 = 2  | Y =  2 ) =  0.018800338607541944\n",
      "P(L_ 0 = 1 , L_ 8 = 0  | Y =  2 ) =  0.08889560996171116\n",
      "P(L_ 0 = 1 , L_ 8 = 1  | Y =  2 ) =  0.1399867390909882\n",
      "P(L_ 0 = 1 , L_ 8 = 2  | Y =  2 ) =  0.1586806542986798\n",
      "P(L_ 0 = 2 , L_ 8 = 0  | Y =  2 ) =  0.12871677171906903\n",
      "P(L_ 0 = 2 , L_ 8 = 1  | Y =  2 ) =  0.20220298843498247\n",
      "P(L_ 0 = 2 , L_ 8 = 2  | Y =  2 ) =  0.23532005034313627\n",
      "Labelers =  (0, 9)\n",
      "P(L_ 0 = 0 , L_ 9 = 0  | Y =  2 ) =  0.00541237673773328\n",
      "P(L_ 0 = 0 , L_ 9 = 1  | Y =  2 ) =  0.02010383113763298\n",
      "P(L_ 0 = 0 , L_ 9 = 2  | Y =  2 ) =  0.020680978276066877\n",
      "P(L_ 0 = 1 , L_ 9 = 0  | Y =  2 ) =  0.045466434284129366\n",
      "P(L_ 0 = 1 , L_ 9 = 1  | Y =  2 ) =  0.16933796358601202\n",
      "P(L_ 0 = 1 , L_ 9 = 2  | Y =  2 ) =  0.17275860548123767\n",
      "P(L_ 0 = 2 , L_ 9 = 0  | Y =  2 ) =  0.06632332198772704\n",
      "P(L_ 0 = 2 , L_ 9 = 1  | Y =  2 ) =  0.2466780488177102\n",
      "P(L_ 0 = 2 , L_ 9 = 2  | Y =  2 ) =  0.2532384396917504\n",
      "Labelers =  (1, 2)\n",
      "P(L_ 1 = 0 , L_ 2 = 0  | Y =  2 ) =  0.006496147670618618\n",
      "P(L_ 1 = 0 , L_ 2 = 1  | Y =  2 ) =  0.046743968552975454\n",
      "P(L_ 1 = 0 , L_ 2 = 2  | Y =  2 ) =  0.047189241730569424\n",
      "P(L_ 1 = 1 , L_ 2 = 0  | Y =  2 ) =  0.024331296214012584\n",
      "P(L_ 1 = 1 , L_ 2 = 1  | Y =  2 ) =  0.3853592141643739\n",
      "P(L_ 1 = 1 , L_ 2 = 2  | Y =  2 ) =  0.2215591376632767\n",
      "P(L_ 1 = 2 , L_ 2 = 0  | Y =  2 ) =  0.012070188970208073\n",
      "P(L_ 1 = 2 , L_ 2 = 1  | Y =  2 ) =  0.0985965046216543\n",
      "P(L_ 1 = 2 , L_ 2 = 2  | Y =  2 ) =  0.15765430041231085\n",
      "Labelers =  (1, 3)\n",
      "P(L_ 1 = 0 , L_ 3 = 0  | Y =  2 ) =  0.012177614668491304\n",
      "P(L_ 1 = 0 , L_ 3 = 1  | Y =  2 ) =  0.03132713196249647\n",
      "P(L_ 1 = 0 , L_ 3 = 2  | Y =  2 ) =  0.056924611323175736\n",
      "P(L_ 1 = 1 , L_ 3 = 0  | Y =  2 ) =  0.07473683868965268\n",
      "P(L_ 1 = 1 , L_ 3 = 1  | Y =  2 ) =  0.19876568466169733\n",
      "P(L_ 1 = 1 , L_ 3 = 2  | Y =  2 ) =  0.3577471246903131\n",
      "P(L_ 1 = 2 , L_ 3 = 0  | Y =  2 ) =  0.03210904639758759\n",
      "P(L_ 1 = 2 , L_ 3 = 1  | Y =  2 ) =  0.08238228852916045\n",
      "P(L_ 1 = 2 , L_ 3 = 2  | Y =  2 ) =  0.15382965907742518\n",
      "Labelers =  (1, 4)\n",
      "P(L_ 1 = 0 , L_ 4 = 0  | Y =  2 ) =  0.010391440664176937\n",
      "P(L_ 1 = 0 , L_ 4 = 1  | Y =  2 ) =  0.04841433857177685\n",
      "P(L_ 1 = 0 , L_ 4 = 2  | Y =  2 ) =  0.04162357871820973\n",
      "P(L_ 1 = 1 , L_ 4 = 0  | Y =  2 ) =  0.06390396334038412\n",
      "P(L_ 1 = 1 , L_ 4 = 1  | Y =  2 ) =  0.3061998937049735\n",
      "P(L_ 1 = 1 , L_ 4 = 2  | Y =  2 ) =  0.2611457909963055\n",
      "P(L_ 1 = 2 , L_ 4 = 0  | Y =  2 ) =  0.027213356557780205\n",
      "P(L_ 1 = 2 , L_ 4 = 1  | Y =  2 ) =  0.12726179359105427\n",
      "P(L_ 1 = 2 , L_ 4 = 2  | Y =  2 ) =  0.11384584385533876\n",
      "Labelers =  (1, 5)\n",
      "P(L_ 1 = 0 , L_ 5 = 0  | Y =  2 ) =  0.010688684810661691\n",
      "P(L_ 1 = 0 , L_ 5 = 1  | Y =  2 ) =  0.05705692624749822\n",
      "P(L_ 1 = 0 , L_ 5 = 2  | Y =  2 ) =  0.0326837468960036\n",
      "P(L_ 1 = 1 , L_ 5 = 0  | Y =  2 ) =  0.06707704093227604\n",
      "P(L_ 1 = 1 , L_ 5 = 1  | Y =  2 ) =  0.3586020775114825\n",
      "P(L_ 1 = 1 , L_ 5 = 2  | Y =  2 ) =  0.20557052959790462\n",
      "P(L_ 1 = 2 , L_ 5 = 0  | Y =  2 ) =  0.028570839972503575\n",
      "P(L_ 1 = 2 , L_ 5 = 1  | Y =  2 ) =  0.1525345502989552\n",
      "P(L_ 1 = 2 , L_ 5 = 2  | Y =  2 ) =  0.08721560373271448\n",
      "Labelers =  (1, 6)\n",
      "P(L_ 1 = 0 , L_ 6 = 0  | Y =  2 ) =  0.012306137685992055\n",
      "P(L_ 1 = 0 , L_ 6 = 1  | Y =  2 ) =  0.04708135822038161\n",
      "P(L_ 1 = 0 , L_ 6 = 2  | Y =  2 ) =  0.04104186204778983\n",
      "P(L_ 1 = 1 , L_ 6 = 0  | Y =  2 ) =  0.07470120324646838\n",
      "P(L_ 1 = 1 , L_ 6 = 1  | Y =  2 ) =  0.29928521243589806\n",
      "P(L_ 1 = 1 , L_ 6 = 2  | Y =  2 ) =  0.25726323235929677\n",
      "P(L_ 1 = 2 , L_ 6 = 0  | Y =  2 ) =  0.03271107792199265\n",
      "P(L_ 1 = 2 , L_ 6 = 1  | Y =  2 ) =  0.12507759325345902\n",
      "P(L_ 1 = 2 , L_ 6 = 2  | Y =  2 ) =  0.1105323228287216\n",
      "Labelers =  (1, 7)\n",
      "P(L_ 1 = 0 , L_ 7 = 0  | Y =  2 ) =  0.02024523114921178\n",
      "P(L_ 1 = 0 , L_ 7 = 1  | Y =  2 ) =  0.045235790949716276\n",
      "P(L_ 1 = 0 , L_ 7 = 2  | Y =  2 ) =  0.034948335855235456\n",
      "P(L_ 1 = 1 , L_ 7 = 0  | Y =  2 ) =  0.12724077985487503\n",
      "P(L_ 1 = 1 , L_ 7 = 1  | Y =  2 ) =  0.2843346266945693\n",
      "P(L_ 1 = 1 , L_ 7 = 2  | Y =  2 ) =  0.2196742414922189\n",
      "P(L_ 1 = 2 , L_ 7 = 0  | Y =  2 ) =  0.05409096114480824\n",
      "P(L_ 1 = 2 , L_ 7 = 1  | Y =  2 ) =  0.120864511901391\n",
      "P(L_ 1 = 2 , L_ 7 = 2  | Y =  2 ) =  0.093365520957974\n",
      "Labelers =  (1, 8)\n",
      "P(L_ 1 = 0 , L_ 8 = 0  | Y =  2 ) =  0.022957933427704972\n",
      "P(L_ 1 = 0 , L_ 8 = 1  | Y =  2 ) =  0.03603203537307888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(L_ 1 = 0 , L_ 8 = 2  | Y =  2 ) =  0.04143938915337966\n",
      "P(L_ 1 = 1 , L_ 8 = 0  | Y =  2 ) =  0.1442021846097643\n",
      "P(L_ 1 = 1 , L_ 8 = 1  | Y =  2 ) =  0.2265211927689233\n",
      "P(L_ 1 = 1 , L_ 8 = 2  | Y =  2 ) =  0.2605262706629756\n",
      "P(L_ 1 = 2 , L_ 8 = 0  | Y =  2 ) =  0.061269877738988995\n",
      "P(L_ 1 = 2 , L_ 8 = 1  | Y =  2 ) =  0.09621573283218161\n",
      "P(L_ 1 = 2 , L_ 8 = 2  | Y =  2 ) =  0.11083538343300266\n",
      "Labelers =  (1, 9)\n",
      "P(L_ 1 = 0 , L_ 9 = 0  | Y =  2 ) =  0.011839037015298676\n",
      "P(L_ 1 = 0 , L_ 9 = 1  | Y =  2 ) =  0.04331249924036644\n",
      "P(L_ 1 = 0 , L_ 9 = 2  | Y =  2 ) =  0.04527782169849838\n",
      "P(L_ 1 = 1 , L_ 9 = 0  | Y =  2 ) =  0.0745970443392745\n",
      "P(L_ 1 = 1 , L_ 9 = 1  | Y =  2 ) =  0.28029548053527026\n",
      "P(L_ 1 = 1 , L_ 9 = 2  | Y =  2 ) =  0.27635712316711836\n",
      "P(L_ 1 = 2 , L_ 9 = 0  | Y =  2 ) =  0.030766051655016523\n",
      "P(L_ 1 = 2 , L_ 9 = 1  | Y =  2 ) =  0.11251186376571849\n",
      "P(L_ 1 = 2 , L_ 9 = 2  | Y =  2 ) =  0.12504307858343822\n",
      "Labelers =  (2, 3)\n",
      "P(L_ 2 = 0 , L_ 3 = 0  | Y =  2 ) =  0.005112796847780446\n",
      "P(L_ 2 = 0 , L_ 3 = 1  | Y =  2 ) =  0.013393606353084035\n",
      "P(L_ 2 = 0 , L_ 3 = 2  | Y =  2 ) =  0.02439122965397479\n",
      "P(L_ 2 = 1 , L_ 3 = 0  | Y =  2 ) =  0.0630912941165677\n",
      "P(L_ 2 = 1 , L_ 3 = 1  | Y =  2 ) =  0.16619347612850688\n",
      "P(L_ 2 = 1 , L_ 3 = 2  | Y =  2 ) =  0.3014149170939291\n",
      "P(L_ 2 = 2 , L_ 3 = 0  | Y =  2 ) =  0.05081940879138343\n",
      "P(L_ 2 = 2 , L_ 3 = 1  | Y =  2 ) =  0.13288802267176333\n",
      "P(L_ 2 = 2 , L_ 3 = 2  | Y =  2 ) =  0.24269524834301023\n",
      "Labelers =  (2, 4)\n",
      "P(L_ 2 = 0 , L_ 4 = 0  | Y =  2 ) =  0.004359482638287472\n",
      "P(L_ 2 = 0 , L_ 4 = 1  | Y =  2 ) =  0.020658750787805803\n",
      "P(L_ 2 = 0 , L_ 4 = 2  | Y =  2 ) =  0.017879399428746\n",
      "P(L_ 2 = 1 , L_ 4 = 0  | Y =  2 ) =  0.05384782854016754\n",
      "P(L_ 2 = 1 , L_ 4 = 1  | Y =  2 ) =  0.2562232712749868\n",
      "P(L_ 2 = 1 , L_ 4 = 2  | Y =  2 ) =  0.22062858752384928\n",
      "P(L_ 2 = 2 , L_ 4 = 0  | Y =  2 ) =  0.04330144938388625\n",
      "P(L_ 2 = 2 , L_ 4 = 1  | Y =  2 ) =  0.20499400380501206\n",
      "P(L_ 2 = 2 , L_ 4 = 2  | Y =  2 ) =  0.1781072266172587\n",
      "Labelers =  (2, 5)\n",
      "P(L_ 2 = 0 , L_ 5 = 0  | Y =  2 ) =  0.004562079890449811\n",
      "P(L_ 2 = 0 , L_ 5 = 1  | Y =  2 ) =  0.024374482782552536\n",
      "P(L_ 2 = 0 , L_ 5 = 2  | Y =  2 ) =  0.013961070181836928\n",
      "P(L_ 2 = 1 , L_ 5 = 0  | Y =  2 ) =  0.05642206530001695\n",
      "P(L_ 2 = 1 , L_ 5 = 1  | Y =  2 ) =  0.30152252813836183\n",
      "P(L_ 2 = 1 , L_ 5 = 2  | Y =  2 ) =  0.17275509390062488\n",
      "P(L_ 2 = 2 , L_ 5 = 0  | Y =  2 ) =  0.04535242052497453\n",
      "P(L_ 2 = 2 , L_ 5 = 1  | Y =  2 ) =  0.24229654313702162\n",
      "P(L_ 2 = 2 , L_ 5 = 2  | Y =  2 ) =  0.1387537161441609\n",
      "Labelers =  (2, 6)\n",
      "P(L_ 2 = 0 , L_ 6 = 0  | Y =  2 ) =  0.00921720416697747\n",
      "P(L_ 2 = 0 , L_ 6 = 1  | Y =  2 ) =  0.018460695660430976\n",
      "P(L_ 2 = 0 , L_ 6 = 2  | Y =  2 ) =  0.015219733027430828\n",
      "P(L_ 2 = 1 , L_ 6 = 0  | Y =  2 ) =  0.05837670493794776\n",
      "P(L_ 2 = 1 , L_ 6 = 1  | Y =  2 ) =  0.25876610331127364\n",
      "P(L_ 2 = 1 , L_ 6 = 2  | Y =  2 ) =  0.21355687908978227\n",
      "P(L_ 2 = 2 , L_ 6 = 0  | Y =  2 ) =  0.05212450974952784\n",
      "P(L_ 2 = 2 , L_ 6 = 1  | Y =  2 ) =  0.19421736493803404\n",
      "P(L_ 2 = 2 , L_ 6 = 2  | Y =  2 ) =  0.18006080511859507\n",
      "Labelers =  (2, 7)\n",
      "P(L_ 2 = 0 , L_ 7 = 0  | Y =  2 ) =  0.008647224056947702\n",
      "P(L_ 2 = 0 , L_ 7 = 1  | Y =  2 ) =  0.019322585145832745\n",
      "P(L_ 2 = 0 , L_ 7 = 2  | Y =  2 ) =  0.014927823652058832\n",
      "P(L_ 2 = 1 , L_ 7 = 0  | Y =  2 ) =  0.10697581164647699\n",
      "P(L_ 2 = 1 , L_ 7 = 1  | Y =  2 ) =  0.23904501831822395\n",
      "P(L_ 2 = 1 , L_ 7 = 2  | Y =  2 ) =  0.18467885737430267\n",
      "P(L_ 2 = 2 , L_ 7 = 0  | Y =  2 ) =  0.08595393644547034\n",
      "P(L_ 2 = 2 , L_ 7 = 1  | Y =  2 ) =  0.1920673260816199\n",
      "P(L_ 2 = 2 , L_ 7 = 2  | Y =  2 ) =  0.1483814172790668\n",
      "Labelers =  (2, 8)\n",
      "P(L_ 2 = 0 , L_ 8 = 0  | Y =  2 ) =  0.009799400597578323\n",
      "P(L_ 2 = 0 , L_ 8 = 1  | Y =  2 ) =  0.015390049065499673\n",
      "P(L_ 2 = 0 , L_ 8 = 2  | Y =  2 ) =  0.017708183191761283\n",
      "P(L_ 2 = 1 , L_ 8 = 0  | Y =  2 ) =  0.12123079572631176\n",
      "P(L_ 2 = 1 , L_ 8 = 1  | Y =  2 ) =  0.1904104479506748\n",
      "P(L_ 2 = 1 , L_ 8 = 2  | Y =  2 ) =  0.2190584436620172\n",
      "P(L_ 2 = 2 , L_ 8 = 0  | Y =  2 ) =  0.09739979945256817\n",
      "P(L_ 2 = 2 , L_ 8 = 1  | Y =  2 ) =  0.15296846395800937\n",
      "P(L_ 2 = 2 , L_ 8 = 2  | Y =  2 ) =  0.17603441639557954\n",
      "Labelers =  (2, 9)\n",
      "P(L_ 2 = 0 , L_ 9 = 0  | Y =  2 ) =  0.007976775596397381\n",
      "P(L_ 2 = 0 , L_ 9 = 1  | Y =  2 ) =  0.020004111207796934\n",
      "P(L_ 2 = 0 , L_ 9 = 2  | Y =  2 ) =  0.014916746050644955\n",
      "P(L_ 2 = 1 , L_ 9 = 0  | Y =  2 ) =  0.06448874685950404\n",
      "P(L_ 2 = 1 , L_ 9 = 1  | Y =  2 ) =  0.25533495791957816\n",
      "P(L_ 2 = 1 , L_ 9 = 2  | Y =  2 ) =  0.2108759825599215\n",
      "P(L_ 2 = 2 , L_ 9 = 0  | Y =  2 ) =  0.044736610553688265\n",
      "P(L_ 2 = 2 , L_ 9 = 1  | Y =  2 ) =  0.1607807744139801\n",
      "P(L_ 2 = 2 , L_ 9 = 2  | Y =  2 ) =  0.22088529483848854\n",
      "Labelers =  (3, 4)\n",
      "P(L_ 3 = 0 , L_ 4 = 0  | Y =  2 ) =  0.012331671764968088\n",
      "P(L_ 3 = 0 , L_ 4 = 1  | Y =  2 ) =  0.05687902588900653\n",
      "P(L_ 3 = 0 , L_ 4 = 2  | Y =  2 ) =  0.049812802101756974\n",
      "P(L_ 3 = 1 , L_ 4 = 0  | Y =  2 ) =  0.03174143983479201\n",
      "P(L_ 3 = 1 , L_ 4 = 1  | Y =  2 ) =  0.15522905824672217\n",
      "P(L_ 3 = 1 , L_ 4 = 2  | Y =  2 ) =  0.12550460707184002\n",
      "P(L_ 3 = 2 , L_ 4 = 0  | Y =  2 ) =  0.05743564896258119\n",
      "P(L_ 3 = 2 , L_ 4 = 1  | Y =  2 ) =  0.2697679417320759\n",
      "P(L_ 3 = 2 , L_ 4 = 2  | Y =  2 ) =  0.24129780439625703\n",
      "Labelers =  (3, 5)\n",
      "P(L_ 3 = 0 , L_ 5 = 0  | Y =  2 ) =  0.012678190854910015\n",
      "P(L_ 3 = 0 , L_ 5 = 1  | Y =  2 ) =  0.0676388852680736\n",
      "P(L_ 3 = 0 , L_ 5 = 2  | Y =  2 ) =  0.038706423632747976\n",
      "P(L_ 3 = 1 , L_ 5 = 0  | Y =  2 ) =  0.03313792155948245\n",
      "P(L_ 3 = 1 , L_ 5 = 1  | Y =  2 ) =  0.1773727928544572\n",
      "P(L_ 3 = 1 , L_ 5 = 2  | Y =  2 ) =  0.10196439073941464\n",
      "P(L_ 3 = 2 , L_ 5 = 0  | Y =  2 ) =  0.060520453301048854\n",
      "P(L_ 3 = 2 , L_ 5 = 1  | Y =  2 ) =  0.3231818759354052\n",
      "P(L_ 3 = 2 , L_ 5 = 2  | Y =  2 ) =  0.18479906585446013\n",
      "Labelers =  (3, 6)\n",
      "P(L_ 3 = 0 , L_ 6 = 0  | Y =  2 ) =  0.014250862183865912\n",
      "P(L_ 3 = 0 , L_ 6 = 1  | Y =  2 ) =  0.05611036844543732\n",
      "P(L_ 3 = 0 , L_ 6 = 2  | Y =  2 ) =  0.048662269126428355\n",
      "P(L_ 3 = 1 , L_ 6 = 0  | Y =  2 ) =  0.03740357723900845\n",
      "P(L_ 3 = 1 , L_ 6 = 1  | Y =  2 ) =  0.14732649611651716\n",
      "P(L_ 3 = 1 , L_ 6 = 2  | Y =  2 ) =  0.12774503179782865\n",
      "P(L_ 3 = 2 , L_ 6 = 0  | Y =  2 ) =  0.06806397943157874\n",
      "P(L_ 3 = 2 , L_ 6 = 1  | Y =  2 ) =  0.26800729934778417\n",
      "P(L_ 3 = 2 , L_ 6 = 2  | Y =  2 ) =  0.23243011631155122\n",
      "Labelers =  (3, 7)\n",
      "P(L_ 3 = 0 , L_ 7 = 0  | Y =  2 ) =  0.023994568199655862\n",
      "P(L_ 3 = 0 , L_ 7 = 1  | Y =  2 ) =  0.05361174324735974\n",
      "P(L_ 3 = 0 , L_ 7 = 2  | Y =  2 ) =  0.04141718830871598\n",
      "P(L_ 3 = 1 , L_ 7 = 0  | Y =  2 ) =  0.06297932755254236\n",
      "P(L_ 3 = 1 , L_ 7 = 1  | Y =  2 ) =  0.14074218049894655\n",
      "P(L_ 3 = 1 , L_ 7 = 2  | Y =  2 ) =  0.10875359710186533\n",
      "P(L_ 3 = 2 , L_ 7 = 0  | Y =  2 ) =  0.11460307639669683\n",
      "P(L_ 3 = 2 , L_ 7 = 1  | Y =  2 ) =  0.2560810057993703\n",
      "P(L_ 3 = 2 , L_ 7 = 2  | Y =  2 ) =  0.19781731289484705\n",
      "Labelers =  (3, 8)\n",
      "P(L_ 3 = 0 , L_ 8 = 0  | Y =  2 ) =  0.0347797639236128\n",
      "P(L_ 3 = 0 , L_ 8 = 1  | Y =  2 ) =  0.042801670935747466\n",
      "P(L_ 3 = 0 , L_ 8 = 2  | Y =  2 ) =  0.04144206489637132\n",
      "P(L_ 3 = 1 , L_ 8 = 0  | Y =  2 ) =  0.07375221500740188\n",
      "P(L_ 3 = 1 , L_ 8 = 1  | Y =  2 ) =  0.11922505438802901\n",
      "P(L_ 3 = 1 , L_ 8 = 2  | Y =  2 ) =  0.11949783575792339\n",
      "P(L_ 3 = 2 , L_ 8 = 0  | Y =  2 ) =  0.11989801684544357\n",
      "P(L_ 3 = 2 , L_ 8 = 1  | Y =  2 ) =  0.1967422356504073\n",
      "P(L_ 3 = 2 , L_ 8 = 2  | Y =  2 ) =  0.25186114259506326\n",
      "Labelers =  (3, 9)\n",
      "P(L_ 3 = 0 , L_ 9 = 0  | Y =  2 ) =  0.013949137172298075\n",
      "P(L_ 3 = 0 , L_ 9 = 1  | Y =  2 ) =  0.05190138561843889\n",
      "P(L_ 3 = 0 , L_ 9 = 2  | Y =  2 ) =  0.05317297696499461\n",
      "P(L_ 3 = 1 , L_ 9 = 0  | Y =  2 ) =  0.036627897198075916\n",
      "P(L_ 3 = 1 , L_ 9 = 1  | Y =  2 ) =  0.13631340629654215\n",
      "P(L_ 3 = 1 , L_ 9 = 2  | Y =  2 ) =  0.13953380165873616\n",
      "P(L_ 3 = 2 , L_ 9 = 0  | Y =  2 ) =  0.06662509863921569\n",
      "P(L_ 3 = 2 , L_ 9 = 1  | Y =  2 ) =  0.24790505162637413\n",
      "P(L_ 3 = 2 , L_ 9 = 2  | Y =  2 ) =  0.25397124482532424\n",
      "Labelers =  (4, 5)\n",
      "P(L_ 4 = 0 , L_ 5 = 0  | Y =  2 ) =  0.016265719556818915\n",
      "P(L_ 4 = 0 , L_ 5 = 1  | Y =  2 ) =  0.056877229430246784\n",
      "P(L_ 4 = 0 , L_ 5 = 2  | Y =  2 ) =  0.028365811575275585\n",
      "P(L_ 4 = 1 , L_ 5 = 0  | Y =  2 ) =  0.04395173135586869\n",
      "P(L_ 4 = 1 , L_ 5 = 1  | Y =  2 ) =  0.26592796305714905\n",
      "P(L_ 4 = 1 , L_ 5 = 2  | Y =  2 ) =  0.1719963314547869\n",
      "P(L_ 4 = 2 , L_ 5 = 0  | Y =  2 ) =  0.0461191148027537\n",
      "P(L_ 4 = 2 , L_ 5 = 1  | Y =  2 ) =  0.24538836157054014\n",
      "P(L_ 4 = 2 , L_ 5 = 2  | Y =  2 ) =  0.1251077371965602\n",
      "Labelers =  (4, 6)\n",
      "P(L_ 4 = 0 , L_ 6 = 0  | Y =  2 ) =  0.012153210774697698\n",
      "P(L_ 4 = 0 , L_ 6 = 1  | Y =  2 ) =  0.04785485366341996\n",
      "P(L_ 4 = 0 , L_ 6 = 2  | Y =  2 ) =  0.041500696124223614\n",
      "P(L_ 4 = 1 , L_ 6 = 0  | Y =  2 ) =  0.057682248512920815\n",
      "P(L_ 4 = 1 , L_ 6 = 1  | Y =  2 ) =  0.22719375145107698\n",
      "P(L_ 4 = 1 , L_ 6 = 2  | Y =  2 ) =  0.19700002590380689\n",
      "P(L_ 4 = 2 , L_ 6 = 0  | Y =  2 ) =  0.04988295956683458\n",
      "P(L_ 4 = 2 , L_ 6 = 1  | Y =  2 ) =  0.19639555879524173\n",
      "P(L_ 4 = 2 , L_ 6 = 2  | Y =  2 ) =  0.17033669520777775\n",
      "Labelers =  (4, 7)\n",
      "P(L_ 4 = 0 , L_ 7 = 0  | Y =  2 ) =  0.021025042311932796\n",
      "P(L_ 4 = 0 , L_ 7 = 1  | Y =  2 ) =  0.04530621831923316\n",
      "P(L_ 4 = 0 , L_ 7 = 2  | Y =  2 ) =  0.03517749993117532\n",
      "P(L_ 4 = 1 , L_ 7 = 0  | Y =  2 ) =  0.09642145341541028\n",
      "P(L_ 4 = 1 , L_ 7 = 1  | Y =  2 ) =  0.21692217876889014\n",
      "P(L_ 4 = 1 , L_ 7 = 2  | Y =  2 ) =  0.16853239368350426\n",
      "P(L_ 4 = 2 , L_ 7 = 0  | Y =  2 ) =  0.08413047642155198\n",
      "P(L_ 4 = 2 , L_ 7 = 1  | Y =  2 ) =  0.18820653245755328\n",
      "P(L_ 4 = 2 , L_ 7 = 2  | Y =  2 ) =  0.14427820469074878\n",
      "Labelers =  (4, 8)\n",
      "P(L_ 4 = 0 , L_ 8 = 0  | Y =  2 ) =  0.023208516518493844\n",
      "P(L_ 4 = 0 , L_ 8 = 1  | Y =  2 ) =  0.03642237042848701\n",
      "P(L_ 4 = 0 , L_ 8 = 2  | Y =  2 ) =  0.041877873615360425\n",
      "P(L_ 4 = 1 , L_ 8 = 0  | Y =  2 ) =  0.1101532203683496\n",
      "P(L_ 4 = 1 , L_ 8 = 1  | Y =  2 ) =  0.173040871501412\n",
      "P(L_ 4 = 1 , L_ 8 = 2  | Y =  2 ) =  0.19868193399804313\n",
      "P(L_ 4 = 2 , L_ 8 = 0  | Y =  2 ) =  0.0950682588896148\n",
      "P(L_ 4 = 2 , L_ 8 = 1  | Y =  2 ) =  0.14930571904428477\n",
      "P(L_ 4 = 2 , L_ 8 = 2  | Y =  2 ) =  0.17224123563595448\n",
      "Labelers =  (4, 9)\n",
      "P(L_ 4 = 0 , L_ 9 = 0  | Y =  2 ) =  0.011897069056238729\n",
      "P(L_ 4 = 0 , L_ 9 = 1  | Y =  2 ) =  0.04426805405850318\n",
      "P(L_ 4 = 0 , L_ 9 = 2  | Y =  2 ) =  0.04534363744759936\n",
      "P(L_ 4 = 1 , L_ 9 = 0  | Y =  2 ) =  0.0564840420569486\n",
      "P(L_ 4 = 1 , L_ 9 = 1  | Y =  2 ) =  0.2102057542915558\n",
      "P(L_ 4 = 1 , L_ 9 = 2  | Y =  2 ) =  0.21518622951930028\n",
      "P(L_ 4 = 2 , L_ 9 = 0  | Y =  2 ) =  0.048821021896402354\n",
      "P(L_ 4 = 2 , L_ 9 = 1  | Y =  2 ) =  0.1816460351912962\n",
      "P(L_ 4 = 2 , L_ 9 = 2  | Y =  2 ) =  0.18614815648215532\n",
      "Labelers =  (5, 6)\n",
      "P(L_ 5 = 0 , L_ 6 = 0  | Y =  2 ) =  0.012730622376984064\n",
      "P(L_ 5 = 0 , L_ 6 = 1  | Y =  2 ) =  0.0501313967489391\n",
      "P(L_ 5 = 0 , L_ 6 = 2  | Y =  2 ) =  0.04347454658951815\n",
      "P(L_ 5 = 1 , L_ 6 = 0  | Y =  2 ) =  0.06802347957281456\n",
      "P(L_ 5 = 1 , L_ 6 = 1  | Y =  2 ) =  0.26787096121912024\n",
      "P(L_ 5 = 1 , L_ 6 = 2  | Y =  2 ) =  0.2322991132660012\n",
      "P(L_ 5 = 2 , L_ 6 = 0  | Y =  2 ) =  0.03896431690465448\n",
      "P(L_ 5 = 2 , L_ 6 = 1  | Y =  2 ) =  0.15344180594167933\n",
      "P(L_ 5 = 2 , L_ 6 = 2  | Y =  2 ) =  0.1330637573802889\n",
      "Labelers =  (5, 7)\n",
      "P(L_ 5 = 0 , L_ 7 = 0  | Y =  2 ) =  0.031407586584624204\n",
      "P(L_ 5 = 0 , L_ 7 = 1  | Y =  2 ) =  0.037079981036438336\n",
      "P(L_ 5 = 0 , L_ 7 = 2  | Y =  2 ) =  0.03784899809437875\n",
      "P(L_ 5 = 1 , L_ 7 = 0  | Y =  2 ) =  0.107345235020517\n",
      "P(L_ 5 = 1 , L_ 7 = 1  | Y =  2 ) =  0.2787209783462516\n",
      "P(L_ 5 = 1 , L_ 7 = 2  | Y =  2 ) =  0.1821273406911674\n",
      "P(L_ 5 = 2 , L_ 7 = 0  | Y =  2 ) =  0.06282415054375386\n",
      "P(L_ 5 = 2 , L_ 7 = 1  | Y =  2 ) =  0.13463397016298664\n",
      "P(L_ 5 = 2 , L_ 7 = 2  | Y =  2 ) =  0.1280117595198822\n",
      "Labelers =  (5, 8)\n",
      "P(L_ 5 = 0 , L_ 8 = 0  | Y =  2 ) =  0.024289969489307017\n",
      "P(L_ 5 = 0 , L_ 8 = 1  | Y =  2 ) =  0.03814737291431012\n",
      "P(L_ 5 = 0 , L_ 8 = 2  | Y =  2 ) =  0.04389922331182418\n",
      "P(L_ 5 = 1 , L_ 8 = 0  | Y =  2 ) =  0.12978894466156718\n",
      "P(L_ 5 = 1 , L_ 8 = 1  | Y =  2 ) =  0.20384419586150715\n",
      "P(L_ 5 = 1 , L_ 8 = 2  | Y =  2 ) =  0.2345604135348617\n",
      "P(L_ 5 = 2 , L_ 8 = 0  | Y =  2 ) =  0.07435108162558406\n",
      "P(L_ 5 = 2 , L_ 8 = 1  | Y =  2 ) =  0.11677739219836654\n",
      "P(L_ 5 = 2 , L_ 8 = 2  | Y =  2 ) =  0.13434140640267217\n",
      "Labelers =  (5, 9)\n",
      "P(L_ 5 = 0 , L_ 9 = 0  | Y =  2 ) =  0.012462734361267672\n",
      "P(L_ 5 = 0 , L_ 9 = 1  | Y =  2 ) =  0.04637441514232612\n",
      "P(L_ 5 = 0 , L_ 9 = 2  | Y =  2 ) =  0.047499416211847514\n",
      "P(L_ 5 = 1 , L_ 9 = 0  | Y =  2 ) =  0.06659323039403005\n",
      "P(L_ 5 = 1 , L_ 9 = 1  | Y =  2 ) =  0.24779867989967083\n",
      "P(L_ 5 = 1 , L_ 9 = 2  | Y =  2 ) =  0.25380164376423503\n",
      "P(L_ 5 = 2 , L_ 9 = 0  | Y =  2 ) =  0.03814616825429198\n",
      "P(L_ 5 = 2 , L_ 9 = 1  | Y =  2 ) =  0.1419467484993583\n",
      "P(L_ 5 = 2 , L_ 9 = 2  | Y =  2 ) =  0.1453769634729724\n",
      "Labelers =  (6, 7)\n",
      "P(L_ 6 = 0 , L_ 7 = 0  | Y =  2 ) =  0.024132493474432335\n",
      "P(L_ 6 = 0 , L_ 7 = 1  | Y =  2 ) =  0.05392536496097222\n",
      "P(L_ 6 = 0 , L_ 7 = 2  | Y =  2 ) =  0.04166056041904851\n",
      "P(L_ 6 = 1 , L_ 7 = 0  | Y =  2 ) =  0.09503225296306919\n",
      "P(L_ 6 = 1 , L_ 7 = 1  | Y =  2 ) =  0.2123548978029024\n",
      "P(L_ 6 = 1 , L_ 7 = 2  | Y =  2 ) =  0.164057013143767\n",
      "P(L_ 6 = 2 , L_ 7 = 0  | Y =  2 ) =  0.0824122257113935\n",
      "P(L_ 6 = 2 , L_ 7 = 1  | Y =  2 ) =  0.18415466678180192\n",
      "P(L_ 6 = 2 , L_ 7 = 2  | Y =  2 ) =  0.14227052474261276\n",
      "Labelers =  (6, 8)\n",
      "P(L_ 6 = 0 , L_ 8 = 0  | Y =  2 ) =  0.027347267625071378\n",
      "P(L_ 6 = 0 , L_ 8 = 1  | Y =  2 ) =  0.04295108051707587\n",
      "P(L_ 6 = 0 , L_ 8 = 2  | Y =  2 ) =  0.049420070712305836\n",
      "P(L_ 6 = 1 , L_ 8 = 0  | Y =  2 ) =  0.10769207951084067\n",
      "P(L_ 6 = 1 , L_ 8 = 1  | Y =  2 ) =  0.16913992142713538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(L_ 6 = 1 , L_ 8 = 2  | Y =  2 ) =  0.19461216297176268\n",
      "P(L_ 6 = 2 , L_ 8 = 0  | Y =  2 ) =  0.09339064864054622\n",
      "P(L_ 6 = 2 , L_ 8 = 1  | Y =  2 ) =  0.14667795902997255\n",
      "P(L_ 6 = 2 , L_ 8 = 2  | Y =  2 ) =  0.16876880956528947\n",
      "Labelers =  (6, 9)\n",
      "P(L_ 6 = 0 , L_ 9 = 0  | Y =  2 ) =  0.014276374198403191\n",
      "P(L_ 6 = 0 , L_ 9 = 1  | Y =  2 ) =  0.05203914164442935\n",
      "P(L_ 6 = 0 , L_ 9 = 2  | Y =  2 ) =  0.05340290301162052\n",
      "P(L_ 6 = 1 , L_ 9 = 0  | Y =  2 ) =  0.055253666102935216\n",
      "P(L_ 6 = 1 , L_ 9 = 1  | Y =  2 ) =  0.20634070842217173\n",
      "P(L_ 6 = 1 , L_ 9 = 2  | Y =  2 ) =  0.20984978938463167\n",
      "P(L_ 6 = 2 , L_ 9 = 0  | Y =  2 ) =  0.04767209270825129\n",
      "P(L_ 6 = 2 , L_ 9 = 1  | Y =  2 ) =  0.17773999347475408\n",
      "P(L_ 6 = 2 , L_ 9 = 2  | Y =  2 ) =  0.18342533105280276\n",
      "Labelers =  (7, 8)\n",
      "P(L_ 7 = 0 , L_ 8 = 0  | Y =  2 ) =  0.04604619095659611\n",
      "P(L_ 7 = 0 , L_ 8 = 1  | Y =  2 ) =  0.07231929016496216\n",
      "P(L_ 7 = 0 , L_ 8 = 2  | Y =  2 ) =  0.0832114910273368\n",
      "P(L_ 7 = 1 , L_ 8 = 0  | Y =  2 ) =  0.10289261142334319\n",
      "P(L_ 7 = 1 , L_ 8 = 1  | Y =  2 ) =  0.161601796705473\n",
      "P(L_ 7 = 1 , L_ 8 = 2  | Y =  2 ) =  0.18594052141686043\n",
      "P(L_ 7 = 2 , L_ 8 = 0  | Y =  2 ) =  0.07949119339651896\n",
      "P(L_ 7 = 2 , L_ 8 = 1  | Y =  2 ) =  0.12484787410374862\n",
      "P(L_ 7 = 2 , L_ 8 = 2  | Y =  2 ) =  0.14364903080516087\n",
      "Labelers =  (7, 9)\n",
      "P(L_ 7 = 0 , L_ 9 = 0  | Y =  2 ) =  0.023625238075335293\n",
      "P(L_ 7 = 0 , L_ 9 = 1  | Y =  2 ) =  0.08791161532911669\n",
      "P(L_ 7 = 0 , L_ 9 = 2  | Y =  2 ) =  0.09004011874444305\n",
      "P(L_ 7 = 1 , L_ 9 = 0  | Y =  2 ) =  0.05279192302833175\n",
      "P(L_ 7 = 1 , L_ 9 = 1  | Y =  2 ) =  0.1964435418955999\n",
      "P(L_ 7 = 1 , L_ 9 = 2  | Y =  2 ) =  0.2011994646217449\n",
      "P(L_ 7 = 2 , L_ 9 = 0  | Y =  2 ) =  0.04078497190592266\n",
      "P(L_ 7 = 2 , L_ 9 = 1  | Y =  2 ) =  0.15176468631663867\n",
      "P(L_ 7 = 2 , L_ 9 = 2  | Y =  2 ) =  0.15543844008286703\n",
      "Labelers =  (8, 9)\n",
      "P(L_ 8 = 0 , L_ 9 = 0  | Y =  2 ) =  0.026772557548585315\n",
      "P(L_ 8 = 0 , L_ 9 = 1  | Y =  2 ) =  0.09962319961934055\n",
      "P(L_ 8 = 0 , L_ 9 = 2  | Y =  2 ) =  0.10203423860853238\n",
      "P(L_ 8 = 1 , L_ 9 = 0  | Y =  2 ) =  0.04204866106147624\n",
      "P(L_ 8 = 1 , L_ 9 = 1  | Y =  2 ) =  0.156467472756626\n",
      "P(L_ 8 = 1 , L_ 9 = 2  | Y =  2 ) =  0.1602528271560815\n",
      "P(L_ 8 = 2 , L_ 9 = 0  | Y =  2 ) =  0.04838091439952814\n",
      "P(L_ 8 = 2 , L_ 9 = 1  | Y =  2 ) =  0.1800291711653887\n",
      "P(L_ 8 = 2 , L_ 9 = 2  | Y =  2 ) =  0.1843909576844411\n",
      "[[0.44892041 0.         0.1979985  0.21982931 0.23184051 0.19017902\n",
      "  0.18622118 0.21511018 0.19335238 0.20566561 0.17832659 0.21534878\n",
      "  0.22735624 0.15450669 0.20172626 0.16408343 0.21904401 0.15430887\n",
      "  0.21990254 0.16239705]\n",
      " [0.         0.50799138 0.21784672 0.251299   0.25973707 0.21976043\n",
      "  0.17928222 0.27548076 0.21908685 0.24149607 0.22216684 0.22309286\n",
      "  0.25370167 0.18114441 0.22784079 0.18436124 0.23503678 0.18238769\n",
      "  0.24336737 0.19228684]\n",
      " [0.1979985  0.21784672 0.43540153 0.         0.26050524 0.15062981\n",
      "  0.15495552 0.23144886 0.19619873 0.19385774 0.20690291 0.17760229\n",
      "  0.21541276 0.1616115  0.19570119 0.15588362 0.18745606 0.16322136\n",
      "  0.20551464 0.17090526]\n",
      " [0.21982931 0.251299   0.         0.48888167 0.2182242  0.24367396\n",
      "  0.19795223 0.24006919 0.20139753 0.23605548 0.17738624 0.24792807\n",
      "  0.25012696 0.16148309 0.21913068 0.1810149  0.25312182 0.16080962\n",
      "  0.24308221 0.17013913]\n",
      " [0.23184051 0.25973707 0.26050524 0.2182242  0.51368786 0.\n",
      "  0.19449837 0.26333964 0.22246368 0.23741316 0.21741743 0.23309633\n",
      "  0.27526077 0.17485439 0.23058991 0.1868226  0.24188333 0.18164757\n",
      "  0.26343245 0.17569369]\n",
      " [0.19017902 0.21976043 0.15062981 0.24367396 0.         0.42828814\n",
      "  0.16281213 0.21904468 0.18457486 0.19886245 0.17928874 0.19608302\n",
      "  0.20195262 0.15644138 0.19223117 0.15598237 0.20322145 0.15063889\n",
      "  0.19190522 0.17718   ]\n",
      " [0.18622118 0.17928222 0.15495552 0.19795223 0.19449837 0.16281213\n",
      "  0.38021984 0.         0.16341704 0.17686056 0.1508106  0.18152911\n",
      "  0.19288982 0.13013135 0.17056535 0.13937895 0.19099752 0.13014773\n",
      "  0.18675858 0.13668412]\n",
      " [0.21511018 0.27548076 0.23144886 0.24006919 0.26333964 0.21904468\n",
      "  0.         0.51132593 0.22118591 0.23688122 0.22154604 0.22743527\n",
      "  0.25550846 0.18221756 0.22958516 0.18541258 0.2379186  0.18464759\n",
      "  0.24516276 0.19329098]\n",
      " [0.19335238 0.21908685 0.19619873 0.20139753 0.22246368 0.18457486\n",
      "  0.16341704 0.22118591 0.43140346 0.         0.19624681 0.17986994\n",
      "  0.21551686 0.15384107 0.1907572  0.15915275 0.19972816 0.15428893\n",
      "  0.20678448 0.16318508]\n",
      " [0.20566561 0.24149607 0.19385774 0.23605548 0.23741316 0.19886245\n",
      "  0.17686056 0.23688122 0.         0.46379433 0.17608554 0.23789683\n",
      "  0.23435241 0.16046408 0.21227591 0.16605922 0.22435817 0.16093714\n",
      "  0.22634464 0.16902979]\n",
      " [0.17832659 0.22216684 0.20690291 0.17738624 0.21741743 0.17928874\n",
      "  0.1508106  0.22154604 0.19624681 0.17608554 0.41913287 0.\n",
      "  0.20676725 0.15432969 0.1867389  0.15727292 0.18427122 0.15512715\n",
      "  0.19686377 0.1649311 ]\n",
      " [0.21534878 0.22309286 0.17760229 0.24792807 0.23309633 0.19608302\n",
      "  0.18152911 0.22743527 0.17986994 0.23789683 0.         0.45739446\n",
      "  0.23335763 0.15409554 0.22011848 0.1582842  0.22961133 0.1542272\n",
      "  0.2266738  0.16123879]\n",
      " [0.22735624 0.25370167 0.21541276 0.25012696 0.27526077 0.20195262\n",
      "  0.19288982 0.25550846 0.21551686 0.23435241 0.20676725 0.23335763\n",
      "  0.50263478 0.         0.22556346 0.18345155 0.24130564 0.17530083\n",
      "  0.24531517 0.18374863]\n",
      " [0.15450669 0.18114441 0.1616115  0.16148309 0.17485439 0.15644138\n",
      "  0.13013135 0.18221756 0.15384107 0.16046408 0.15432969 0.15409554\n",
      "  0.         0.35092155 0.15758656 0.12699899 0.16075759 0.12646058\n",
      "  0.16709893 0.13432268]\n",
      " [0.20172626 0.22784079 0.19570119 0.21913068 0.23058991 0.19223117\n",
      "  0.17056535 0.22958516 0.1907572  0.21227591 0.1867389  0.22011848\n",
      "  0.22556346 0.15758656 0.44884473 0.         0.21263201 0.15804554\n",
      "  0.21716993 0.16656547]\n",
      " [0.16408343 0.18436124 0.15588362 0.1810149  0.1868226  0.15598237\n",
      "  0.13937895 0.18541258 0.15915275 0.16605922 0.15727292 0.1582842\n",
      "  0.18345155 0.12699899 0.         0.36413871 0.17419274 0.12732743\n",
      "  0.17688636 0.13402141]\n",
      " [0.21904401 0.23503678 0.18745606 0.25312182 0.24188333 0.20322145\n",
      "  0.19099752 0.2379186  0.19972816 0.22435817 0.18427122 0.22961133\n",
      "  0.24130564 0.16075759 0.21263201 0.17419274 0.47407528 0.\n",
      "  0.23407822 0.16848401]\n",
      " [0.15430887 0.18238769 0.16322136 0.16080962 0.18164757 0.15063889\n",
      "  0.13014773 0.18464759 0.15428893 0.16093714 0.15512715 0.1542272\n",
      "  0.17530083 0.12646058 0.15804554 0.12732743 0.         0.35193462\n",
      "  0.16788467 0.13439678]\n",
      " [0.21990254 0.24336737 0.20551464 0.24308221 0.26343245 0.19190522\n",
      "  0.18675858 0.24516276 0.20678448 0.22634464 0.19686377 0.2266738\n",
      "  0.24531517 0.16709893 0.21716993 0.17688636 0.23407822 0.16788467\n",
      "  0.48398431 0.        ]\n",
      " [0.16239705 0.19228684 0.17090526 0.17013913 0.17569369 0.17718\n",
      "  0.13668412 0.19329098 0.16318508 0.16902979 0.1649311  0.16123879\n",
      "  0.18374863 0.13432268 0.16656547 0.13402141 0.16848401 0.13439678\n",
      "  0.         0.37087279]]\n",
      "\n",
      "Condition number =  181.58655094972215 \n",
      "\n",
      "[[0.5004242  0.387563  ]\n",
      " [0.45909729 0.56623981]\n",
      " [0.27100543 0.63124965]\n",
      " [0.67402165 0.26832099]\n",
      " [0.49940803 0.53069969]\n",
      " [0.42987081 0.42640268]\n",
      " [0.43708518 0.31247511]\n",
      " [0.4633325  0.5685014 ]\n",
      " [0.38903648 0.48187603]\n",
      " [0.50339676 0.41661521]\n",
      " [0.29401042 0.56819355]\n",
      " [0.56813275 0.32546988]\n",
      " [0.52881637 0.47144416]\n",
      " [0.30230663 0.40883742]\n",
      " [0.44750991 0.45043493]\n",
      " [0.37769564 0.3479881 ]\n",
      " [0.57086411 0.35876896]\n",
      " [0.30084298 0.41280104]\n",
      " [0.52416203 0.43611984]\n",
      " [0.30724142 0.44667802]]\n",
      "[0.54365374 0.45634626]\n",
      "sig\n",
      " [[ 2.44230737e-01 -2.25047684e-01  1.26247858e-02 -1.09993643e-02\n",
      "   2.11171375e-03 -2.18537529e-03  1.20436188e-02 -1.14897184e-02\n",
      "   2.28608701e-03 -4.97103294e-03 -2.15351671e-03  3.22045817e-03\n",
      "   1.06796323e-04 -4.62780631e-05  3.12598405e-04 -2.17694670e-04\n",
      "   2.83221964e-04 -5.46919116e-04  1.66902696e-04 -1.91064659e-04]\n",
      " [-2.25047684e-01  2.47088134e-01 -1.29093177e-02  1.37354374e-02\n",
      "  -2.04371517e-03  2.28593570e-03 -1.05538663e-02  1.29360539e-02\n",
      "  -2.53020100e-03  8.19932853e-03  1.96277216e-03 -2.80925179e-03\n",
      "  -1.07424609e-04  4.75448680e-05 -2.46209633e-04  1.71580468e-04\n",
      "  -1.51578296e-04  6.31932146e-04 -1.52198001e-04  1.80230949e-04]\n",
      " [ 1.26247858e-02 -1.29093177e-02  2.13630371e-01 -1.76600514e-01\n",
      "   3.40480776e-02 -3.55375358e-02  5.44193445e-04 -5.82661144e-04\n",
      "   6.75148674e-05 -3.22955388e-04 -9.31802190e-05  1.39929608e-04\n",
      "   1.69242870e-03 -7.01419554e-04  1.20845737e-05 -7.83086306e-06\n",
      "  -1.13247823e-06 -1.77177305e-05  2.65586044e-03 -3.03540618e-03]\n",
      " [-1.09993643e-02  1.37354374e-02 -1.76600514e-01  2.09041785e-01\n",
      "  -2.97588104e-02  3.39426566e-02 -4.72535661e-04  6.76777292e-04\n",
      "  -1.63228054e-04  5.80198005e-04  7.69526767e-05 -1.08213621e-04\n",
      "  -1.37660368e-03  6.46513967e-04 -6.86939663e-06  4.02787399e-06\n",
      "   7.29332017e-06  2.40461289e-05 -2.39047701e-03  2.86079639e-03]\n",
      " [ 2.11171375e-03 -2.04371517e-03  3.40480776e-02 -2.97588104e-02\n",
      "   2.49569716e-01 -2.19979496e-01  1.51433211e-04 -1.38740468e-04\n",
      "   1.36218179e-04 -1.58649568e-04 -1.45967302e-05  2.22100774e-05\n",
      "   1.75087882e-02 -6.23677666e-03  1.11409975e-06 -4.11731977e-07\n",
      "   3.16570403e-06 -6.13337727e-06  1.54990789e-02 -1.59016516e-02]\n",
      " [-2.18537529e-03  2.28593570e-03 -3.55375358e-02  3.39426566e-02\n",
      "  -2.19979496e-01  2.44854426e-01 -1.38732020e-04  1.40337910e-04\n",
      "  -1.10241393e-04  1.50169497e-04  1.50140347e-05 -2.23957049e-05\n",
      "  -1.33692608e-02  6.23750034e-03 -1.18948625e-06  5.09774987e-07\n",
      "  -1.86070251e-06  5.79070950e-06 -1.54552712e-02  1.84595564e-02]\n",
      " [ 1.20436188e-02 -1.05538663e-02  5.44193445e-04 -4.72535661e-04\n",
      "   1.51433211e-04 -1.38732020e-04  2.31800386e-01 -1.91164961e-01\n",
      "   2.25902058e-03 -2.16610467e-03 -7.56473379e-05  1.16730096e-04\n",
      "   4.43884259e-06 -2.58563068e-06 -3.89961447e-06  7.77350839e-06\n",
      "   4.18775640e-03 -2.03605544e-04  1.63131388e-05 -1.83851469e-05]\n",
      " [-1.14897184e-02  1.29360539e-02 -5.82661144e-04  6.76777292e-04\n",
      "  -1.38740468e-04  1.40337910e-04 -1.91164961e-01  2.47127676e-01\n",
      "  -1.82421795e-03  1.99544677e-03  7.86066792e-05 -1.10860989e-04\n",
      "  -4.79179322e-06  2.68828397e-06  2.89046099e-06 -5.86675476e-06\n",
      "   1.04556615e-03  1.77310815e-03 -1.37881037e-05  1.59518473e-05]\n",
      " [ 2.28608701e-03 -2.53020100e-03  6.75148674e-05 -1.63228054e-04\n",
      "   1.36218179e-04 -1.10241393e-04  2.25902058e-03 -1.82421795e-03\n",
      "   2.43156145e-01 -1.98083641e-01  9.11619172e-03 -1.18623700e-02\n",
      "  -7.34884341e-08 -1.42750958e-06 -2.94334206e-03  2.74630087e-03\n",
      "   9.56250166e-05 -1.15612337e-04  1.98440341e-05 -2.23672350e-05]\n",
      " [-4.97103294e-03  8.19932853e-03 -3.22955388e-04  5.80198005e-04\n",
      "  -1.58649568e-04  1.50169497e-04 -2.16610467e-03  1.99544677e-03\n",
      "  -1.98083641e-01  2.46820742e-01 -1.24027386e-02  2.05353378e-02\n",
      "  -1.97093420e-06  2.26708138e-06  4.16724505e-03 -3.46585281e-03\n",
      "  -8.16710066e-05  1.22321237e-04 -2.00833738e-05  2.31638907e-05]\n",
      " [-2.15351671e-03  1.96277216e-03 -9.31802190e-05  7.69526767e-05\n",
      "  -1.45967302e-05  1.50140347e-05 -7.56473379e-05  7.86066792e-05\n",
      "   9.11619172e-03 -1.24027386e-02  2.24809668e-01 -1.75202324e-01\n",
      "  -8.54158521e-07  3.57652355e-07 -1.58564506e-03  6.67122608e-03\n",
      "  -1.90282952e-06  4.02787603e-06 -1.04583179e-06  1.18892306e-06]\n",
      " [ 3.22045817e-03 -2.80925179e-03  1.39929608e-04 -1.08213621e-04\n",
      "   2.22100774e-05 -2.23957049e-05  1.16730096e-04 -1.10860989e-04\n",
      "  -1.18623700e-02  2.05353378e-02 -1.75202324e-01  2.33575665e-01\n",
      "   1.27309009e-06 -5.28863827e-07  1.49954849e-02 -1.00593175e-02\n",
      "   3.09729597e-06 -5.49878049e-06  1.62698937e-06 -1.83350766e-06]\n",
      " [ 1.06796323e-04 -1.07424609e-04  1.69242870e-03 -1.37660368e-03\n",
      "   1.75087882e-02 -1.33692608e-02  4.43884259e-06 -4.79179322e-06\n",
      "  -7.34884341e-08 -1.97093420e-06 -8.54158521e-07  1.27309009e-06\n",
      "   2.49176438e-01 -1.74869048e-01  1.20014450e-07 -8.23503576e-08\n",
      "   1.58424594e-08 -1.69307815e-07  7.94659877e-04 -6.80231413e-04]\n",
      " [-4.62780631e-05  4.75448680e-05 -7.01419554e-04  6.46513967e-04\n",
      "  -6.23677666e-03  6.23750034e-03 -2.58563068e-06  2.68828397e-06\n",
      "  -1.42750958e-06  2.26708138e-06  3.57652355e-07 -5.28863827e-07\n",
      "  -1.74869048e-01  2.24960042e-01 -3.91673670e-08  2.36987488e-08\n",
      "  -3.90831623e-08  1.17350136e-07 -4.14668460e-04  4.90160736e-04]\n",
      " [ 3.12598405e-04 -2.46209633e-04  1.20845737e-05 -6.86939663e-06\n",
      "   1.11409975e-06 -1.18948625e-06 -3.89961447e-06  2.89046099e-06\n",
      "  -2.94334206e-03  4.16724505e-03 -1.58564506e-03  1.49954849e-02\n",
      "   1.20014450e-07 -3.91673670e-08  2.47381016e-01 -1.63420186e-01\n",
      "  -2.66392148e-07  2.91389275e-07  1.64433511e-08 -1.43394004e-08]\n",
      " [-2.17694670e-04  1.71580468e-04 -7.83086306e-06  4.02787399e-06\n",
      "  -4.11731977e-07  5.09774987e-07  7.77350839e-06 -5.86675476e-06\n",
      "   2.74630087e-03 -3.46585281e-03  6.67122608e-03 -1.00593175e-02\n",
      "  -8.23503576e-08  2.36987488e-08 -1.63420186e-01  2.31322758e-01\n",
      "   3.79021465e-07 -4.25138429e-07  3.81684031e-08 -4.62692585e-08]\n",
      " [ 2.83221964e-04 -1.51578296e-04 -1.13247823e-06  7.29332017e-06\n",
      "   3.16570403e-06 -1.86070251e-06  4.18775640e-03  1.04556615e-03\n",
      "   9.56250166e-05 -8.16710066e-05 -1.90282952e-06  3.09729597e-06\n",
      "   1.58424594e-08 -3.90831623e-08 -2.66392148e-07  3.79021465e-07\n",
      "   2.38167546e-01 -1.60952315e-01  4.75142785e-07 -5.12385837e-07]\n",
      " [-5.46919116e-04  6.31932146e-04 -1.77177305e-05  2.40461289e-05\n",
      "  -6.13337727e-06  5.79070950e-06 -2.03605544e-04  1.77310815e-03\n",
      "  -1.15612337e-04  1.22321237e-04  4.02787603e-06 -5.49878049e-06\n",
      "  -1.69307815e-07  1.17350136e-07  2.91389275e-07 -4.25138429e-07\n",
      "  -1.60952315e-01  2.24966878e-01 -6.86355639e-07  7.87359843e-07]\n",
      " [ 1.66902696e-04 -1.52198001e-04  2.65586044e-03 -2.39047701e-03\n",
      "   1.54990789e-02 -1.54552712e-02  1.63131388e-05 -1.37881037e-05\n",
      "   1.98440341e-05 -2.00833738e-05 -1.04583179e-06  1.62698937e-06\n",
      "   7.94659877e-04 -4.14668460e-04  1.64433511e-08  3.81684031e-08\n",
      "   4.75142785e-07 -6.86355639e-07  2.47820412e-01 -1.76450932e-01]\n",
      " [-1.91064659e-04  1.80230949e-04 -3.03540618e-03  2.86079639e-03\n",
      "  -1.59016516e-02  1.84595564e-02 -1.83851469e-05  1.59518473e-05\n",
      "  -2.23672350e-05  2.31638907e-05  1.18892306e-06 -1.83350766e-06\n",
      "  -6.80231413e-04  4.90160736e-04 -1.43394004e-08 -4.62692586e-08\n",
      "  -5.12385837e-07  7.87359843e-07 -1.76450932e-01  2.28502574e-01]]\n",
      "\n",
      "Condition number =  25.76949215010394 \n",
      "\n",
      "moment of truth!!!\n",
      "[[ 2.56287428e+01  2.33661129e+01 -8.46365174e-01 -9.01931653e-01\n",
      "  -3.02733861e-02 -1.43838264e-02 -8.09588262e-01 -6.55873208e-01\n",
      "  -5.98579698e-01 -7.37957104e-01 -1.04748444e-02 -4.54528877e-02\n",
      "   2.42643789e-03  1.73015882e-03 -6.65023548e-04  6.90481160e-04\n",
      "   4.55198023e-03  4.48620037e-03 -1.00576101e-04  2.02632420e-03]\n",
      " [ 2.33661129e+01  2.53854764e+01 -6.88302076e-01 -1.01897127e+00\n",
      "  -2.90969917e-02 -1.29921213e-02 -7.11057302e-01 -7.88884841e-01\n",
      "  -7.45974825e-01 -9.72398539e-01  6.68243012e-03  3.56189015e-02\n",
      "   2.55913134e-03  1.76842704e-03  6.36805780e-04 -7.48300302e-04\n",
      "  -3.03663698e-03 -1.09002874e-02 -1.28603928e-04  2.08189292e-03]\n",
      " [-8.46365174e-01 -6.88302076e-01  1.56315418e+01  1.31367398e+01\n",
      "  -8.23168055e-01 -2.93175877e-01  2.22129458e-03 -9.72822120e-04\n",
      "   4.46895038e-03 -1.38807749e-03 -2.29944110e-05  4.90829518e-04\n",
      "   1.31421891e-02  6.45893012e-03  1.74969203e-05 -2.59363252e-05\n",
      "   1.88404763e-05 -2.85925395e-04 -1.70896184e-03  8.12010195e-03]\n",
      " [-9.01931653e-01 -1.01897127e+00  1.31367398e+01  1.59532173e+01\n",
      "  -7.59693224e-01 -9.86042172e-01  2.95195019e-03  1.14643676e-03\n",
      "   3.55926655e-03 -1.64360225e-03  6.16017912e-05  4.99656911e-05\n",
      "   7.28336161e-04  1.98302948e-03 -3.06500381e-06  6.04149444e-06\n",
      "  -1.13329474e-04 -8.10501407e-05  5.54986678e-04  2.04324476e-03]\n",
      " [-3.02733861e-02 -2.90969917e-02 -8.23168055e-01 -7.59693224e-01\n",
      "   1.93974779e+01  1.73839540e+01 -1.58485151e-03  1.16481505e-05\n",
      "  -2.52273981e-03  9.34115679e-04 -9.37794834e-06 -1.81685185e-04\n",
      "  -8.57534040e-01 -6.11141715e-01 -5.12081434e-06  7.17163169e-06\n",
      "   2.52693798e-05  1.20370453e-04 -3.69776342e-01 -3.42688725e-01]\n",
      " [-1.43838264e-02 -1.29921213e-02 -2.93175877e-01 -9.86042172e-01\n",
      "   1.73839540e+01  1.98092255e+01 -6.43559640e-04  4.03167902e-05\n",
      "  -1.05912487e-03  3.82249052e-04 -2.46355566e-06 -8.25640854e-05\n",
      "  -4.58092310e-01 -4.20685829e-01 -2.46335423e-06  3.50317722e-06\n",
      "   8.24244828e-06  5.32398475e-05 -2.88317576e-01 -6.05178038e-01]\n",
      " [-8.09588262e-01 -7.11057302e-01  2.22129458e-03  2.95195019e-03\n",
      "  -1.58485151e-03 -6.43559640e-04  1.19818582e+01  9.27353572e+00\n",
      "  -3.15319332e-02  1.23726251e-02 -2.20740014e-04 -1.82922140e-03\n",
      "   1.56860180e-04  1.04442328e-04 -4.19829208e-05  5.50532644e-05\n",
      "  -5.67132263e-01 -4.67994691e-01 -9.46274827e-06  1.23733451e-04]\n",
      " [-6.55873208e-01 -7.88884841e-01 -9.72822120e-04  1.14643676e-03\n",
      "   1.16481505e-05  4.03167902e-05  9.27353572e+00  1.12361653e+01\n",
      "  -2.84645301e-03  1.30645583e-03 -4.80792406e-05 -4.50172117e-05\n",
      "   8.54686420e-06  3.74077980e-06  2.19897095e-06 -4.43548747e-06\n",
      "  -5.14738514e-01 -4.47816456e-01 -1.29519120e-06  4.83011168e-06]\n",
      " [-5.98579698e-01 -7.45974825e-01  4.46895038e-03  3.55926655e-03\n",
      "  -2.52273981e-03 -1.05912487e-03 -3.15319332e-02 -2.84645301e-03\n",
      "   1.19260761e+01  9.60754873e+00 -3.36407310e-01 -4.92535941e-01\n",
      "   2.40224586e-04  1.61851262e-04  2.96041307e-03 -7.27486619e-03\n",
      "   6.77367098e-04  2.01764231e-03 -1.37312407e-05  1.91357504e-04]\n",
      " [-7.37957104e-01 -9.72398539e-01 -1.38807749e-03 -1.64360225e-03\n",
      "   9.34115679e-04  3.82249052e-04  1.23726251e-02  1.30645583e-03\n",
      "   9.60754873e+00  1.18309213e+01 -3.99648106e-01 -8.51185485e-01\n",
      "  -9.16542908e-05 -6.11869734e-05 -2.07370337e-02  2.30849006e-02\n",
      "  -2.76540452e-04 -7.68461122e-04  5.46487829e-06 -7.24557363e-05]\n",
      " [-1.04748444e-02  6.68243012e-03 -2.29944110e-05  6.16017912e-05\n",
      "  -9.37794834e-06 -2.46355567e-06 -2.20740014e-04 -4.80792406e-05\n",
      "  -3.36407310e-01 -3.99648106e-01  1.07932100e+01  8.14088106e+00\n",
      "   1.29465494e-06  7.88346696e-07 -7.39968974e-01 -4.82022506e-01\n",
      "   6.33888641e-06  1.06745085e-05 -1.07555952e-07  9.49010937e-07]\n",
      " [-4.54528877e-02  3.56189015e-02  4.90829518e-04  4.99656911e-05\n",
      "  -1.81685185e-04 -8.25640854e-05 -1.82922140e-03 -4.50172117e-05\n",
      "  -4.92535941e-01 -8.51185485e-01  8.14088106e+00  1.04751501e+01\n",
      "   1.55871214e-05  1.08598855e-05 -8.11913528e-01 -3.59814476e-01\n",
      "   3.24819301e-05  1.31766170e-04 -7.47807361e-07  1.27673993e-05]\n",
      " [ 2.42643789e-03  2.55913134e-03  1.31421891e-02  7.28336161e-04\n",
      "  -8.57534040e-01 -4.58092310e-01  1.56860180e-04  8.54686420e-06\n",
      "   2.40224586e-04 -9.16542908e-05  1.29465494e-06  1.55871214e-05\n",
      "   8.89167396e+00  6.90078879e+00  4.02179971e-07 -5.48724616e-07\n",
      "  -3.05124904e-06 -1.07249446e-05  5.49691465e-04 -1.04126267e-02]\n",
      " [ 1.73015882e-03  1.76842704e-03  6.45893012e-03  1.98302948e-03\n",
      "  -6.11141715e-01 -4.20685829e-01  1.04442328e-04  3.74077981e-06\n",
      "   1.61851262e-04 -6.11869734e-05  7.88346695e-07  1.08598855e-05\n",
      "   6.90078879e+00  9.80420545e+00  2.88822284e-07 -3.97741482e-07\n",
      "  -1.92100195e-06 -7.37996438e-06 -3.89527311e-04 -9.27242669e-03]\n",
      " [-6.65023548e-04  6.36805780e-04  1.74969203e-05 -3.06500381e-06\n",
      "  -5.12081434e-06 -2.46335423e-06 -4.19829208e-05  2.19897095e-06\n",
      "   2.96041307e-03 -2.07370337e-02 -7.39968974e-01 -8.11913528e-01\n",
      "   4.02179968e-07  2.88822281e-07  7.64608869e+00  5.38733928e+00\n",
      "   5.62155112e-07  3.42029473e-06 -1.58508390e-08  3.37871261e-07]\n",
      " [ 6.90481160e-04 -7.48300302e-04 -2.59363252e-05  6.04149444e-06\n",
      "   7.17163169e-06  3.50317722e-06  5.50532644e-05 -4.43548747e-06\n",
      "  -7.27486619e-03  2.30849006e-02 -4.82022506e-01 -3.59814476e-01\n",
      "  -5.48724619e-07 -3.97741485e-07  5.38733928e+00  8.12758959e+00\n",
      "  -6.49135066e-07 -4.67530372e-06  2.01555142e-08 -4.64590627e-07]\n",
      " [ 4.55198023e-03 -3.03663698e-03  1.88404763e-05 -1.13329474e-04\n",
      "   2.52693798e-05  8.24244827e-06 -5.67132263e-01 -5.14738514e-01\n",
      "   6.77367098e-04 -2.76540452e-04  6.33888640e-06  3.24819301e-05\n",
      "  -3.05124904e-06 -1.92100195e-06  5.62155113e-07 -6.49135065e-07\n",
      "   8.15746057e+00  5.83981035e+00  2.28292291e-07 -2.29842115e-06]\n",
      " [ 4.48620037e-03 -1.09002874e-02 -2.85925395e-04 -8.10501407e-05\n",
      "   1.20370453e-04  5.32398475e-05 -4.67994691e-01 -4.47816456e-01\n",
      "   2.01764231e-03 -7.68461122e-04  1.06745085e-05  1.31766170e-04\n",
      "  -1.07249446e-05 -7.37996438e-06  3.42029473e-06 -4.67530372e-06\n",
      "   5.83981035e+00  8.62633388e+00  5.51455525e-07 -8.69426644e-06]\n",
      " [-1.00576101e-04 -1.28603928e-04 -1.70896184e-03  5.54986678e-04\n",
      "  -3.69776342e-01 -2.88317576e-01 -9.46274827e-06 -1.29519119e-06\n",
      "  -1.37312407e-05  5.46487830e-06 -1.07555954e-07 -7.47807364e-07\n",
      "   5.49691465e-04 -3.89527311e-04 -1.58508363e-08  2.01555169e-08\n",
      "   2.28292293e-07  5.51455528e-07  8.97103449e+00  6.92501322e+00]\n",
      " [ 2.02632420e-03  2.08189292e-03  8.12010195e-03  2.04324476e-03\n",
      "  -3.42688725e-01 -6.05178038e-01  1.23733451e-04  4.83011168e-06\n",
      "   1.91357504e-04 -7.24557363e-05  9.49010934e-07  1.27673993e-05\n",
      "  -1.04126267e-02 -9.27242669e-03  3.37871265e-07 -4.64590623e-07\n",
      "  -2.29842115e-06 -8.69426643e-06  6.92501322e+00  9.74896378e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic dataset\n",
    "np.random.seed(1)\n",
    "N = 10000\n",
    "M = 10\n",
    "K = 2\n",
    "EDGE_PROB=1.0\n",
    "data = SingleTaskTreeDepsGenerator(N, M, k=K, edge_prob=EDGE_PROB)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjgAAAI3CAYAAACWIyEjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/z81Uukyrlna4gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f51f548e5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# mask the diagonals so we don't get influenced by them unfairly\n",
    "sg_no_diag = np.copy(data.sig_inv)\n",
    "for i in range(M):\n",
    "    sg_no_diag[i*2:i*2+2,i*2:i*2+2] = np.zeros([2,2])\n",
    "\n",
    "visualize_matrix(np.abs(sg_no_diag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the `LabelModel`\n",
    "\n",
    "Note that:\n",
    "* The `train` method assembles other data structures, such as the dependencies junction tree, etc.\n",
    "* The `higher_order_cliques` kwarg controls whether or not to include them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm = LabelModel(k=data.k, class_balance=data.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm.config['higher_order_cliques'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Generate the \"correct\" mu\\nlm._set_constants(data.L)\\nlm._set_dependencies(data.E)\\nmu = compute_mu(lm._get_augmented_label_matrix(data.L.todense()), data.Y, K, data.p)\\n\\n# Compute O, O_inv, P based on L\\nlm._generate_O(data.L.todense())\\nO = lm.O.numpy()\\nprint(O)\\nd, d = O.shape\\nO_inv = np.linalg.inv(O)\\nP = np.diag(data.p)\\n\\nJJT = np.linalg.inv(np.linalg.inv(P) - mu.T @ O_inv @ mu)\\nZZT = O_inv @ mu @ JJT @ mu.T @ O_inv.T'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Generate the \"correct\" mu\n",
    "lm._set_constants(data.L)\n",
    "lm._set_dependencies(data.E)\n",
    "mu = compute_mu(lm._get_augmented_label_matrix(data.L.todense()), data.Y, K, data.p)\n",
    "\n",
    "# Compute O, O_inv, P based on L\n",
    "lm._generate_O(data.L.todense())\n",
    "O = lm.O.numpy()\n",
    "print(O)\n",
    "d, d = O.shape\n",
    "O_inv = np.linalg.inv(O)\n",
    "P = np.diag(data.p)\n",
    "\n",
    "JJT = np.linalg.inv(np.linalg.inv(P) - mu.T @ O_inv @ mu)\n",
    "ZZT = O_inv @ mu @ JJT @ mu.T @ O_inv.T'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that JJT is indeed PSD ==> ZZT is rank k\n",
    "#np.linalg.eig(JJT)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.linalg.eig((ZZT + ZZT.T)/2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: O is ill-conditioned: kappa(O) = 8393.67.\n",
      "Computing O^{-1}...\n",
      "Estimating Z...\n",
      "[Epoch 0] Loss: 1265079.375000\n",
      "[Epoch 5000] Loss: 14751.180664\n",
      "[Epoch 10000] Loss: 14723.509766\n",
      "[Epoch 15000] Loss: 14711.140625\n",
      "[Epoch 20000] Loss: 14752.640625\n",
      "[Epoch 25000] Loss: 14704.625000\n",
      "[Epoch 30000] Loss: 14703.866211\n",
      "[Epoch 35000] Loss: 14705.026367\n",
      "[Epoch 40000] Loss: 14704.472656\n",
      "[Epoch 45000] Loss: 14703.853516\n",
      "[Epoch 49999] Loss: 14705.061523\n",
      "Estimating \\mu...\n",
      "[Epoch 0] Loss: 1047.384521\n",
      "[Epoch 5000] Loss: 0.000375\n",
      "[Epoch 10000] Loss: 0.000089\n",
      "[Epoch 15000] Loss: 0.000040\n",
      "[Epoch 20000] Loss: 0.000022\n",
      "[Epoch 25000] Loss: 0.000017\n",
      "[Epoch 30000] Loss: 0.000014\n",
      "[Epoch 35000] Loss: 0.000014\n",
      "[Epoch 40000] Loss: 0.000013\n",
      "[Epoch 45000] Loss: 0.000013\n",
      "[Epoch 49999] Loss: 0.000013\n",
      "[[0.50375252 0.39056645]\n",
      " [0.45908841 0.55807803]\n",
      " [0.26853377 0.62882962]\n",
      " [0.67783269 0.26338991]\n",
      " [0.49441699 0.52832268]\n",
      " [0.43565806 0.42539123]\n",
      " [0.43950211 0.31254133]\n",
      " [0.46750869 0.56226581]\n",
      " [0.3952041  0.49239586]\n",
      " [0.49606443 0.4004849 ]\n",
      " [0.30459455 0.5664536 ]\n",
      " [0.5590335  0.32642715]\n",
      " [0.52535237 0.46859158]\n",
      " [0.30313015 0.41701565]\n",
      " [0.45890536 0.45690985]\n",
      " [0.36207212 0.34868856]\n",
      " [0.57550796 0.35640291]\n",
      " [0.30660809 0.41701565]\n",
      " [0.53377265 0.43729337]\n",
      " [0.30624199 0.43861583]\n",
      " [0.11568735 0.27925942]\n",
      " [0.13655501 0.18889134]\n",
      " [0.29434377 0.13819705]\n",
      " [0.17206663 0.12409081]\n",
      " [0.26615413 0.2565572 ]\n",
      " [0.14936848 0.20321799]\n",
      " [0.22991031 0.15649107]\n",
      " [0.1387516  0.22085078]\n",
      " [0.14991763 0.38770112]\n",
      " [0.0948197  0.21534053]\n",
      " [0.32070291 0.093013  ]\n",
      " [0.31850632 0.1571523 ]\n",
      " [0.16584294 0.2323121 ]\n",
      " [0.27658796 0.11307031]\n",
      " [0.2110562  0.23517743]\n",
      " [0.20721215 0.27022261]\n",
      " [0.28372689 0.24862244]\n",
      " [0.14570749 0.22415693]\n",
      " [0.21160535 0.19969143]\n",
      " [0.13344316 0.17610756]\n",
      " [0.14881933 0.25942253]\n",
      " [0.33150284 0.093013  ]\n",
      " [0.10616877 0.34119462]\n",
      " [0.32784185 0.15605025]\n",
      " [0.24784917 0.11791933]\n",
      " [0.14955153 0.12034384]\n",
      " [0.28372689 0.19880979]\n",
      " [0.12520593 0.24928367]\n",
      " [0.22130697 0.14877672]\n",
      " [0.23265605 0.19374036]\n",
      " [0.20318506 0.14789508]\n",
      " [0.21856123 0.34383954]\n",
      " [0.15010068 0.27044302]\n",
      " [0.18213436 0.17236059]\n",
      " [0.1151382  0.23473661]\n",
      " [0.3276588  0.12475204]]\n",
      "[[ 0.4615968   0.4377171 ]\n",
      " [ 0.5046731   0.5056992 ]\n",
      " [ 0.14725089  0.7708281 ]\n",
      " [ 0.87413985  0.03175215]\n",
      " [ 0.34982967  0.7000802 ]\n",
      " [ 0.64975995  0.16982818]\n",
      " [ 0.40425387  0.35409465]\n",
      " [ 0.50220937  0.52098274]\n",
      " [ 0.42520598  0.45687622]\n",
      " [ 0.46467134  0.44017953]\n",
      " [ 0.3804834   0.47443423]\n",
      " [ 0.49152404  0.4083808 ]\n",
      " [ 0.50158834  0.49689212]\n",
      " [ 0.34127533  0.3712653 ]\n",
      " [ 0.45543423  0.4611072 ]\n",
      " [ 0.36638024  0.34350327]\n",
      " [ 0.5104302   0.43576318]\n",
      " [ 0.33696026  0.38014024]\n",
      " [ 0.48319778  0.49823725]\n",
      " [ 0.36878273  0.3630875 ]\n",
      " [ 0.16235292  0.22228943]\n",
      " [ 0.15765643  0.1633921 ]\n",
      " [ 0.2468882   0.19583988]\n",
      " [ 0.15965483  0.13931067]\n",
      " [ 0.18344909  0.35467714]\n",
      " [ 0.11120848  0.24846308]\n",
      " [ 0.30102366  0.07248201]\n",
      " [ 0.25787166  0.07762351]\n",
      " [ 0.0529604   0.5020266 ]\n",
      " [ 0.10342068  0.2035743 ]\n",
      " [ 0.31586334  0.09955816]\n",
      " [ 0.5207348  -0.08265256]\n",
      " [ 0.17802526  0.21653524]\n",
      " [ 0.22355928  0.17614402]\n",
      " [ 0.22845267  0.21560657]\n",
      " [ 0.23023875  0.24450321]\n",
      " [ 0.18360744  0.23018888]\n",
      " [ 0.17967014  0.17577802]\n",
      " [ 0.14947909  0.19416288]\n",
      " [ 0.2685695   0.19674326]\n",
      " [ 0.19215758  0.35729003]\n",
      " [ 0.11315113  0.2629388 ]\n",
      " [ 0.3150321   0.07648715]\n",
      " [ 0.22225413  0.0695312 ]\n",
      " [ 0.21161589  0.16170973]\n",
      " [ 0.13765784  0.13418342]\n",
      " [ 0.26135242  0.22587788]\n",
      " [ 0.162339    0.20485422]\n",
      " [ 0.19877893  0.17441042]\n",
      " [ 0.22039579  0.20672363]\n",
      " [ 0.19231734  0.16154806]\n",
      " [ 0.26519716  0.28926215]\n",
      " [ 0.0709559   0.35002917]\n",
      " [ 0.40165767  0.00862213]\n",
      " [ 0.06873421  0.38571528]\n",
      " [ 0.44541308  0.01785215]]\n",
      "Average absolute error: 0.06950499439287791\n"
     ]
    }
   ],
   "source": [
    "lm.train(\n",
    "    data.L,\n",
    "    deps=data.E,\n",
    "    all_unary_cliques=True,\n",
    "    higher_order_cliques=True,\n",
    "    n_epochs=50000,\n",
    "    print_every=5000,\n",
    "    lr=0.0001,\n",
    "    l2=0,\n",
    "    O_inv_prec=1024,\n",
    "    #O_inv=ZZT\n",
    ")\n",
    "\n",
    "lm._set_constants(data.L)\n",
    "lm._set_dependencies(data.E)\n",
    "mu = compute_mu(lm._get_augmented_label_matrix(data.L.todense()), data.Y, K, data.p)\n",
    "\n",
    "\n",
    "# Test against the true parameter values\n",
    "mu_est = lm.mu.detach().numpy()\n",
    "print(mu)\n",
    "print(mu_est)\n",
    "print(f\"Average absolute error: {np.mean(np.abs(mu_est - mu))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check that the true $Z$ gets lower loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'O' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-adb0a025c1d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'O' is not defined"
     ]
    }
   ],
   "source": [
    "sorted(np.linalg.eig(O)[0])[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "O = lm.O.numpy()\n",
    "d, d = O.shape\n",
    "O_inv = lm.O_inv.numpy()\n",
    "mask = lm.mask.numpy()\n",
    "P = lm.P.numpy()\n",
    "\n",
    "JJT = np.linalg.inv(np.linalg.inv(P) - mu.T @ O_inv @ mu)\n",
    "ZZT = O_inv @ mu @ JJT @ mu.T @ O_inv.T\n",
    "\n",
    "np.linalg.norm((O_inv + ZZT) * mask)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seed=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_matrix(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#visualize_matrix(np.abs((O_inv + ZZT) * mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.c_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_est = lm.Z.detach().numpy()\n",
    "visualize_matrix(np.abs((O_inv + Z_est @ Z_est.T) * mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seed=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_matrix(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_matrix(np.abs((O_inv + ZZT) * mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_est = lm.Z.detach().numpy()\n",
    "visualize_matrix(np.abs((O_inv + Z_est @ Z_est.T) * mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seed=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_matrix(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_matrix(np.abs((O_inv + ZZT) * mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_est = lm.Z.detach().numpy()\n",
    "visualize_matrix(np.abs((O_inv + Z_est @ Z_est.T) * mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_matrix(np.abs(mu_est - mu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_matrix(np.abs(mu_est - mu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.c_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying to solve with `scipy.optimize.minimize`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "O_inv = lm.O_inv.numpy()\n",
    "mask = lm.mask.numpy()\n",
    "\n",
    "z0 = np.random.randn(lm.d * lm.k)\n",
    "l import LabelModl import LabelModel\n",
    "from metal.label_model.utils import (\n",
    "    compute_mu,\n",
    "    compute_covariance,\n",
    "    compute_inv_covariance,\n",
    "    print_matrix,el\n",
    "from metal.label_model.utils import (\n",
    "    compute_mu,\n",
    "    compute_covariance,\n",
    "    compute_inv_covariance,\n",
    "    print_matrix,\n",
    "def objective_fn(z):\n",
    "    Z = z.reshape(-1, data.k)\n",
    "    return np.linalg.norm( (O_inv + Z @ Z.T) * mask )**2\n",
    "\n",
    "def gradient_fn(z):\n",
    "    Z = z.reshape(-1, data.k)\n",
    "    X = (O_inv + Z @ Z.T) * mask\n",
    "    return np.ravel(X @ Z)\n",
    "\n",
    "res = minimize(objective_fn, z0, jac=gradient_fn, method='BFGS')\n",
    "Z = res['x'].reshape(-1, data.k)\n",
    "res['fun']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "O = lm.O.numpy()\n",
    "P = lm.P.numpy()\n",
    "I_k = np.eye(data.k)\n",
    "Q = O @ Z @ np.linalg.inv(I_k + Z.T @ O @ Z) @ Z.T @ O\n",
    "\n",
    "mu0 = np.random.randn(lm.d * lm.k)\n",
    "\n",
    "def objective_fn_2(mu):\n",
    "    M = mu.reshape(-1, data.k)\n",
    "    return np.linalg.norm(Q - M @ P @ M.T)**2 + np.linalg.norm(np.sum(M @ P, 1) - np.diag(O))**2\n",
    "\n",
    "res_2 = minimize(objective_fn_2, mu0, method='BFGS')\n",
    "M = res_2['x'].reshape(-1, data.k)\n",
    "res_2['fun']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test against the true parameter values\n",
    "print(f\"Average absolute error: {np.mean(np.abs(M - mu))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the inverse covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = compute_inv_covariance(\n",
    "    lm._get_augmented_label_matrix(data.L.todense()),\n",
    "    data.Y,\n",
    "    data.k,\n",
    "    data.p\n",
    ")\n",
    "visualize_matrix(np.abs(J))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_matrix(lm.mask.numpy(), fig_size=[5,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "O_inv = lm.O_inv.numpy()\n",
    "Z = lm.Z.detach().numpy()\n",
    "mask = lm.mask.numpy()\n",
    "visualize_matrix(np.abs((O_inv + Z@Z.T) * mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at the internal 'bookkeeping' of cliques..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.c_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependency edge weights\n",
    "[((i,j), data.theta[(i,j)]) for i,j in data.E]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
