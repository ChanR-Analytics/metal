{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from  metal.utils import hard_to_soft\n",
    "import torch\n",
    "\n",
    "N = 1200\n",
    "X = np.random.random((N,500)) * 2 - 1\n",
    "\n",
    "Y = np.zeros((N,1))\n",
    "Y[:,0] = (X[:,0] > X[:,1] + 0.5).astype(int) + 1\n",
    "\n",
    "X = torch.tensor(X, dtype=torch.float)\n",
    "Y = torch.tensor(Y, dtype=torch.long)\n",
    "\n",
    "X_train = X[:1000]\n",
    "X_dev   = X[1000:1100]\n",
    "X_test  = X[1100:]\n",
    "\n",
    "Y_train = Y[:1000, 0]\n",
    "Y_dev   = Y[1000:1100]\n",
    "Y_test  = Y[1100:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=500, out_features=4, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (2): Linear(in_features=4, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "dict_keys(['print_every', 'use_cuda', 'data_loader_config', 'n_epochs', 'l2', 'validation_metric', 'validation_freq', 'optimizer_config', 'scheduler_config', 'checkpoint', 'checkpoint_config'])\n",
      "dict_keys(['print_every', 'use_cuda', 'data_loader_config', 'n_epochs', 'l2', 'validation_metric', 'validation_freq', 'optimizer_config', 'scheduler_config', 'checkpoint', 'checkpoint_config'])\n",
      "Saving model at iteration 0 with best score 0.660\n",
      "[E:0]\tTrain Loss: 0.704\tDev score: 0.660\n",
      "Saving model at iteration 1 with best score 0.710\n",
      "Saving model at iteration 2 with best score 0.740\n",
      "Saving model at iteration 3 with best score 0.760\n",
      "[E:5]\tTrain Loss: 0.049\tDev score: 0.760\n",
      "Saving model at iteration 9 with best score 0.770\n",
      "Saving model at iteration 10 with best score 0.780\n",
      "[E:10]\tTrain Loss: 0.033\tDev score: 0.780\n",
      "[E:15]\tTrain Loss: 0.029\tDev score: 0.780\n",
      "Saving model at iteration 18 with best score 0.790\n",
      "Saving model at iteration 19 with best score 0.800\n",
      "[E:20]\tTrain Loss: 0.026\tDev score: 0.780\n",
      "[E:25]\tTrain Loss: 0.024\tDev score: 0.780\n",
      "[E:30]\tTrain Loss: 0.023\tDev score: 0.750\n",
      "[E:35]\tTrain Loss: 0.023\tDev score: 0.750\n",
      "[E:39]\tTrain Loss: 0.023\tDev score: 0.750\n",
      "Restoring best model from iteration 19 with score 0.800\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    57      6    \n",
      " l=2    14     23    \n",
      "Accuracy: 0.760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.76"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from metal.end_model import EndModel\n",
    "from metal.end_model.em_defaults import *\n",
    "\n",
    "em = EndModel(\n",
    "    seed=1,\n",
    "    dropout=0.0,\n",
    "    batchnorm=False,\n",
    "    layer_out_dims=[500,4,2],\n",
    ")\n",
    "\n",
    "print(em.config[\"train_config\"].keys())\n",
    "\n",
    "em.train(X_train, Y_train, X_dev, Y_dev, n_epochs=40, print_every=5)\n",
    "em.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rs_max_search = 10\n",
    "\n",
    "search_space = {\n",
    "    'n_epochs': [50, 100, 150],\n",
    "    'batchnorm' : [True, False],\n",
    "    'dropout': [0, .1, .2, .3, .4, .5],\n",
    "    'lr': {'range': [1e-5, 1], 'scale': 'log'},\n",
    "    'layer_out_dims' : [[500,4,2], [500, 50, 2], [500, 100, 2], [500, 200, 2], [500, 400, 2]],\n",
    "    'print_every': 50\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# First run basic grid search / random search\n",
    "from metal.label_model import LabelModel\n",
    "from metal.end_model import EndModel\n",
    "from metal.tuners.random_tuner import RandomSearchTuner\n",
    "\n",
    "def run_random_search(seed=123):\n",
    "    tuner = RandomSearchTuner(EndModel, seed=seed)\n",
    "    init_args = []\n",
    "    train_args = [X_train, Y_train]\n",
    "    model = tuner.search(init_args, train_args, X_dev, Y_dev, search_space,\n",
    "                         max_search=rs_max_search, metric='f1',\n",
    "                        verbose=False)\n",
    "    return tuner.get_run_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Hyperband\n",
    "from metal.label_model import LabelModel\n",
    "from metal.end_model import EndModel\n",
    "from metal.tuners.hyperband_tuner import HyperbandTuner\n",
    "\n",
    "def run_hyperband(seed=123):    \n",
    "    tuner = HyperbandTuner(EndModel, hyperband_epochs_budget=1000, seed=seed)\n",
    "    init_args = []\n",
    "    train_args = [X_train, Y_train]\n",
    "\n",
    "    model = tuner.search(init_args, train_args, X_dev, Y_dev, search_space, verbose=False)\n",
    "    return tuner.get_run_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=500, out_features=4, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.3)\n",
      "  )\n",
      "  (2): Linear(in_features=4, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "dict_keys(['print_every', 'use_cuda', 'data_loader_config', 'n_epochs', 'l2', 'validation_metric', 'validation_freq', 'optimizer_config', 'scheduler_config', 'checkpoint', 'checkpoint_config'])\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=500, out_features=4, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5)\n",
      "  )\n",
      "  (2): Linear(in_features=4, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "dict_keys(['print_every', 'use_cuda', 'data_loader_config', 'n_epochs', 'l2', 'validation_metric', 'validation_freq', 'optimizer_config', 'scheduler_config', 'checkpoint', 'checkpoint_config'])\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=500, out_features=200, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.3)\n",
      "  )\n",
      "  (2): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "dict_keys(['print_every', 'use_cuda', 'data_loader_config', 'n_epochs', 'l2', 'validation_metric', 'validation_freq', 'optimizer_config', 'scheduler_config', 'checkpoint', 'checkpoint_config'])\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=500, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.2)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "dict_keys(['print_every', 'use_cuda', 'data_loader_config', 'n_epochs', 'l2', 'validation_metric', 'validation_freq', 'optimizer_config', 'scheduler_config', 'checkpoint', 'checkpoint_config'])\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=500, out_features=200, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.5)\n",
      "  )\n",
      "  (2): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "dict_keys(['print_every', 'use_cuda', 'data_loader_config', 'n_epochs', 'l2', 'validation_metric', 'validation_freq', 'optimizer_config', 'scheduler_config', 'checkpoint', 'checkpoint_config'])\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=500, out_features=400, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2)\n",
      "  )\n",
      "  (2): Linear(in_features=400, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "dict_keys(['print_every', 'use_cuda', 'data_loader_config', 'n_epochs', 'l2', 'validation_metric', 'validation_freq', 'optimizer_config', 'scheduler_config', 'checkpoint', 'checkpoint_config'])\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=500, out_features=400, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.4)\n",
      "  )\n",
      "  (2): Linear(in_features=400, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "dict_keys(['print_every', 'use_cuda', 'data_loader_config', 'n_epochs', 'l2', 'validation_metric', 'validation_freq', 'optimizer_config', 'scheduler_config', 'checkpoint', 'checkpoint_config'])\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=500, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.4)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "dict_keys(['print_every', 'use_cuda', 'data_loader_config', 'n_epochs', 'l2', 'validation_metric', 'validation_freq', 'optimizer_config', 'scheduler_config', 'checkpoint', 'checkpoint_config'])\n"
     ]
    }
   ],
   "source": [
    "#%%capture\n",
    "seeds = [123, 234, 456, 567, 678]\n",
    "#seeds = [123]\n",
    "runstats_hyperband = []\n",
    "runstats_rs = []\n",
    "for seed in seeds:\n",
    "    runstats_rs.append(run_random_search(seed=seed))\n",
    "    runstats_hyperband.append(run_hyperband(seed=seed))\n",
    "    \n",
    "print(runstats_hyperband)\n",
    "print(runstats_rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Plot random search vs hyperband run stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "print(runstats_hyperband)\n",
    "\n",
    "xs_hyperband = [[x[\"time_elapsed\"] for x in z] for z in runstats_hyperband]\n",
    "ys_hyperband = [[x[\"best_score\"] for x in z] for z in runstats_hyperband]\n",
    "xs_rs = [[x[\"time_elapsed\"] for x in z] for z in runstats_rs]\n",
    "ys_rs = [[x[\"best_score\"] for x in z] for z in runstats_rs]\n",
    "\n",
    "# Extract min and max times for segmented times\n",
    "flat_xs_hyperband = [item for sublist in xs_hyperband for item in sublist]\n",
    "flat_xs_rs = [item for sublist in xs_rs for item in sublist]\n",
    "min_time, max_time = 0, max(flat_xs_hyperband + flat_xs_rs)\n",
    "\n",
    "\n",
    "# Get list of best scores at time\n",
    "def get_best_scores_at_time(all_runstats, target_time):\n",
    "    best_scores = []\n",
    "    for runstats in all_runstats:\n",
    "        best_score = 0        \n",
    "        times = [x[\"time_elapsed\"] for x in runstats]\n",
    "        scores = [x[\"best_score\"] for x in runstats]\n",
    "        for time, score in zip(times, scores):\n",
    "            if time < target_time:\n",
    "                best_score = score\n",
    "        best_scores.append(best_score)\n",
    "    return best_scores\n",
    "        \n",
    "# Extract best scores per segment\n",
    "segments = list(np.arange(0, max_time, 1))\n",
    "hyperband_scores = [get_best_scores_at_time(runstats_hyperband, t) for t in segments]\n",
    "rs_scores = [get_best_scores_at_time(runstats_rs, t) for t in segments]\n",
    "\n",
    "# Extract means and error bars\n",
    "mean_hyperband_scores = [np.mean(x) for x in hyperband_scores]\n",
    "mean_rs_scores = [np.mean(x) for x in rs_scores]\n",
    "#hyperband_stds = [np.std(x) for x in hyperband_scores]\n",
    "#rs_stds = [np.std(x) for x in rs_scores]\n",
    "hyperband_stds = [0 for x in hyperband_scores]\n",
    "rs_stds = [0 for x in rs_scores]\n",
    "\n",
    "#plt.plot(segments, mean_hyperband_scores, label=\"Hyperband\", marker=\"o\")\n",
    "#plt.plot(segments, mean_rs_scores, label=\"Random Search\", marker=\"o\")\n",
    "width = 12\n",
    "height = 12\n",
    "plt.figure(figsize=(width, height))\n",
    "plt.errorbar(segments, mean_hyperband_scores, hyperband_stds, label=\"Hyperband\", marker=\"o\")\n",
    "plt.errorbar(segments, mean_rs_scores, rs_stds, label=\"Random Search\", marker=\"o\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(\"Best Acc Score Achieved vs Time\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Mean Acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Plot random search vs hyperband run stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "print(runstats_hyperband)\n",
    "\n",
    "xs_hyperband = [[x[\"time_elapsed\"] for x in z] for z in runstats_hyperband]\n",
    "ys_hyperband = [[x[\"best_score\"] for x in z] for z in runstats_hyperband]\n",
    "xs_rs = [[x[\"time_elapsed\"] for x in z] for z in runstats_rs]\n",
    "ys_rs = [[x[\"best_score\"] for x in z] for z in runstats_rs]\n",
    "\n",
    "# Extract min and max times for segmented times\n",
    "flat_xs_hyperband = [item for sublist in xs_hyperband for item in sublist]\n",
    "flat_xs_rs = [item for sublist in xs_rs for item in sublist]\n",
    "min_time, max_time = 0, max(flat_xs_hyperband + flat_xs_rs)\n",
    "\n",
    "\n",
    "# Get list of best scores at time\n",
    "def get_best_scores_at_time(all_runstats, target_time):\n",
    "    best_scores = []\n",
    "    for runstats in all_runstats:\n",
    "        best_score = 0        \n",
    "        times = [x[\"time_elapsed\"] for x in runstats]\n",
    "        scores = [x[\"best_score\"] for x in runstats]\n",
    "        for time, score in zip(times, scores):\n",
    "            if time < target_time:\n",
    "                best_score = score\n",
    "        best_scores.append(best_score)\n",
    "    return best_scores\n",
    "        \n",
    "# Extract best scores per segment\n",
    "segments = list(np.arange(0, max_time, 1))\n",
    "hyperband_scores = [get_best_scores_at_time(runstats_hyperband, t) for t in segments]\n",
    "rs_scores = [get_best_scores_at_time(runstats_rs, t) for t in segments]\n",
    "\n",
    "# Extract means and error bars\n",
    "mean_hyperband_scores = [np.mean(x) for x in hyperband_scores]\n",
    "mean_rs_scores = [np.mean(x) for x in rs_scores]\n",
    "hyperband_stds = [[-np.percentile(x, 10)+np.mean(x) for x in hyperband_scores], [np.percentile(x, 90)-np.mean(x) for x in hyperband_scores]]\n",
    "rs_stds = [[-np.percentile(x, 10)+np.mean(x) for x in rs_scores], [np.percentile(x, 90)-np.mean(x) for x in rs_scores]]\n",
    "\n",
    "\n",
    "#plt.plot(segments, mean_hyperband_scores, label=\"Hyperband\", marker=\"o\")\n",
    "#plt.plot(segments, mean_rs_scores, label=\"Random Search\", marker=\"o\")\n",
    "width = 12\n",
    "height = 12\n",
    "plt.figure(figsize=(width, height))\n",
    "plt.errorbar(segments, mean_hyperband_scores, hyperband_stds, label=\"Hyperband\", marker=\"o\")\n",
    "plt.errorbar(segments, mean_rs_scores, rs_stds, label=\"Random Search\", marker=\"o\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(\"Best Acc Score Achieved vs Time\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Mean Acc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
