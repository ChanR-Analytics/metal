{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging the `LabelModel` with deps + higher-order cliques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append(\"../\") # go to parent dir\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import mpmath\n",
    "\n",
    "from synthetic.generate import SingleTaskTreeDepsGenerator\n",
    "from metal.label_model import LabelModel\n",
    "from metal.label_model.utils import (\n",
    "    compute_mu,\n",
    "    compute_covariance,\n",
    "    compute_inv_covariance,\n",
    "    print_matrix,\n",
    "    visualize_matrix\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1)   [0.92256582 0.51148433]\n",
      "(0, 2)   [0.48762871 0.94521501]\n",
      "(1, 1)   [0.80055031 0.74437346]\n",
      "(1, 2)   [0.82248175 0.18352073]\n",
      "(2, 1)   [0.56633729 0.87851823]\n",
      "(2, 2)   [0.84623222 0.84664302]\n",
      "(3, 1)   [0.34574498 0.15331888]\n",
      "(3, 2)   [0.70347524 0.63375897]\n",
      "(4, 1)   [0.70448869 0.47060909]\n",
      "(4, 2)   [0.27779581 0.36066668]\n",
      "(5, 1)   [0.22790812 0.80498303]\n",
      "(5, 2)   [0.47128496 0.13075418]\n",
      "(6, 1)   [0.66162699 0.69457216]\n",
      "(6, 2)   [0.36864577 0.50152106]\n",
      "(7, 1)   [0.29991209 0.16602775]\n",
      "(7, 2)   [0.52231467 0.18655503]\n",
      "(8, 1)   [0.91303315 0.20754142]\n",
      "(8, 2)   [0.57231944 0.1752607 ]\n",
      "(9, 1)   [0.9251752  0.91940354]\n",
      "(9, 2)   [0.3690371  0.62595021]\n",
      "((0, 1), 1, 1)   [0.60932082 0.65254449]\n",
      "((0, 1), 1, 2)   [0.96088209 0.33488108]\n",
      "((0, 1), 2, 1)   [0.30791388 0.58010364]\n",
      "((0, 1), 2, 2)   [0.95494432 0.54375363]\n",
      "((1, 2), 1, 1)   [0.58654046 0.78893659]\n",
      "((1, 2), 1, 2)   [0.14081116 0.22596951]\n",
      "((1, 2), 2, 1)   [0.81316323 0.12682122]\n",
      "((1, 2), 2, 2)   [0.89481293 0.58670937]\n",
      "((0, 3), 1, 1)   [0.50318216 0.90292228]\n",
      "((0, 3), 1, 2)   [0.43982591 0.58458222]\n",
      "((0, 3), 2, 1)   [0.68706899 0.42513492]\n",
      "((0, 3), 2, 2)   [0.61390771 0.67405284]\n",
      "((0, 4), 1, 1)   [0.2136834  0.72118413]\n",
      "((0, 4), 1, 2)   [0.68297446 0.41854518]\n",
      "((0, 4), 2, 1)   [0.78690975 0.42087855]\n",
      "((0, 4), 2, 2)   [0.77750952 0.89320765]\n",
      "((4, 5), 1, 1)   [0.11050227 0.54829816]\n",
      "((4, 5), 1, 2)   [0.16641281 0.80825633]\n",
      "((4, 5), 2, 1)   [0.1576606  0.41977933]\n",
      "((4, 5), 2, 2)   [0.94765325 0.44182296]\n",
      "((2, 6), 1, 1)   [0.78662807 0.7944355 ]\n",
      "((2, 6), 1, 2)   [0.37122445 0.79546523]\n",
      "((2, 6), 2, 1)   [0.23763684 0.62077054]\n",
      "((2, 6), 2, 2)   [0.1081072  0.73813827]\n",
      "((5, 7), 1, 1)   [0.52357673 0.78813331]\n",
      "((5, 7), 1, 2)   [0.52065341 0.34210095]\n",
      "((5, 7), 2, 1)   [0.84852333 0.59619245]\n",
      "((5, 7), 2, 2)   [0.16307335 0.52522753]\n",
      "((3, 8), 1, 1)   [0.76848835 0.27276047]\n",
      "((3, 8), 1, 2)   [0.51788035 0.30732653]\n",
      "((3, 8), 2, 1)   [0.55742278 0.28771148]\n",
      "((3, 8), 2, 2)   [0.14437382 0.56697569]\n",
      "((2, 9), 1, 1)   [0.25505052 0.45668196]\n",
      "((2, 9), 1, 2)   [0.19662877 0.55882925]\n",
      "((2, 9), 2, 1)   [0.19192171 0.35984605]\n",
      "((2, 9), 2, 2)   [0.30858262 0.97090114]\n",
      "Labeler =  0\n",
      "P(L= 0 , Y= 1 ) =  0.04047851671854997\n",
      "P(L= 1 , Y= 1 ) =  0.5004241979692685\n",
      "P(L= 2 , Y= 1 ) =  0.45909728531218147\n",
      "Labeler =  1\n",
      "P(L= 0 , Y= 1 ) =  0.054972922407379936\n",
      "P(L= 1 , Y= 1 ) =  0.2710054320807368\n",
      "P(L= 2 , Y= 1 ) =  0.674021645511883\n",
      "Labeler =  2\n",
      "P(L= 0 , Y= 1 ) =  0.07072115597568643\n",
      "P(L= 1 , Y= 1 ) =  0.49940802970620424\n",
      "P(L= 2 , Y= 1 ) =  0.4298708143181091\n",
      "Labeler =  3\n",
      "P(L= 0 , Y= 1 ) =  0.09958232192021327\n",
      "P(L= 1 , Y= 1 ) =  0.43708518030482224\n",
      "P(L= 2 , Y= 1 ) =  0.4633324977749643\n",
      "Labeler =  4\n",
      "P(L= 0 , Y= 1 ) =  0.1075667575860416\n",
      "P(L= 1 , Y= 1 ) =  0.3890364818324785\n",
      "P(L= 2 , Y= 1 ) =  0.5033967605814799\n",
      "Labeler =  5\n",
      "P(L= 0 , Y= 1 ) =  0.13785683117342726\n",
      "P(L= 1 , Y= 1 ) =  0.29401041809295425\n",
      "P(L= 2 , Y= 1 ) =  0.5681327507336182\n",
      "Labeler =  6\n",
      "P(L= 0 , Y= 1 ) =  0.16887700571159062\n",
      "P(L= 1 , Y= 1 ) =  0.528816366599669\n",
      "P(L= 2 , Y= 1 ) =  0.30230662768874017\n",
      "Labeler =  7\n",
      "P(L= 0 , Y= 1 ) =  0.1747944488539912\n",
      "P(L= 1 , Y= 1 ) =  0.4475099107315628\n",
      "P(L= 2 , Y= 1 ) =  0.3776956404144459\n",
      "Labeler =  8\n",
      "P(L= 0 , Y= 1 ) =  0.1282929169056262\n",
      "P(L= 1 , Y= 1 ) =  0.5708641052357463\n",
      "P(L= 2 , Y= 1 ) =  0.30084297785862735\n",
      "Labeler =  9\n",
      "P(L= 0 , Y= 1 ) =  0.1685965425639786\n",
      "P(L= 1 , Y= 1 ) =  0.524162032503679\n",
      "P(L= 2 , Y= 1 ) =  0.3072414249323423\n",
      "Labeler =  0\n",
      "P(L= 0 , Y= 2 ) =  0.04619718615143314\n",
      "P(L= 1 , Y= 2 ) =  0.3875630033513791\n",
      "P(L= 2 , Y= 2 ) =  0.5662398104971877\n",
      "Labeler =  1\n",
      "P(L= 0 , Y= 2 ) =  0.1004293579541635\n",
      "P(L= 1 , Y= 2 ) =  0.6312496480416631\n",
      "P(L= 2 , Y= 2 ) =  0.26832099400417325\n",
      "Labeler =  2\n",
      "P(L= 0 , Y= 2 ) =  0.042897632854839274\n",
      "P(L= 1 , Y= 2 ) =  0.5306996873390036\n",
      "P(L= 2 , Y= 2 ) =  0.4264026798061569\n",
      "Labeler =  3\n",
      "P(L= 0 , Y= 2 ) =  0.1190234997557316\n",
      "P(L= 1 , Y= 2 ) =  0.31247510515335425\n",
      "P(L= 2 , Y= 2 ) =  0.5685013950909141\n",
      "Labeler =  4\n",
      "P(L= 0 , Y= 2 ) =  0.10150876056234127\n",
      "P(L= 1 , Y= 2 ) =  0.4818760258678046\n",
      "P(L= 2 , Y= 2 ) =  0.416615213569854\n",
      "Labeler =  5\n",
      "P(L= 0 , Y= 2 ) =  0.1063365657154413\n",
      "P(L= 1 , Y= 2 ) =  0.5681935540579359\n",
      "P(L= 2 , Y= 2 ) =  0.3254698802266227\n",
      "Labeler =  6\n",
      "P(L= 0 , Y= 2 ) =  0.11971841885445308\n",
      "P(L= 1 , Y= 2 ) =  0.4714441639097386\n",
      "P(L= 2 , Y= 2 ) =  0.4088374172358082\n",
      "Labeler =  7\n",
      "P(L= 0 , Y= 2 ) =  0.20157697214889508\n",
      "P(L= 1 , Y= 2 ) =  0.4504349295456766\n",
      "P(L= 2 , Y= 2 ) =  0.3479880983054284\n",
      "Labeler =  8\n",
      "P(L= 0 , Y= 2 ) =  0.22842999577645826\n",
      "P(L= 1 , Y= 2 ) =  0.35876896097418376\n",
      "P(L= 2 , Y= 2 ) =  0.4128010432493579\n",
      "Labeler =  9\n",
      "P(L= 0 , Y= 2 ) =  0.11720213300958968\n",
      "P(L= 1 , Y= 2 ) =  0.4361198435413552\n",
      "P(L= 2 , Y= 2 ) =  0.44667802344905494\n",
      "Labelers =  (0, 1)\n",
      "P(L_ 0 = 0 , L_ 1 = 0  | Y =  1 ) =  0.00443476016844756\n",
      "P(L_ 0 = 0 , L_ 1 = 1  | Y =  1 ) =  0.014089265143218519\n",
      "P(L_ 0 = 0 , L_ 1 = 2  | Y =  1 ) =  0.021954491406883887\n",
      "P(L_ 0 = 1 , L_ 1 = 0  | Y =  1 ) =  0.025294604507622036\n",
      "P(L_ 0 = 1 , L_ 1 = 1  | Y =  1 ) =  0.14779875277995552\n",
      "P(L_ 0 = 1 , L_ 1 = 2  | Y =  1 ) =  0.3273308406816909\n",
      "P(L_ 0 = 2 , L_ 1 = 0  | Y =  1 ) =  0.02524355773131033\n",
      "P(L_ 0 = 2 , L_ 1 = 1  | Y =  1 ) =  0.10911741415756274\n",
      "P(L_ 0 = 2 , L_ 1 = 2  | Y =  1 ) =  0.32473631342330833\n",
      "Labelers =  (0, 2)\n",
      "P(L_ 0 = 0 , L_ 2 = 0  | Y =  1 ) =  0.003110713023071187\n",
      "P(L_ 0 = 0 , L_ 2 = 1  | Y =  1 ) =  0.020495732974109754\n",
      "P(L_ 0 = 0 , L_ 2 = 2  | Y =  1 ) =  0.016872070721369023\n",
      "P(L_ 0 = 1 , L_ 2 = 0  | Y =  1 ) =  0.035612429851754855\n",
      "P(L_ 0 = 1 , L_ 2 = 1  | Y =  1 ) =  0.25119294846612034\n",
      "P(L_ 0 = 1 , L_ 2 = 2  | Y =  1 ) =  0.2136188196513932\n",
      "P(L_ 0 = 2 , L_ 2 = 0  | Y =  1 ) =  0.03199801310086039\n",
      "P(L_ 0 = 2 , L_ 2 = 1  | Y =  1 ) =  0.22771934826597412\n",
      "P(L_ 0 = 2 , L_ 2 = 2  | Y =  1 ) =  0.19937992394534693\n",
      "Labelers =  (0, 3)\n",
      "P(L_ 0 = 0 , L_ 3 = 0  | Y =  1 ) =  0.006375022734045105\n",
      "P(L_ 0 = 0 , L_ 3 = 1  | Y =  1 ) =  0.015997322374831688\n",
      "P(L_ 0 = 0 , L_ 3 = 2  | Y =  1 ) =  0.018106171609673174\n",
      "P(L_ 0 = 1 , L_ 3 = 0  | Y =  1 ) =  0.05234761658379594\n",
      "P(L_ 0 = 1 , L_ 3 = 1  | Y =  1 ) =  0.2172659698581512\n",
      "P(L_ 0 = 1 , L_ 3 = 2  | Y =  1 ) =  0.23081061152732132\n",
      "P(L_ 0 = 2 , L_ 3 = 0  | Y =  1 ) =  0.04085968260237223\n",
      "P(L_ 0 = 2 , L_ 3 = 1  | Y =  1 ) =  0.20382188807183937\n",
      "P(L_ 0 = 2 , L_ 3 = 2  | Y =  1 ) =  0.21441571463796985\n",
      "Labelers =  (0, 4)\n",
      "P(L_ 0 = 0 , L_ 4 = 0  | Y =  1 ) =  0.007194492243447212\n",
      "P(L_ 0 = 0 , L_ 4 = 1  | Y =  1 ) =  0.016361506173999483\n",
      "P(L_ 0 = 0 , L_ 4 = 2  | Y =  1 ) =  0.01692251830110327\n",
      "P(L_ 0 = 1 , L_ 4 = 0  | Y =  1 ) =  0.05906359642230384\n",
      "P(L_ 0 = 1 , L_ 4 = 1  | Y =  1 ) =  0.16632002429940565\n",
      "P(L_ 0 = 1 , L_ 4 = 2  | Y =  1 ) =  0.2750405772475589\n",
      "P(L_ 0 = 2 , L_ 4 = 0  | Y =  1 ) =  0.041308668920290545\n",
      "P(L_ 0 = 2 , L_ 4 = 1  | Y =  1 ) =  0.2063549513590734\n",
      "P(L_ 0 = 2 , L_ 4 = 2  | Y =  1 ) =  0.21143366503281757\n",
      "Labelers =  (0, 5)\n",
      "P(L_ 0 = 0 , L_ 5 = 0  | Y =  1 ) =  0.00585132549839498\n",
      "P(L_ 0 = 0 , L_ 5 = 1  | Y =  1 ) =  0.012321822174600764\n",
      "P(L_ 0 = 0 , L_ 5 = 2  | Y =  1 ) =  0.022305369045554215\n",
      "P(L_ 0 = 1 , L_ 5 = 0  | Y =  1 ) =  0.06767376693857013\n",
      "P(L_ 0 = 1 , L_ 5 = 1  | Y =  1 ) =  0.14437000026865252\n",
      "P(L_ 0 = 1 , L_ 5 = 2  | Y =  1 ) =  0.28838043076204584\n",
      "P(L_ 0 = 2 , L_ 5 = 0  | Y =  1 ) =  0.06433173873646218\n",
      "P(L_ 0 = 2 , L_ 5 = 1  | Y =  1 ) =  0.13731859564970098\n",
      "P(L_ 0 = 2 , L_ 5 = 2  | Y =  1 ) =  0.25744695092601827\n",
      "Labelers =  (0, 6)\n",
      "P(L_ 0 = 0 , L_ 6 = 0  | Y =  1 ) =  0.006826355788001187\n",
      "P(L_ 0 = 0 , L_ 6 = 1  | Y =  1 ) =  0.021421440063256914\n",
      "P(L_ 0 = 0 , L_ 6 = 2  | Y =  1 ) =  0.012230720867291862\n",
      "P(L_ 0 = 1 , L_ 6 = 0  | Y =  1 ) =  0.0844387412148925\n",
      "P(L_ 0 = 1 , L_ 6 = 1  | Y =  1 ) =  0.2647430453784932\n",
      "P(L_ 0 = 1 , L_ 6 = 2  | Y =  1 ) =  0.15124241137588273\n",
      "P(L_ 0 = 2 , L_ 6 = 0  | Y =  1 ) =  0.07761190870869694\n",
      "P(L_ 0 = 2 , L_ 6 = 1  | Y =  1 ) =  0.24265188115791894\n",
      "P(L_ 0 = 2 , L_ 6 = 2  | Y =  1 ) =  0.13883349544556553\n",
      "Labelers =  (0, 7)\n",
      "P(L_ 0 = 0 , L_ 7 = 0  | Y =  1 ) =  0.0070986694734814365\n",
      "P(L_ 0 = 0 , L_ 7 = 1  | Y =  1 ) =  0.018006524515068845\n",
      "P(L_ 0 = 0 , L_ 7 = 2  | Y =  1 ) =  0.01537332272999968\n",
      "P(L_ 0 = 1 , L_ 7 = 0  | Y =  1 ) =  0.08735833440534942\n",
      "P(L_ 0 = 1 , L_ 7 = 1  | Y =  1 ) =  0.22456995155379214\n",
      "P(L_ 0 = 1 , L_ 7 = 2  | Y =  1 ) =  0.18849591201012697\n",
      "P(L_ 0 = 2 , L_ 7 = 0  | Y =  1 ) =  0.08033744497516035\n",
      "P(L_ 0 = 2 , L_ 7 = 1  | Y =  1 ) =  0.20493343466270197\n",
      "P(L_ 0 = 2 , L_ 7 = 2  | Y =  1 ) =  0.17382640567431923\n",
      "Labelers =  (0, 8)\n",
      "P(L_ 0 = 0 , L_ 8 = 0  | Y =  1 ) =  0.005369359407646461\n",
      "P(L_ 0 = 0 , L_ 8 = 1  | Y =  1 ) =  0.022861290845813863\n",
      "P(L_ 0 = 0 , L_ 8 = 2  | Y =  1 ) =  0.01224786646508964\n",
      "P(L_ 0 = 1 , L_ 8 = 0  | Y =  1 ) =  0.06437988314790367\n",
      "P(L_ 0 = 1 , L_ 8 = 1  | Y =  1 ) =  0.28540515421917645\n",
      "P(L_ 0 = 1 , L_ 8 = 2  | Y =  1 ) =  0.1506391606021884\n",
      "P(L_ 0 = 2 , L_ 8 = 0  | Y =  1 ) =  0.058543674350076055\n",
      "P(L_ 0 = 2 , L_ 8 = 1  | Y =  1 ) =  0.2625976601707561\n",
      "P(L_ 0 = 2 , L_ 8 = 2  | Y =  1 ) =  0.1379559507913493\n",
      "Labelers =  (0, 9)\n",
      "P(L_ 0 = 0 , L_ 9 = 0  | Y =  1 ) =  0.006833363966856995\n",
      "P(L_ 0 = 0 , L_ 9 = 1  | Y =  1 ) =  0.021226917655723827\n",
      "P(L_ 0 = 0 , L_ 9 = 2  | Y =  1 ) =  0.01241823509596914\n",
      "P(L_ 0 = 1 , L_ 9 = 0  | Y =  1 ) =  0.0843779510902171\n",
      "P(L_ 0 = 1 , L_ 9 = 1  | Y =  1 ) =  0.26234675342491265\n",
      "P(L_ 0 = 1 , L_ 9 = 2  | Y =  1 ) =  0.15369949345413864\n",
      "P(L_ 0 = 2 , L_ 9 = 0  | Y =  1 ) =  0.07738522750690448\n",
      "P(L_ 0 = 2 , L_ 9 = 1  | Y =  1 ) =  0.24058836142304235\n",
      "P(L_ 0 = 2 , L_ 9 = 2  | Y =  1 ) =  0.14112369638223451\n",
      "Labelers =  (1, 2)\n",
      "P(L_ 1 = 0 , L_ 2 = 0  | Y =  1 ) =  0.007007230577925494\n",
      "P(L_ 1 = 0 , L_ 2 = 1  | Y =  1 ) =  0.02506556475825018\n",
      "P(L_ 1 = 0 , L_ 2 = 2  | Y =  1 ) =  0.022900127071204264\n",
      "P(L_ 1 = 1 , L_ 2 = 0  | Y =  1 ) =  0.024212072119523052\n",
      "P(L_ 1 = 1 , L_ 2 = 1  | Y =  1 ) =  0.15570204939296367\n",
      "P(L_ 1 = 1 , L_ 2 = 2  | Y =  1 ) =  0.09109131056825005\n",
      "P(L_ 1 = 2 , L_ 2 = 0  | Y =  1 ) =  0.03950185327823789\n",
      "P(L_ 1 = 2 , L_ 2 = 1  | Y =  1 ) =  0.31864041555499034\n",
      "P(L_ 1 = 2 , L_ 2 = 2  | Y =  1 ) =  0.31587937667865484\n",
      "Labelers =  (1, 3)\n",
      "P(L_ 1 = 0 , L_ 3 = 0  | Y =  1 ) =  0.005591094724544213\n",
      "P(L_ 1 = 0 , L_ 3 = 1  | Y =  1 ) =  0.023941825012383323\n",
      "P(L_ 1 = 0 , L_ 3 = 2  | Y =  1 ) =  0.025440002670452395\n",
      "P(L_ 1 = 1 , L_ 3 = 0  | Y =  1 ) =  0.02739110334323508\n",
      "P(L_ 1 = 1 , L_ 3 = 1  | Y =  1 ) =  0.11818100820689492\n",
      "P(L_ 1 = 1 , L_ 3 = 2  | Y =  1 ) =  0.12543332053060682\n",
      "P(L_ 1 = 2 , L_ 3 = 0  | Y =  1 ) =  0.06660012385243398\n",
      "P(L_ 1 = 2 , L_ 3 = 1  | Y =  1 ) =  0.294962347085544\n",
      "P(L_ 1 = 2 , L_ 3 = 2  | Y =  1 ) =  0.31245917457390515\n",
      "Labelers =  (1, 4)\n",
      "P(L_ 1 = 0 , L_ 4 = 0  | Y =  1 ) =  0.0060450301739202504\n",
      "P(L_ 1 = 0 , L_ 4 = 1  | Y =  1 ) =  0.02154587503702306\n",
      "P(L_ 1 = 0 , L_ 4 = 2  | Y =  1 ) =  0.027382017196436622\n",
      "P(L_ 1 = 1 , L_ 4 = 0  | Y =  1 ) =  0.029766592544020008\n",
      "P(L_ 1 = 1 , L_ 4 = 1  | Y =  1 ) =  0.10386309390092835\n",
      "P(L_ 1 = 1 , L_ 4 = 2  | Y =  1 ) =  0.13737574563578847\n",
      "P(L_ 1 = 2 , L_ 4 = 0  | Y =  1 ) =  0.07175513486810133\n",
      "P(L_ 1 = 2 , L_ 4 = 1  | Y =  1 ) =  0.26362751289452707\n",
      "P(L_ 1 = 2 , L_ 4 = 2  | Y =  1 ) =  0.33863899774925477\n",
      "Labelers =  (1, 5)\n",
      "P(L_ 1 = 0 , L_ 5 = 0  | Y =  1 ) =  0.007599015685502336\n",
      "P(L_ 1 = 0 , L_ 5 = 1  | Y =  1 ) =  0.016197822714434894\n",
      "P(L_ 1 = 0 , L_ 5 = 2  | Y =  1 ) =  0.031176084007442692\n",
      "P(L_ 1 = 1 , L_ 5 = 0  | Y =  1 ) =  0.03731414870035586\n",
      "P(L_ 1 = 1 , L_ 5 = 1  | Y =  1 ) =  0.07956570155914894\n",
      "P(L_ 1 = 1 , L_ 5 = 2  | Y =  1 ) =  0.154125581821232\n",
      "P(L_ 1 = 2 , L_ 5 = 0  | Y =  1 ) =  0.0929436667875691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(L_ 1 = 2 , L_ 5 = 1  | Y =  1 ) =  0.19824689381937038\n",
      "P(L_ 1 = 2 , L_ 5 = 2  | Y =  1 ) =  0.38283108490494355\n",
      "Labelers =  (1, 6)\n",
      "P(L_ 1 = 0 , L_ 6 = 0  | Y =  1 ) =  0.009526136592582881\n",
      "P(L_ 1 = 0 , L_ 6 = 1  | Y =  1 ) =  0.028712493193954768\n",
      "P(L_ 1 = 0 , L_ 6 = 2  | Y =  1 ) =  0.016734292620842285\n",
      "P(L_ 1 = 1 , L_ 6 = 0  | Y =  1 ) =  0.04467484582787258\n",
      "P(L_ 1 = 1 , L_ 6 = 1  | Y =  1 ) =  0.14500972314039762\n",
      "P(L_ 1 = 1 , L_ 6 = 2  | Y =  1 ) =  0.08132086311246653\n",
      "P(L_ 1 = 2 , L_ 6 = 0  | Y =  1 ) =  0.11467602329113516\n",
      "P(L_ 1 = 2 , L_ 6 = 1  | Y =  1 ) =  0.35509415026531654\n",
      "P(L_ 1 = 2 , L_ 6 = 2  | Y =  1 ) =  0.20425147195543134\n",
      "Labelers =  (1, 7)\n",
      "P(L_ 1 = 0 , L_ 7 = 0  | Y =  1 ) =  0.009610732229828\n",
      "P(L_ 1 = 0 , L_ 7 = 1  | Y =  1 ) =  0.024592257970255226\n",
      "P(L_ 1 = 0 , L_ 7 = 2  | Y =  1 ) =  0.020769932207296712\n",
      "P(L_ 1 = 1 , L_ 7 = 0  | Y =  1 ) =  0.0473662929046579\n",
      "P(L_ 1 = 1 , L_ 7 = 1  | Y =  1 ) =  0.12130174561120088\n",
      "P(L_ 1 = 1 , L_ 7 = 2  | Y =  1 ) =  0.10233739356487802\n",
      "P(L_ 1 = 2 , L_ 7 = 0  | Y =  1 ) =  0.11781742371950527\n",
      "P(L_ 1 = 2 , L_ 7 = 1  | Y =  1 ) =  0.3016159071501067\n",
      "P(L_ 1 = 2 , L_ 7 = 2  | Y =  1 ) =  0.2545883146422711\n",
      "Labelers =  (1, 8)\n",
      "P(L_ 1 = 0 , L_ 8 = 0  | Y =  1 ) =  0.007061460645884922\n",
      "P(L_ 1 = 0 , L_ 8 = 1  | Y =  1 ) =  0.031369813391323186\n",
      "P(L_ 1 = 0 , L_ 8 = 2  | Y =  1 ) =  0.016541648370171826\n",
      "P(L_ 1 = 1 , L_ 8 = 0  | Y =  1 ) =  0.03479785668409725\n",
      "P(L_ 1 = 1 , L_ 8 = 1  | Y =  1 ) =  0.15466455272728383\n",
      "P(L_ 1 = 1 , L_ 8 = 2  | Y =  1 ) =  0.08154302266935576\n",
      "P(L_ 1 = 2 , L_ 8 = 0  | Y =  1 ) =  0.08643359957564402\n",
      "P(L_ 1 = 2 , L_ 8 = 1  | Y =  1 ) =  0.38482973911713936\n",
      "P(L_ 1 = 2 , L_ 8 = 2  | Y =  1 ) =  0.20275830681909968\n",
      "Labelers =  (1, 9)\n",
      "P(L_ 1 = 0 , L_ 9 = 0  | Y =  1 ) =  0.009377713209707062\n",
      "P(L_ 1 = 0 , L_ 9 = 1  | Y =  1 ) =  0.028735140529409755\n",
      "P(L_ 1 = 0 , L_ 9 = 2  | Y =  1 ) =  0.01686006866826312\n",
      "P(L_ 1 = 1 , L_ 9 = 0  | Y =  1 ) =  0.045873960948062606\n",
      "P(L_ 1 = 1 , L_ 9 = 1  | Y =  1 ) =  0.14274314502957478\n",
      "P(L_ 1 = 1 , L_ 9 = 2  | Y =  1 ) =  0.08238832610309937\n",
      "P(L_ 1 = 2 , L_ 9 = 0  | Y =  1 ) =  0.1133448684062089\n",
      "P(L_ 1 = 2 , L_ 9 = 1  | Y =  1 ) =  0.35268374694469434\n",
      "P(L_ 1 = 2 , L_ 9 = 2  | Y =  1 ) =  0.2079930301609798\n",
      "Labelers =  (2, 3)\n",
      "P(L_ 2 = 0 , L_ 3 = 0  | Y =  1 ) =  0.007063026870678213\n",
      "P(L_ 2 = 0 , L_ 3 = 1  | Y =  1 ) =  0.030896902354096062\n",
      "P(L_ 2 = 0 , L_ 3 = 2  | Y =  1 ) =  0.03276122675091217\n",
      "P(L_ 2 = 1 , L_ 3 = 0  | Y =  1 ) =  0.04977134945438835\n",
      "P(L_ 2 = 1 , L_ 3 = 1  | Y =  1 ) =  0.21825766165588092\n",
      "P(L_ 2 = 1 , L_ 3 = 2  | Y =  1 ) =  0.2313790185959349\n",
      "P(L_ 2 = 2 , L_ 3 = 0  | Y =  1 ) =  0.04274794559514671\n",
      "P(L_ 2 = 2 , L_ 3 = 1  | Y =  1 ) =  0.18793061629484523\n",
      "P(L_ 2 = 2 , L_ 3 = 2  | Y =  1 ) =  0.19919225242811725\n",
      "Labelers =  (2, 4)\n",
      "P(L_ 2 = 0 , L_ 4 = 0  | Y =  1 ) =  0.007635234410073192\n",
      "P(L_ 2 = 0 , L_ 4 = 1  | Y =  1 ) =  0.027475896020710364\n",
      "P(L_ 2 = 0 , L_ 4 = 2  | Y =  1 ) =  0.03561002554490288\n",
      "P(L_ 2 = 1 , L_ 4 = 0  | Y =  1 ) =  0.05378013405743952\n",
      "P(L_ 2 = 1 , L_ 4 = 1  | Y =  1 ) =  0.19412567091365873\n",
      "P(L_ 2 = 1 , L_ 4 = 2  | Y =  1 ) =  0.2515022247351059\n",
      "P(L_ 2 = 2 , L_ 4 = 0  | Y =  1 ) =  0.046151389118528875\n",
      "P(L_ 2 = 2 , L_ 4 = 1  | Y =  1 ) =  0.16743491489810935\n",
      "P(L_ 2 = 2 , L_ 4 = 2  | Y =  1 ) =  0.21628451030147097\n",
      "Labelers =  (2, 5)\n",
      "P(L_ 2 = 0 , L_ 5 = 0  | Y =  1 ) =  0.009749406835011661\n",
      "P(L_ 2 = 0 , L_ 5 = 1  | Y =  1 ) =  0.020791716816139314\n",
      "P(L_ 2 = 0 , L_ 5 = 2  | Y =  1 ) =  0.04018003232453546\n",
      "P(L_ 2 = 1 , L_ 5 = 0  | Y =  1 ) =  0.06884180021310699\n",
      "P(L_ 2 = 1 , L_ 5 = 1  | Y =  1 ) =  0.14681909905015614\n",
      "P(L_ 2 = 1 , L_ 5 = 2  | Y =  1 ) =  0.283747130442941\n",
      "P(L_ 2 = 2 , L_ 5 = 0  | Y =  1 ) =  0.05926562412530864\n",
      "P(L_ 2 = 2 , L_ 5 = 1  | Y =  1 ) =  0.12639960222665875\n",
      "P(L_ 2 = 2 , L_ 5 = 2  | Y =  1 ) =  0.2442055879661417\n",
      "Labelers =  (2, 6)\n",
      "P(L_ 2 = 0 , L_ 6 = 0  | Y =  1 ) =  0.016132687724777568\n",
      "P(L_ 2 = 0 , L_ 6 = 1  | Y =  1 ) =  0.03126422570075099\n",
      "P(L_ 2 = 0 , L_ 6 = 2  | Y =  1 ) =  0.023324242550157873\n",
      "P(L_ 2 = 1 , L_ 6 = 0  | Y =  1 ) =  0.06793423366189898\n",
      "P(L_ 2 = 1 , L_ 6 = 1  | Y =  1 ) =  0.28910650194937937\n",
      "P(L_ 2 = 1 , L_ 6 = 2  | Y =  1 ) =  0.1423672940949259\n",
      "P(L_ 2 = 2 , L_ 6 = 0  | Y =  1 ) =  0.08481008432491408\n",
      "P(L_ 2 = 2 , L_ 6 = 1  | Y =  1 ) =  0.2084456389495386\n",
      "P(L_ 2 = 2 , L_ 6 = 2  | Y =  1 ) =  0.13661509104365643\n",
      "Labelers =  (2, 7)\n",
      "P(L_ 2 = 0 , L_ 7 = 0  | Y =  1 ) =  0.012361665929262505\n",
      "P(L_ 2 = 0 , L_ 7 = 1  | Y =  1 ) =  0.031648562812607514\n",
      "P(L_ 2 = 0 , L_ 7 = 2  | Y =  1 ) =  0.026710927233816413\n",
      "P(L_ 2 = 1 , L_ 7 = 0  | Y =  1 ) =  0.0872933192938185\n",
      "P(L_ 2 = 1 , L_ 7 = 1  | Y =  1 ) =  0.22349264436843003\n",
      "P(L_ 2 = 1 , L_ 7 = 2  | Y =  1 ) =  0.18862206604395568\n",
      "P(L_ 2 = 2 , L_ 7 = 0  | Y =  1 ) =  0.07513946363091016\n",
      "P(L_ 2 = 2 , L_ 7 = 1  | Y =  1 ) =  0.1923687035505253\n",
      "P(L_ 2 = 2 , L_ 7 = 2  | Y =  1 ) =  0.16236264713667367\n",
      "Labelers =  (2, 8)\n",
      "P(L_ 2 = 0 , L_ 8 = 0  | Y =  1 ) =  0.009074546299726545\n",
      "P(L_ 2 = 0 , L_ 8 = 1  | Y =  1 ) =  0.04037001251301695\n",
      "P(L_ 2 = 0 , L_ 8 = 2  | Y =  1 ) =  0.021276597162942938\n",
      "P(L_ 2 = 1 , L_ 8 = 0  | Y =  1 ) =  0.06407339598899692\n",
      "P(L_ 2 = 1 , L_ 8 = 1  | Y =  1 ) =  0.2850899751632335\n",
      "P(L_ 2 = 1 , L_ 8 = 2  | Y =  1 ) =  0.1502446585539738\n",
      "P(L_ 2 = 2 , L_ 8 = 0  | Y =  1 ) =  0.05514497461690272\n",
      "P(L_ 2 = 2 , L_ 8 = 1  | Y =  1 ) =  0.24540411755949598\n",
      "P(L_ 2 = 2 , L_ 8 = 2  | Y =  1 ) =  0.12932172214171048\n",
      "Labelers =  (2, 9)\n",
      "P(L_ 2 = 0 , L_ 9 = 0  | Y =  1 ) =  0.014233471083507202\n",
      "P(L_ 2 = 0 , L_ 9 = 1  | Y =  1 ) =  0.03590122834311547\n",
      "P(L_ 2 = 0 , L_ 9 = 2  | Y =  1 ) =  0.020586456549063766\n",
      "P(L_ 2 = 1 , L_ 9 = 0  | Y =  1 ) =  0.083017047965294\n",
      "P(L_ 2 = 1 , L_ 9 = 1  | Y =  1 ) =  0.2702295281061424\n",
      "P(L_ 2 = 1 , L_ 9 = 2  | Y =  1 ) =  0.1461614536347678\n",
      "P(L_ 2 = 2 , L_ 9 = 0  | Y =  1 ) =  0.07134602351517741\n",
      "P(L_ 2 = 2 , L_ 9 = 1  | Y =  1 ) =  0.21803127605442102\n",
      "P(L_ 2 = 2 , L_ 9 = 2  | Y =  1 ) =  0.14049351474851074\n",
      "Labelers =  (3, 4)\n",
      "P(L_ 3 = 0 , L_ 4 = 0  | Y =  1 ) =  0.010987980401522327\n",
      "P(L_ 3 = 0 , L_ 4 = 1  | Y =  1 ) =  0.03834055307329566\n",
      "P(L_ 3 = 0 , L_ 4 = 2  | Y =  1 ) =  0.0502537884453953\n",
      "P(L_ 3 = 1 , L_ 4 = 0  | Y =  1 ) =  0.046826056381208146\n",
      "P(L_ 3 = 1 , L_ 4 = 1  | Y =  1 ) =  0.17029007261064535\n",
      "P(L_ 3 = 1 , L_ 4 = 2  | Y =  1 ) =  0.2199690513129687\n",
      "P(L_ 3 = 2 , L_ 4 = 0  | Y =  1 ) =  0.04975272080331113\n",
      "P(L_ 3 = 2 , L_ 4 = 1  | Y =  1 ) =  0.1804058561485375\n",
      "P(L_ 3 = 2 , L_ 4 = 2  | Y =  1 ) =  0.23317392082311578\n",
      "Labelers =  (3, 5)\n",
      "P(L_ 3 = 0 , L_ 5 = 0  | Y =  1 ) =  0.013726177146763798\n",
      "P(L_ 3 = 0 , L_ 5 = 1  | Y =  1 ) =  0.029263982970927933\n",
      "P(L_ 3 = 0 , L_ 5 = 2  | Y =  1 ) =  0.05659216180252155\n",
      "P(L_ 3 = 1 , L_ 5 = 0  | Y =  1 ) =  0.06025482752984056\n",
      "P(L_ 3 = 1 , L_ 5 = 1  | Y =  1 ) =  0.12851412742194576\n",
      "P(L_ 3 = 1 , L_ 5 = 2  | Y =  1 ) =  0.24831622535303588\n",
      "P(L_ 3 = 2 , L_ 5 = 0  | Y =  1 ) =  0.06387582649682291\n",
      "P(L_ 3 = 2 , L_ 5 = 1  | Y =  1 ) =  0.13623230770008052\n",
      "P(L_ 3 = 2 , L_ 5 = 2  | Y =  1 ) =  0.26322436357806095\n",
      "Labelers =  (3, 6)\n",
      "P(L_ 3 = 0 , L_ 6 = 0  | Y =  1 ) =  0.016815397005235686\n",
      "P(L_ 3 = 0 , L_ 6 = 1  | Y =  1 ) =  0.05266356469231764\n",
      "P(L_ 3 = 0 , L_ 6 = 2  | Y =  1 ) =  0.03010336022265995\n",
      "P(L_ 3 = 1 , L_ 6 = 0  | Y =  1 ) =  0.07381480100199458\n",
      "P(L_ 3 = 1 , L_ 6 = 1  | Y =  1 ) =  0.23113594646685054\n",
      "P(L_ 3 = 1 , L_ 6 = 2  | Y =  1 ) =  0.132134432835977\n",
      "P(L_ 3 = 2 , L_ 6 = 0  | Y =  1 ) =  0.07824680770436035\n",
      "P(L_ 3 = 2 , L_ 6 = 1  | Y =  1 ) =  0.24501685544050078\n",
      "P(L_ 3 = 2 , L_ 6 = 2  | Y =  1 ) =  0.14006883463010317\n",
      "Labelers =  (3, 7)\n",
      "P(L_ 3 = 0 , L_ 7 = 0  | Y =  1 ) =  0.017406265352885343\n",
      "P(L_ 3 = 0 , L_ 7 = 1  | Y =  1 ) =  0.04456643460322895\n",
      "P(L_ 3 = 0 , L_ 7 = 2  | Y =  1 ) =  0.03760962196409899\n",
      "P(L_ 3 = 1 , L_ 7 = 0  | Y =  1 ) =  0.07640003723977835\n",
      "P(L_ 3 = 1 , L_ 7 = 1  | Y =  1 ) =  0.19559909061805097\n",
      "P(L_ 3 = 1 , L_ 7 = 2  | Y =  1 ) =  0.16508605244699298\n",
      "P(L_ 3 = 2 , L_ 7 = 0  | Y =  1 ) =  0.0809881462613275\n",
      "P(L_ 3 = 2 , L_ 7 = 1  | Y =  1 ) =  0.20734438551028303\n",
      "P(L_ 3 = 2 , L_ 7 = 2  | Y =  1 ) =  0.1749999660033539\n",
      "Labelers =  (3, 8)\n",
      "P(L_ 3 = 0 , L_ 8 = 0  | Y =  1 ) =  0.018916742915877548\n",
      "P(L_ 3 = 0 , L_ 8 = 1  | Y =  1 ) =  0.04713805083917836\n",
      "P(L_ 3 = 0 , L_ 8 = 2  | Y =  1 ) =  0.033527528165157354\n",
      "P(L_ 3 = 1 , L_ 8 = 0  | Y =  1 ) =  0.04675410757338524\n",
      "P(L_ 3 = 1 , L_ 8 = 1  | Y =  1 ) =  0.2512437570033407\n",
      "P(L_ 3 = 1 , L_ 8 = 2  | Y =  1 ) =  0.1390873157280963\n",
      "P(L_ 3 = 2 , L_ 8 = 0  | Y =  1 ) =  0.0626220664163634\n",
      "P(L_ 3 = 2 , L_ 8 = 1  | Y =  1 ) =  0.27248229739322727\n",
      "P(L_ 3 = 2 , L_ 8 = 2  | Y =  1 ) =  0.12822813396537366\n",
      "Labelers =  (3, 9)\n",
      "P(L_ 3 = 0 , L_ 9 = 0  | Y =  1 ) =  0.016789967053702885\n",
      "P(L_ 3 = 0 , L_ 9 = 1  | Y =  1 ) =  0.05219860801996536\n",
      "P(L_ 3 = 0 , L_ 9 = 2  | Y =  1 ) =  0.030593746846545023\n",
      "P(L_ 3 = 1 , L_ 9 = 0  | Y =  1 ) =  0.0736905399034982\n",
      "P(L_ 3 = 1 , L_ 9 = 1  | Y =  1 ) =  0.22910256248194671\n",
      "P(L_ 3 = 1 , L_ 9 = 2  | Y =  1 ) =  0.13429207791937725\n",
      "P(L_ 3 = 2 , L_ 9 = 0  | Y =  1 ) =  0.07811603560677748\n",
      "P(L_ 3 = 2 , L_ 9 = 1  | Y =  1 ) =  0.24286086200176676\n",
      "P(L_ 3 = 2 , L_ 9 = 2  | Y =  1 ) =  0.14235560016642004\n",
      "Labelers =  (4, 5)\n",
      "P(L_ 4 = 0 , L_ 5 = 0  | Y =  1 ) =  0.020143711144067048\n",
      "P(L_ 4 = 0 , L_ 5 = 1  | Y =  1 ) =  0.03834205781238426\n",
      "P(L_ 4 = 0 , L_ 5 = 2  | Y =  1 ) =  0.04908098862959029\n",
      "P(L_ 4 = 1 , L_ 5 = 0  | Y =  1 ) =  0.06480136502184404\n",
      "P(L_ 4 = 1 , L_ 5 = 1  | Y =  1 ) =  0.13775602887442281\n",
      "P(L_ 4 = 1 , L_ 5 = 2  | Y =  1 ) =  0.18647908793621162\n",
      "P(L_ 4 = 2 , L_ 5 = 0  | Y =  1 ) =  0.05291175500751622\n",
      "P(L_ 4 = 2 , L_ 5 = 1  | Y =  1 ) =  0.11791233140614717\n",
      "P(L_ 4 = 2 , L_ 5 = 2  | Y =  1 ) =  0.33257267416781644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labelers =  (4, 6)\n",
      "P(L_ 4 = 0 , L_ 6 = 0  | Y =  1 ) =  0.018162712499619267\n",
      "P(L_ 4 = 0 , L_ 6 = 1  | Y =  1 ) =  0.05688754356182601\n",
      "P(L_ 4 = 0 , L_ 6 = 2  | Y =  1 ) =  0.0325165015245963\n",
      "P(L_ 4 = 1 , L_ 6 = 0  | Y =  1 ) =  0.06570811024630711\n",
      "P(L_ 4 = 1 , L_ 6 = 1  | Y =  1 ) =  0.20571519967598428\n",
      "P(L_ 4 = 1 , L_ 6 = 2  | Y =  1 ) =  0.11761317191018707\n",
      "P(L_ 4 = 2 , L_ 6 = 0  | Y =  1 ) =  0.08500618296566426\n",
      "P(L_ 4 = 2 , L_ 6 = 1  | Y =  1 ) =  0.2662136233618588\n",
      "P(L_ 4 = 2 , L_ 6 = 2  | Y =  1 ) =  0.1521769542539568\n",
      "Labelers =  (4, 7)\n",
      "P(L_ 4 = 0 , L_ 7 = 0  | Y =  1 ) =  0.01925701348185254\n",
      "P(L_ 4 = 0 , L_ 7 = 1  | Y =  1 ) =  0.046235861299082054\n",
      "P(L_ 4 = 0 , L_ 7 = 2  | Y =  1 ) =  0.04207388280510701\n",
      "P(L_ 4 = 1 , L_ 7 = 0  | Y =  1 ) =  0.06896290407750161\n",
      "P(L_ 4 = 1 , L_ 7 = 1  | Y =  1 ) =  0.16879415841027404\n",
      "P(L_ 4 = 1 , L_ 7 = 2  | Y =  1 ) =  0.15127941934470288\n",
      "P(L_ 4 = 2 , L_ 7 = 0  | Y =  1 ) =  0.08657453129463706\n",
      "P(L_ 4 = 2 , L_ 7 = 1  | Y =  1 ) =  0.23247989102220679\n",
      "P(L_ 4 = 2 , L_ 7 = 2  | Y =  1 ) =  0.184342338264636\n",
      "Labelers =  (4, 8)\n",
      "P(L_ 4 = 0 , L_ 8 = 0  | Y =  1 ) =  0.01382054152267628\n",
      "P(L_ 4 = 0 , L_ 8 = 1  | Y =  1 ) =  0.06137682680093568\n",
      "P(L_ 4 = 0 , L_ 8 = 2  | Y =  1 ) =  0.03236938926242964\n",
      "P(L_ 4 = 1 , L_ 8 = 0  | Y =  1 ) =  0.04988167960516181\n",
      "P(L_ 4 = 1 , L_ 8 = 1  | Y =  1 ) =  0.22212963388263723\n",
      "P(L_ 4 = 1 , L_ 8 = 2  | Y =  1 ) =  0.11702516834467945\n",
      "P(L_ 4 = 2 , L_ 8 = 0  | Y =  1 ) =  0.06459069577778812\n",
      "P(L_ 4 = 2 , L_ 8 = 1  | Y =  1 ) =  0.2873576445521735\n",
      "P(L_ 4 = 2 , L_ 8 = 2  | Y =  1 ) =  0.15144842025151825\n",
      "Labelers =  (4, 9)\n",
      "P(L_ 4 = 0 , L_ 9 = 0  | Y =  1 ) =  0.01813638689832147\n",
      "P(L_ 4 = 0 , L_ 9 = 1  | Y =  1 ) =  0.0563844711836837\n",
      "P(L_ 4 = 0 , L_ 9 = 2  | Y =  1 ) =  0.03304589950403641\n",
      "P(L_ 4 = 1 , L_ 9 = 0  | Y =  1 ) =  0.06558885025981166\n",
      "P(L_ 4 = 1 , L_ 9 = 1  | Y =  1 ) =  0.20391263588429914\n",
      "P(L_ 4 = 1 , L_ 9 = 2  | Y =  1 ) =  0.1195349956883676\n",
      "P(L_ 4 = 2 , L_ 9 = 0  | Y =  1 ) =  0.08487130540584545\n",
      "P(L_ 4 = 2 , L_ 9 = 1  | Y =  1 ) =  0.263864925435696\n",
      "P(L_ 4 = 2 , L_ 9 = 2  | Y =  1 ) =  0.15466052973993827\n",
      "Labelers =  (5, 6)\n",
      "P(L_ 5 = 0 , L_ 6 = 0  | Y =  1 ) =  0.02328115606333602\n",
      "P(L_ 5 = 0 , L_ 6 = 1  | Y =  1 ) =  0.07290047729198303\n",
      "P(L_ 5 = 0 , L_ 6 = 2  | Y =  1 ) =  0.04167519781810823\n",
      "P(L_ 5 = 1 , L_ 6 = 0  | Y =  1 ) =  0.04965230610865076\n",
      "P(L_ 5 = 1 , L_ 6 = 1  | Y =  1 ) =  0.15547643155579746\n",
      "P(L_ 5 = 1 , L_ 6 = 2  | Y =  1 ) =  0.08888168042850601\n",
      "P(L_ 5 = 2 , L_ 6 = 0  | Y =  1 ) =  0.09594354353960385\n",
      "P(L_ 5 = 2 , L_ 6 = 1  | Y =  1 ) =  0.3004394577518886\n",
      "P(L_ 5 = 2 , L_ 6 = 2  | Y =  1 ) =  0.17174974944212593\n",
      "Labelers =  (5, 7)\n",
      "P(L_ 5 = 0 , L_ 7 = 0  | Y =  1 ) =  0.034159626431652164\n",
      "P(L_ 5 = 0 , L_ 7 = 1  | Y =  1 ) =  0.04610661931947464\n",
      "P(L_ 5 = 0 , L_ 7 = 2  | Y =  1 ) =  0.05759058542230048\n",
      "P(L_ 5 = 1 , L_ 7 = 0  | Y =  1 ) =  0.04807185134696156\n",
      "P(L_ 5 = 1 , L_ 7 = 1  | Y =  1 ) =  0.10952859036556749\n",
      "P(L_ 5 = 1 , L_ 7 = 2  | Y =  1 ) =  0.13640997638042524\n",
      "P(L_ 5 = 2 , L_ 7 = 0  | Y =  1 ) =  0.09256297107537745\n",
      "P(L_ 5 = 2 , L_ 7 = 1  | Y =  1 ) =  0.2918747010465207\n",
      "P(L_ 5 = 2 , L_ 7 = 2  | Y =  1 ) =  0.1836950786117202\n",
      "Labelers =  (5, 8)\n",
      "P(L_ 5 = 0 , L_ 8 = 0  | Y =  1 ) =  0.017685959297850443\n",
      "P(L_ 5 = 0 , L_ 8 = 1  | Y =  1 ) =  0.0786977422314125\n",
      "P(L_ 5 = 0 , L_ 8 = 2  | Y =  1 ) =  0.041473129644164344\n",
      "P(L_ 5 = 1 , L_ 8 = 0  | Y =  1 ) =  0.037718488685094184\n",
      "P(L_ 5 = 1 , L_ 8 = 1  | Y =  1 ) =  0.16784154334035178\n",
      "P(L_ 5 = 1 , L_ 8 = 2  | Y =  1 ) =  0.0884503860675083\n",
      "P(L_ 5 = 2 , L_ 8 = 0  | Y =  1 ) =  0.07288846892268157\n",
      "P(L_ 5 = 2 , L_ 8 = 1  | Y =  1 ) =  0.32432481966398213\n",
      "P(L_ 5 = 2 , L_ 8 = 2  | Y =  1 ) =  0.1709194621469547\n",
      "Labelers =  (5, 9)\n",
      "P(L_ 5 = 0 , L_ 9 = 0  | Y =  1 ) =  0.023242184238985213\n",
      "P(L_ 5 = 0 , L_ 9 = 1  | Y =  1 ) =  0.07225914705992398\n",
      "P(L_ 5 = 0 , L_ 9 = 2  | Y =  1 ) =  0.04235549987451806\n",
      "P(L_ 5 = 1 , L_ 9 = 0  | Y =  1 ) =  0.04956910013449886\n",
      "P(L_ 5 = 1 , L_ 9 = 1  | Y =  1 ) =  0.15410868890179694\n",
      "P(L_ 5 = 1 , L_ 9 = 2  | Y =  1 ) =  0.09033262905665843\n",
      "P(L_ 5 = 2 , L_ 9 = 0  | Y =  1 ) =  0.09578525819049451\n",
      "P(L_ 5 = 2 , L_ 9 = 1  | Y =  1 ) =  0.29779419654195793\n",
      "P(L_ 5 = 2 , L_ 9 = 2  | Y =  1 ) =  0.17455329600116581\n",
      "Labelers =  (6, 7)\n",
      "P(L_ 6 = 0 , L_ 7 = 0  | Y =  1 ) =  0.029518789617419734\n",
      "P(L_ 6 = 0 , L_ 7 = 1  | Y =  1 ) =  0.07557397882927151\n",
      "P(L_ 6 = 0 , L_ 7 = 2  | Y =  1 ) =  0.06378423726489937\n",
      "P(L_ 6 = 1 , L_ 7 = 0  | Y =  1 ) =  0.09243412471842913\n",
      "P(L_ 6 = 1 , L_ 7 = 1  | Y =  1 ) =  0.2366508033533719\n",
      "P(L_ 6 = 1 , L_ 7 = 2  | Y =  1 ) =  0.19973143852786793\n",
      "P(L_ 6 = 2 , L_ 7 = 0  | Y =  1 ) =  0.052841534518142316\n",
      "P(L_ 6 = 2 , L_ 7 = 1  | Y =  1 ) =  0.13528512854891941\n",
      "P(L_ 6 = 2 , L_ 7 = 2  | Y =  1 ) =  0.11417996462167847\n",
      "Labelers =  (6, 8)\n",
      "P(L_ 6 = 0 , L_ 8 = 0  | Y =  1 ) =  0.021665593976656603\n",
      "P(L_ 6 = 0 , L_ 8 = 1  | Y =  1 ) =  0.09640600807607974\n",
      "P(L_ 6 = 0 , L_ 8 = 2  | Y =  1 ) =  0.050805403658854276\n",
      "P(L_ 6 = 1 , L_ 8 = 0  | Y =  1 ) =  0.06784359996005858\n",
      "P(L_ 6 = 1 , L_ 8 = 1  | Y =  1 ) =  0.3018819849139723\n",
      "P(L_ 6 = 1 , L_ 8 = 2  | Y =  1 ) =  0.1590907817256381\n",
      "P(L_ 6 = 2 , L_ 8 = 0  | Y =  1 ) =  0.03878372296891099\n",
      "P(L_ 6 = 2 , L_ 8 = 1  | Y =  1 ) =  0.17257611224569433\n",
      "P(L_ 6 = 2 , L_ 8 = 2  | Y =  1 ) =  0.09094679247413483\n",
      "Labelers =  (6, 9)\n",
      "P(L_ 6 = 0 , L_ 9 = 0  | Y =  1 ) =  0.028615665305093504\n",
      "P(L_ 6 = 0 , L_ 9 = 1  | Y =  1 ) =  0.08796470024309401\n",
      "P(L_ 6 = 0 , L_ 9 = 2  | Y =  1 ) =  0.05229664016340311\n",
      "P(L_ 6 = 1 , L_ 9 = 0  | Y =  1 ) =  0.08894663051532413\n",
      "P(L_ 6 = 1 , L_ 9 = 1  | Y =  1 ) =  0.27803057514141666\n",
      "P(L_ 6 = 1 , L_ 9 = 2  | Y =  1 ) =  0.1618391609429281\n",
      "P(L_ 6 = 2 , L_ 9 = 0  | Y =  1 ) =  0.051034246743560954\n",
      "P(L_ 6 = 2 , L_ 9 = 1  | Y =  1 ) =  0.15816675711916814\n",
      "P(L_ 6 = 2 , L_ 9 = 2  | Y =  1 ) =  0.09310562382601104\n",
      "Labelers =  (7, 8)\n",
      "P(L_ 7 = 0 , L_ 8 = 0  | Y =  1 ) =  0.02242488102269446\n",
      "P(L_ 7 = 0 , L_ 8 = 1  | Y =  1 ) =  0.09978389669233402\n",
      "P(L_ 7 = 0 , L_ 8 = 2  | Y =  1 ) =  0.052585671138962724\n",
      "P(L_ 7 = 1 , L_ 8 = 0  | Y =  1 ) =  0.05741250528041583\n",
      "P(L_ 7 = 1 , L_ 8 = 1  | Y =  1 ) =  0.2554670855687163\n",
      "P(L_ 7 = 1 , L_ 8 = 2  | Y =  1 ) =  0.1346303198824308\n",
      "P(L_ 7 = 2 , L_ 8 = 0  | Y =  1 ) =  0.04845553060251591\n",
      "P(L_ 7 = 2 , L_ 8 = 1  | Y =  1 ) =  0.21561312297469618\n",
      "P(L_ 7 = 2 , L_ 8 = 2  | Y =  1 ) =  0.11362698683723386\n",
      "Labelers =  (7, 9)\n",
      "P(L_ 7 = 0 , L_ 9 = 0  | Y =  1 ) =  0.02946973963962854\n",
      "P(L_ 7 = 0 , L_ 9 = 1  | Y =  1 ) =  0.09162059893760091\n",
      "P(L_ 7 = 0 , L_ 9 = 2  | Y =  1 ) =  0.053704110276761696\n",
      "P(L_ 7 = 1 , L_ 9 = 0  | Y =  1 ) =  0.07544862949262306\n",
      "P(L_ 7 = 1 , L_ 9 = 1  | Y =  1 ) =  0.23456779262642785\n",
      "P(L_ 7 = 1 , L_ 9 = 2  | Y =  1 ) =  0.1374934886125119\n",
      "P(L_ 7 = 2 , L_ 9 = 0  | Y =  1 ) =  0.063678173431727\n",
      "P(L_ 7 = 2 , L_ 9 = 1  | Y =  1 ) =  0.19797364093965011\n",
      "P(L_ 7 = 2 , L_ 9 = 2  | Y =  1 ) =  0.11604382604306868\n",
      "Labelers =  (8, 9)\n",
      "P(L_ 8 = 0 , L_ 9 = 0  | Y =  1 ) =  0.02162979672063379\n",
      "P(L_ 8 = 0 , L_ 9 = 1  | Y =  1 ) =  0.06724637448757376\n",
      "P(L_ 8 = 0 , L_ 9 = 2  | Y =  1 ) =  0.039416745697418626\n",
      "P(L_ 8 = 1 , L_ 9 = 0  | Y =  1 ) =  0.09624563721957277\n",
      "P(L_ 8 = 1 , L_ 9 = 1  | Y =  1 ) =  0.29922514829429886\n",
      "P(L_ 8 = 1 , L_ 9 = 2  | Y =  1 ) =  0.17539331972187455\n",
      "P(L_ 8 = 2 , L_ 9 = 0  | Y =  1 ) =  0.050721108623772\n",
      "P(L_ 8 = 2 , L_ 9 = 1  | Y =  1 ) =  0.15769050972180615\n",
      "P(L_ 8 = 2 , L_ 9 = 2  | Y =  1 ) =  0.09243135951304912\n",
      "Labelers =  (0, 1)\n",
      "P(L_ 0 = 0 , L_ 1 = 0  | Y =  2 ) =  0.007379398046895549\n",
      "P(L_ 0 = 0 , L_ 1 = 1  | Y =  2 ) =  0.026069297638547727\n",
      "P(L_ 0 = 0 , L_ 1 = 2  | Y =  2 ) =  0.012748490465989862\n",
      "P(L_ 0 = 1 , L_ 1 = 0  | Y =  2 ) =  0.037999867563542546\n",
      "P(L_ 0 = 1 , L_ 1 = 1  | Y =  2 ) =  0.2578023940585031\n",
      "P(L_ 0 = 1 , L_ 1 = 2  | Y =  2 ) =  0.09176074172933342\n",
      "P(L_ 0 = 2 , L_ 1 = 0  | Y =  2 ) =  0.05505009234372541\n",
      "P(L_ 0 = 2 , L_ 1 = 1  | Y =  2 ) =  0.34737795634461227\n",
      "P(L_ 0 = 2 , L_ 1 = 2  | Y =  2 ) =  0.16381176180885\n",
      "Labelers =  (0, 2)\n",
      "P(L_ 0 = 0 , L_ 2 = 0  | Y =  2 ) =  0.002055638954401455\n",
      "P(L_ 0 = 0 , L_ 2 = 1  | Y =  2 ) =  0.024033736275445198\n",
      "P(L_ 0 = 0 , L_ 2 = 2  | Y =  2 ) =  0.020107810921586488\n",
      "P(L_ 0 = 1 , L_ 2 = 0  | Y =  2 ) =  0.016522654823208062\n",
      "P(L_ 0 = 1 , L_ 2 = 1  | Y =  2 ) =  0.20878558625071802\n",
      "P(L_ 0 = 1 , L_ 2 = 2  | Y =  2 ) =  0.162254762277453\n",
      "P(L_ 0 = 2 , L_ 2 = 0  | Y =  2 ) =  0.024319339077229756\n",
      "P(L_ 0 = 2 , L_ 2 = 1  | Y =  2 ) =  0.29788036481284047\n",
      "P(L_ 0 = 2 , L_ 2 = 2  | Y =  2 ) =  0.24404010660711756\n",
      "Labelers =  (0, 3)\n",
      "P(L_ 0 = 0 , L_ 3 = 0  | Y =  2 ) =  0.009139911174983913\n",
      "P(L_ 0 = 0 , L_ 3 = 1  | Y =  2 ) =  0.013190516081477636\n",
      "P(L_ 0 = 0 , L_ 3 = 2  | Y =  2 ) =  0.02386675889497159\n",
      "P(L_ 0 = 1 , L_ 3 = 0  | Y =  2 ) =  0.041920104425321236\n",
      "P(L_ 0 = 1 , L_ 3 = 1  | Y =  2 ) =  0.14923693957589626\n",
      "P(L_ 0 = 1 , L_ 3 = 2  | Y =  2 ) =  0.19640595935016159\n",
      "P(L_ 0 = 2 , L_ 3 = 0  | Y =  2 ) =  0.06796348415542644\n",
      "P(L_ 0 = 2 , L_ 3 = 1  | Y =  2 ) =  0.15004764949598035\n",
      "P(L_ 0 = 2 , L_ 3 = 2  | Y =  2 ) =  0.34822867684578096\n",
      "Labelers =  (0, 4)\n",
      "P(L_ 0 = 0 , L_ 4 = 0  | Y =  2 ) =  0.007844950613034751\n",
      "P(L_ 0 = 0 , L_ 4 = 1  | Y =  2 ) =  0.022064913683927732\n",
      "P(L_ 0 = 0 , L_ 4 = 2  | Y =  2 ) =  0.016287321854470658\n",
      "P(L_ 0 = 1 , L_ 4 = 0  | Y =  2 ) =  0.03898855019420802\n",
      "P(L_ 0 = 1 , L_ 4 = 1  | Y =  2 ) =  0.22555652376229532\n",
      "P(L_ 0 = 1 , L_ 4 = 2  | Y =  2 ) =  0.12301792939487577\n",
      "P(L_ 0 = 2 , L_ 4 = 0  | Y =  2 ) =  0.05467525975509851\n",
      "P(L_ 0 = 2 , L_ 4 = 1  | Y =  2 ) =  0.23425458842158164\n",
      "P(L_ 0 = 2 , L_ 4 = 2  | Y =  2 ) =  0.27730996232050753\n",
      "Labelers =  (0, 5)\n",
      "P(L_ 0 = 0 , L_ 5 = 0  | Y =  2 ) =  0.005072603085584942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(L_ 0 = 0 , L_ 5 = 1  | Y =  2 ) =  0.026165718037244774\n",
      "P(L_ 0 = 0 , L_ 5 = 2  | Y =  2 ) =  0.014958865028603427\n",
      "P(L_ 0 = 1 , L_ 5 = 0  | Y =  2 ) =  0.04043846299552396\n",
      "P(L_ 0 = 1 , L_ 5 = 1  | Y =  2 ) =  0.21877971186765233\n",
      "P(L_ 0 = 1 , L_ 5 = 2  | Y =  2 ) =  0.1283448284882028\n",
      "P(L_ 0 = 2 , L_ 5 = 0  | Y =  2 ) =  0.060825499634332404\n",
      "P(L_ 0 = 2 , L_ 5 = 1  | Y =  2 ) =  0.3232481241530389\n",
      "P(L_ 0 = 2 , L_ 5 = 2  | Y =  2 ) =  0.18216618670981646\n",
      "Labelers =  (0, 6)\n",
      "P(L_ 0 = 0 , L_ 6 = 0  | Y =  2 ) =  0.0055434123957499425\n",
      "P(L_ 0 = 0 , L_ 6 = 1  | Y =  2 ) =  0.021762021691540248\n",
      "P(L_ 0 = 0 , L_ 6 = 2  | Y =  2 ) =  0.018891752064142946\n",
      "P(L_ 0 = 1 , L_ 6 = 0  | Y =  2 ) =  0.04635087404410608\n",
      "P(L_ 0 = 1 , L_ 6 = 1  | Y =  2 ) =  0.1828166533822908\n",
      "P(L_ 0 = 1 , L_ 6 = 2  | Y =  2 ) =  0.15839547592498224\n",
      "P(L_ 0 = 2 , L_ 6 = 0  | Y =  2 ) =  0.06782413241459707\n",
      "P(L_ 0 = 2 , L_ 6 = 1  | Y =  2 ) =  0.2668654888359076\n",
      "P(L_ 0 = 2 , L_ 6 = 2  | Y =  2 ) =  0.23155018924668305\n",
      "Labelers =  (0, 7)\n",
      "P(L_ 0 = 0 , L_ 7 = 0  | Y =  2 ) =  0.009329019441654441\n",
      "P(L_ 0 = 0 , L_ 7 = 1  | Y =  2 ) =  0.02079202509850055\n",
      "P(L_ 0 = 0 , L_ 7 = 2  | Y =  2 ) =  0.016076141611278155\n",
      "P(L_ 0 = 1 , L_ 7 = 0  | Y =  2 ) =  0.07805047605467409\n",
      "P(L_ 0 = 1 , L_ 7 = 1  | Y =  2 ) =  0.17451214805634527\n",
      "P(L_ 0 = 1 , L_ 7 = 2  | Y =  2 ) =  0.13500037924035974\n",
      "P(L_ 0 = 2 , L_ 7 = 0  | Y =  2 ) =  0.11419747665256648\n",
      "P(L_ 0 = 2 , L_ 7 = 1  | Y =  2 ) =  0.25513075639083077\n",
      "P(L_ 0 = 2 , L_ 7 = 2  | Y =  2 ) =  0.19691157745379045\n",
      "Labelers =  (0, 8)\n",
      "P(L_ 0 = 0 , L_ 8 = 0  | Y =  2 ) =  0.010817614095678083\n",
      "P(L_ 0 = 0 , L_ 8 = 1  | Y =  2 ) =  0.016579233448213115\n",
      "P(L_ 0 = 0 , L_ 8 = 2  | Y =  2 ) =  0.018800338607541944\n",
      "P(L_ 0 = 1 , L_ 8 = 0  | Y =  2 ) =  0.08889560996171116\n",
      "P(L_ 0 = 1 , L_ 8 = 1  | Y =  2 ) =  0.1399867390909882\n",
      "P(L_ 0 = 1 , L_ 8 = 2  | Y =  2 ) =  0.1586806542986798\n",
      "P(L_ 0 = 2 , L_ 8 = 0  | Y =  2 ) =  0.12871677171906903\n",
      "P(L_ 0 = 2 , L_ 8 = 1  | Y =  2 ) =  0.20220298843498247\n",
      "P(L_ 0 = 2 , L_ 8 = 2  | Y =  2 ) =  0.23532005034313627\n",
      "Labelers =  (0, 9)\n",
      "P(L_ 0 = 0 , L_ 9 = 0  | Y =  2 ) =  0.00541237673773328\n",
      "P(L_ 0 = 0 , L_ 9 = 1  | Y =  2 ) =  0.02010383113763298\n",
      "P(L_ 0 = 0 , L_ 9 = 2  | Y =  2 ) =  0.020680978276066877\n",
      "P(L_ 0 = 1 , L_ 9 = 0  | Y =  2 ) =  0.045466434284129366\n",
      "P(L_ 0 = 1 , L_ 9 = 1  | Y =  2 ) =  0.16933796358601202\n",
      "P(L_ 0 = 1 , L_ 9 = 2  | Y =  2 ) =  0.17275860548123767\n",
      "P(L_ 0 = 2 , L_ 9 = 0  | Y =  2 ) =  0.06632332198772704\n",
      "P(L_ 0 = 2 , L_ 9 = 1  | Y =  2 ) =  0.2466780488177102\n",
      "P(L_ 0 = 2 , L_ 9 = 2  | Y =  2 ) =  0.2532384396917504\n",
      "Labelers =  (1, 2)\n",
      "P(L_ 1 = 0 , L_ 2 = 0  | Y =  2 ) =  0.006496147670618618\n",
      "P(L_ 1 = 0 , L_ 2 = 1  | Y =  2 ) =  0.046743968552975454\n",
      "P(L_ 1 = 0 , L_ 2 = 2  | Y =  2 ) =  0.047189241730569424\n",
      "P(L_ 1 = 1 , L_ 2 = 0  | Y =  2 ) =  0.024331296214012584\n",
      "P(L_ 1 = 1 , L_ 2 = 1  | Y =  2 ) =  0.3853592141643739\n",
      "P(L_ 1 = 1 , L_ 2 = 2  | Y =  2 ) =  0.2215591376632767\n",
      "P(L_ 1 = 2 , L_ 2 = 0  | Y =  2 ) =  0.012070188970208073\n",
      "P(L_ 1 = 2 , L_ 2 = 1  | Y =  2 ) =  0.0985965046216543\n",
      "P(L_ 1 = 2 , L_ 2 = 2  | Y =  2 ) =  0.15765430041231085\n",
      "Labelers =  (1, 3)\n",
      "P(L_ 1 = 0 , L_ 3 = 0  | Y =  2 ) =  0.012177614668491304\n",
      "P(L_ 1 = 0 , L_ 3 = 1  | Y =  2 ) =  0.03132713196249647\n",
      "P(L_ 1 = 0 , L_ 3 = 2  | Y =  2 ) =  0.056924611323175736\n",
      "P(L_ 1 = 1 , L_ 3 = 0  | Y =  2 ) =  0.07473683868965268\n",
      "P(L_ 1 = 1 , L_ 3 = 1  | Y =  2 ) =  0.19876568466169733\n",
      "P(L_ 1 = 1 , L_ 3 = 2  | Y =  2 ) =  0.3577471246903131\n",
      "P(L_ 1 = 2 , L_ 3 = 0  | Y =  2 ) =  0.03210904639758759\n",
      "P(L_ 1 = 2 , L_ 3 = 1  | Y =  2 ) =  0.08238228852916045\n",
      "P(L_ 1 = 2 , L_ 3 = 2  | Y =  2 ) =  0.15382965907742518\n",
      "Labelers =  (1, 4)\n",
      "P(L_ 1 = 0 , L_ 4 = 0  | Y =  2 ) =  0.010391440664176937\n",
      "P(L_ 1 = 0 , L_ 4 = 1  | Y =  2 ) =  0.04841433857177685\n",
      "P(L_ 1 = 0 , L_ 4 = 2  | Y =  2 ) =  0.04162357871820973\n",
      "P(L_ 1 = 1 , L_ 4 = 0  | Y =  2 ) =  0.06390396334038412\n",
      "P(L_ 1 = 1 , L_ 4 = 1  | Y =  2 ) =  0.3061998937049735\n",
      "P(L_ 1 = 1 , L_ 4 = 2  | Y =  2 ) =  0.2611457909963055\n",
      "P(L_ 1 = 2 , L_ 4 = 0  | Y =  2 ) =  0.027213356557780205\n",
      "P(L_ 1 = 2 , L_ 4 = 1  | Y =  2 ) =  0.12726179359105427\n",
      "P(L_ 1 = 2 , L_ 4 = 2  | Y =  2 ) =  0.11384584385533876\n",
      "Labelers =  (1, 5)\n",
      "P(L_ 1 = 0 , L_ 5 = 0  | Y =  2 ) =  0.010688684810661691\n",
      "P(L_ 1 = 0 , L_ 5 = 1  | Y =  2 ) =  0.05705692624749822\n",
      "P(L_ 1 = 0 , L_ 5 = 2  | Y =  2 ) =  0.0326837468960036\n",
      "P(L_ 1 = 1 , L_ 5 = 0  | Y =  2 ) =  0.06707704093227604\n",
      "P(L_ 1 = 1 , L_ 5 = 1  | Y =  2 ) =  0.3586020775114825\n",
      "P(L_ 1 = 1 , L_ 5 = 2  | Y =  2 ) =  0.20557052959790462\n",
      "P(L_ 1 = 2 , L_ 5 = 0  | Y =  2 ) =  0.028570839972503575\n",
      "P(L_ 1 = 2 , L_ 5 = 1  | Y =  2 ) =  0.1525345502989552\n",
      "P(L_ 1 = 2 , L_ 5 = 2  | Y =  2 ) =  0.08721560373271448\n",
      "Labelers =  (1, 6)\n",
      "P(L_ 1 = 0 , L_ 6 = 0  | Y =  2 ) =  0.012306137685992055\n",
      "P(L_ 1 = 0 , L_ 6 = 1  | Y =  2 ) =  0.04708135822038161\n",
      "P(L_ 1 = 0 , L_ 6 = 2  | Y =  2 ) =  0.04104186204778983\n",
      "P(L_ 1 = 1 , L_ 6 = 0  | Y =  2 ) =  0.07470120324646838\n",
      "P(L_ 1 = 1 , L_ 6 = 1  | Y =  2 ) =  0.29928521243589806\n",
      "P(L_ 1 = 1 , L_ 6 = 2  | Y =  2 ) =  0.25726323235929677\n",
      "P(L_ 1 = 2 , L_ 6 = 0  | Y =  2 ) =  0.03271107792199265\n",
      "P(L_ 1 = 2 , L_ 6 = 1  | Y =  2 ) =  0.12507759325345902\n",
      "P(L_ 1 = 2 , L_ 6 = 2  | Y =  2 ) =  0.1105323228287216\n",
      "Labelers =  (1, 7)\n",
      "P(L_ 1 = 0 , L_ 7 = 0  | Y =  2 ) =  0.02024523114921178\n",
      "P(L_ 1 = 0 , L_ 7 = 1  | Y =  2 ) =  0.045235790949716276\n",
      "P(L_ 1 = 0 , L_ 7 = 2  | Y =  2 ) =  0.034948335855235456\n",
      "P(L_ 1 = 1 , L_ 7 = 0  | Y =  2 ) =  0.12724077985487503\n",
      "P(L_ 1 = 1 , L_ 7 = 1  | Y =  2 ) =  0.2843346266945693\n",
      "P(L_ 1 = 1 , L_ 7 = 2  | Y =  2 ) =  0.2196742414922189\n",
      "P(L_ 1 = 2 , L_ 7 = 0  | Y =  2 ) =  0.05409096114480824\n",
      "P(L_ 1 = 2 , L_ 7 = 1  | Y =  2 ) =  0.120864511901391\n",
      "P(L_ 1 = 2 , L_ 7 = 2  | Y =  2 ) =  0.093365520957974\n",
      "Labelers =  (1, 8)\n",
      "P(L_ 1 = 0 , L_ 8 = 0  | Y =  2 ) =  0.022957933427704972\n",
      "P(L_ 1 = 0 , L_ 8 = 1  | Y =  2 ) =  0.03603203537307888\n",
      "P(L_ 1 = 0 , L_ 8 = 2  | Y =  2 ) =  0.04143938915337966\n",
      "P(L_ 1 = 1 , L_ 8 = 0  | Y =  2 ) =  0.1442021846097643\n",
      "P(L_ 1 = 1 , L_ 8 = 1  | Y =  2 ) =  0.2265211927689233\n",
      "P(L_ 1 = 1 , L_ 8 = 2  | Y =  2 ) =  0.2605262706629756\n",
      "P(L_ 1 = 2 , L_ 8 = 0  | Y =  2 ) =  0.061269877738988995\n",
      "P(L_ 1 = 2 , L_ 8 = 1  | Y =  2 ) =  0.09621573283218161\n",
      "P(L_ 1 = 2 , L_ 8 = 2  | Y =  2 ) =  0.11083538343300266\n",
      "Labelers =  (1, 9)\n",
      "P(L_ 1 = 0 , L_ 9 = 0  | Y =  2 ) =  0.011839037015298676\n",
      "P(L_ 1 = 0 , L_ 9 = 1  | Y =  2 ) =  0.04331249924036644\n",
      "P(L_ 1 = 0 , L_ 9 = 2  | Y =  2 ) =  0.04527782169849838\n",
      "P(L_ 1 = 1 , L_ 9 = 0  | Y =  2 ) =  0.0745970443392745\n",
      "P(L_ 1 = 1 , L_ 9 = 1  | Y =  2 ) =  0.28029548053527026\n",
      "P(L_ 1 = 1 , L_ 9 = 2  | Y =  2 ) =  0.27635712316711836\n",
      "P(L_ 1 = 2 , L_ 9 = 0  | Y =  2 ) =  0.030766051655016523\n",
      "P(L_ 1 = 2 , L_ 9 = 1  | Y =  2 ) =  0.11251186376571849\n",
      "P(L_ 1 = 2 , L_ 9 = 2  | Y =  2 ) =  0.12504307858343822\n",
      "Labelers =  (2, 3)\n",
      "P(L_ 2 = 0 , L_ 3 = 0  | Y =  2 ) =  0.005112796847780446\n",
      "P(L_ 2 = 0 , L_ 3 = 1  | Y =  2 ) =  0.013393606353084035\n",
      "P(L_ 2 = 0 , L_ 3 = 2  | Y =  2 ) =  0.02439122965397479\n",
      "P(L_ 2 = 1 , L_ 3 = 0  | Y =  2 ) =  0.0630912941165677\n",
      "P(L_ 2 = 1 , L_ 3 = 1  | Y =  2 ) =  0.16619347612850688\n",
      "P(L_ 2 = 1 , L_ 3 = 2  | Y =  2 ) =  0.3014149170939291\n",
      "P(L_ 2 = 2 , L_ 3 = 0  | Y =  2 ) =  0.05081940879138343\n",
      "P(L_ 2 = 2 , L_ 3 = 1  | Y =  2 ) =  0.13288802267176333\n",
      "P(L_ 2 = 2 , L_ 3 = 2  | Y =  2 ) =  0.24269524834301023\n",
      "Labelers =  (2, 4)\n",
      "P(L_ 2 = 0 , L_ 4 = 0  | Y =  2 ) =  0.004359482638287472\n",
      "P(L_ 2 = 0 , L_ 4 = 1  | Y =  2 ) =  0.020658750787805803\n",
      "P(L_ 2 = 0 , L_ 4 = 2  | Y =  2 ) =  0.017879399428746\n",
      "P(L_ 2 = 1 , L_ 4 = 0  | Y =  2 ) =  0.05384782854016754\n",
      "P(L_ 2 = 1 , L_ 4 = 1  | Y =  2 ) =  0.2562232712749868\n",
      "P(L_ 2 = 1 , L_ 4 = 2  | Y =  2 ) =  0.22062858752384928\n",
      "P(L_ 2 = 2 , L_ 4 = 0  | Y =  2 ) =  0.04330144938388625\n",
      "P(L_ 2 = 2 , L_ 4 = 1  | Y =  2 ) =  0.20499400380501206\n",
      "P(L_ 2 = 2 , L_ 4 = 2  | Y =  2 ) =  0.1781072266172587\n",
      "Labelers =  (2, 5)\n",
      "P(L_ 2 = 0 , L_ 5 = 0  | Y =  2 ) =  0.004562079890449811\n",
      "P(L_ 2 = 0 , L_ 5 = 1  | Y =  2 ) =  0.024374482782552536\n",
      "P(L_ 2 = 0 , L_ 5 = 2  | Y =  2 ) =  0.013961070181836928\n",
      "P(L_ 2 = 1 , L_ 5 = 0  | Y =  2 ) =  0.05642206530001695\n",
      "P(L_ 2 = 1 , L_ 5 = 1  | Y =  2 ) =  0.30152252813836183\n",
      "P(L_ 2 = 1 , L_ 5 = 2  | Y =  2 ) =  0.17275509390062488\n",
      "P(L_ 2 = 2 , L_ 5 = 0  | Y =  2 ) =  0.04535242052497453\n",
      "P(L_ 2 = 2 , L_ 5 = 1  | Y =  2 ) =  0.24229654313702162\n",
      "P(L_ 2 = 2 , L_ 5 = 2  | Y =  2 ) =  0.1387537161441609\n",
      "Labelers =  (2, 6)\n",
      "P(L_ 2 = 0 , L_ 6 = 0  | Y =  2 ) =  0.00921720416697747\n",
      "P(L_ 2 = 0 , L_ 6 = 1  | Y =  2 ) =  0.018460695660430976\n",
      "P(L_ 2 = 0 , L_ 6 = 2  | Y =  2 ) =  0.015219733027430828\n",
      "P(L_ 2 = 1 , L_ 6 = 0  | Y =  2 ) =  0.05837670493794776\n",
      "P(L_ 2 = 1 , L_ 6 = 1  | Y =  2 ) =  0.25876610331127364\n",
      "P(L_ 2 = 1 , L_ 6 = 2  | Y =  2 ) =  0.21355687908978227\n",
      "P(L_ 2 = 2 , L_ 6 = 0  | Y =  2 ) =  0.05212450974952784\n",
      "P(L_ 2 = 2 , L_ 6 = 1  | Y =  2 ) =  0.19421736493803404\n",
      "P(L_ 2 = 2 , L_ 6 = 2  | Y =  2 ) =  0.18006080511859507\n",
      "Labelers =  (2, 7)\n",
      "P(L_ 2 = 0 , L_ 7 = 0  | Y =  2 ) =  0.008647224056947702\n",
      "P(L_ 2 = 0 , L_ 7 = 1  | Y =  2 ) =  0.019322585145832745\n",
      "P(L_ 2 = 0 , L_ 7 = 2  | Y =  2 ) =  0.014927823652058832\n",
      "P(L_ 2 = 1 , L_ 7 = 0  | Y =  2 ) =  0.10697581164647699\n",
      "P(L_ 2 = 1 , L_ 7 = 1  | Y =  2 ) =  0.23904501831822395\n",
      "P(L_ 2 = 1 , L_ 7 = 2  | Y =  2 ) =  0.18467885737430267\n",
      "P(L_ 2 = 2 , L_ 7 = 0  | Y =  2 ) =  0.08595393644547034\n",
      "P(L_ 2 = 2 , L_ 7 = 1  | Y =  2 ) =  0.1920673260816199\n",
      "P(L_ 2 = 2 , L_ 7 = 2  | Y =  2 ) =  0.1483814172790668\n",
      "Labelers =  (2, 8)\n",
      "P(L_ 2 = 0 , L_ 8 = 0  | Y =  2 ) =  0.009799400597578323\n",
      "P(L_ 2 = 0 , L_ 8 = 1  | Y =  2 ) =  0.015390049065499673\n",
      "P(L_ 2 = 0 , L_ 8 = 2  | Y =  2 ) =  0.017708183191761283\n",
      "P(L_ 2 = 1 , L_ 8 = 0  | Y =  2 ) =  0.12123079572631176\n",
      "P(L_ 2 = 1 , L_ 8 = 1  | Y =  2 ) =  0.1904104479506748\n",
      "P(L_ 2 = 1 , L_ 8 = 2  | Y =  2 ) =  0.2190584436620172\n",
      "P(L_ 2 = 2 , L_ 8 = 0  | Y =  2 ) =  0.09739979945256817\n",
      "P(L_ 2 = 2 , L_ 8 = 1  | Y =  2 ) =  0.15296846395800937\n",
      "P(L_ 2 = 2 , L_ 8 = 2  | Y =  2 ) =  0.17603441639557954\n",
      "Labelers =  (2, 9)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(L_ 2 = 0 , L_ 9 = 0  | Y =  2 ) =  0.007976775596397381\n",
      "P(L_ 2 = 0 , L_ 9 = 1  | Y =  2 ) =  0.020004111207796934\n",
      "P(L_ 2 = 0 , L_ 9 = 2  | Y =  2 ) =  0.014916746050644955\n",
      "P(L_ 2 = 1 , L_ 9 = 0  | Y =  2 ) =  0.06448874685950404\n",
      "P(L_ 2 = 1 , L_ 9 = 1  | Y =  2 ) =  0.25533495791957816\n",
      "P(L_ 2 = 1 , L_ 9 = 2  | Y =  2 ) =  0.2108759825599215\n",
      "P(L_ 2 = 2 , L_ 9 = 0  | Y =  2 ) =  0.044736610553688265\n",
      "P(L_ 2 = 2 , L_ 9 = 1  | Y =  2 ) =  0.1607807744139801\n",
      "P(L_ 2 = 2 , L_ 9 = 2  | Y =  2 ) =  0.22088529483848854\n",
      "Labelers =  (3, 4)\n",
      "P(L_ 3 = 0 , L_ 4 = 0  | Y =  2 ) =  0.012331671764968088\n",
      "P(L_ 3 = 0 , L_ 4 = 1  | Y =  2 ) =  0.05687902588900653\n",
      "P(L_ 3 = 0 , L_ 4 = 2  | Y =  2 ) =  0.049812802101756974\n",
      "P(L_ 3 = 1 , L_ 4 = 0  | Y =  2 ) =  0.03174143983479201\n",
      "P(L_ 3 = 1 , L_ 4 = 1  | Y =  2 ) =  0.15522905824672217\n",
      "P(L_ 3 = 1 , L_ 4 = 2  | Y =  2 ) =  0.12550460707184002\n",
      "P(L_ 3 = 2 , L_ 4 = 0  | Y =  2 ) =  0.05743564896258119\n",
      "P(L_ 3 = 2 , L_ 4 = 1  | Y =  2 ) =  0.2697679417320759\n",
      "P(L_ 3 = 2 , L_ 4 = 2  | Y =  2 ) =  0.24129780439625703\n",
      "Labelers =  (3, 5)\n",
      "P(L_ 3 = 0 , L_ 5 = 0  | Y =  2 ) =  0.012678190854910015\n",
      "P(L_ 3 = 0 , L_ 5 = 1  | Y =  2 ) =  0.0676388852680736\n",
      "P(L_ 3 = 0 , L_ 5 = 2  | Y =  2 ) =  0.038706423632747976\n",
      "P(L_ 3 = 1 , L_ 5 = 0  | Y =  2 ) =  0.03313792155948245\n",
      "P(L_ 3 = 1 , L_ 5 = 1  | Y =  2 ) =  0.1773727928544572\n",
      "P(L_ 3 = 1 , L_ 5 = 2  | Y =  2 ) =  0.10196439073941464\n",
      "P(L_ 3 = 2 , L_ 5 = 0  | Y =  2 ) =  0.060520453301048854\n",
      "P(L_ 3 = 2 , L_ 5 = 1  | Y =  2 ) =  0.3231818759354052\n",
      "P(L_ 3 = 2 , L_ 5 = 2  | Y =  2 ) =  0.18479906585446013\n",
      "Labelers =  (3, 6)\n",
      "P(L_ 3 = 0 , L_ 6 = 0  | Y =  2 ) =  0.014250862183865912\n",
      "P(L_ 3 = 0 , L_ 6 = 1  | Y =  2 ) =  0.05611036844543732\n",
      "P(L_ 3 = 0 , L_ 6 = 2  | Y =  2 ) =  0.048662269126428355\n",
      "P(L_ 3 = 1 , L_ 6 = 0  | Y =  2 ) =  0.03740357723900845\n",
      "P(L_ 3 = 1 , L_ 6 = 1  | Y =  2 ) =  0.14732649611651716\n",
      "P(L_ 3 = 1 , L_ 6 = 2  | Y =  2 ) =  0.12774503179782865\n",
      "P(L_ 3 = 2 , L_ 6 = 0  | Y =  2 ) =  0.06806397943157874\n",
      "P(L_ 3 = 2 , L_ 6 = 1  | Y =  2 ) =  0.26800729934778417\n",
      "P(L_ 3 = 2 , L_ 6 = 2  | Y =  2 ) =  0.23243011631155122\n",
      "Labelers =  (3, 7)\n",
      "P(L_ 3 = 0 , L_ 7 = 0  | Y =  2 ) =  0.023994568199655862\n",
      "P(L_ 3 = 0 , L_ 7 = 1  | Y =  2 ) =  0.05361174324735974\n",
      "P(L_ 3 = 0 , L_ 7 = 2  | Y =  2 ) =  0.04141718830871598\n",
      "P(L_ 3 = 1 , L_ 7 = 0  | Y =  2 ) =  0.06297932755254236\n",
      "P(L_ 3 = 1 , L_ 7 = 1  | Y =  2 ) =  0.14074218049894655\n",
      "P(L_ 3 = 1 , L_ 7 = 2  | Y =  2 ) =  0.10875359710186533\n",
      "P(L_ 3 = 2 , L_ 7 = 0  | Y =  2 ) =  0.11460307639669683\n",
      "P(L_ 3 = 2 , L_ 7 = 1  | Y =  2 ) =  0.2560810057993703\n",
      "P(L_ 3 = 2 , L_ 7 = 2  | Y =  2 ) =  0.19781731289484705\n",
      "Labelers =  (3, 8)\n",
      "P(L_ 3 = 0 , L_ 8 = 0  | Y =  2 ) =  0.0347797639236128\n",
      "P(L_ 3 = 0 , L_ 8 = 1  | Y =  2 ) =  0.042801670935747466\n",
      "P(L_ 3 = 0 , L_ 8 = 2  | Y =  2 ) =  0.04144206489637132\n",
      "P(L_ 3 = 1 , L_ 8 = 0  | Y =  2 ) =  0.07375221500740188\n",
      "P(L_ 3 = 1 , L_ 8 = 1  | Y =  2 ) =  0.11922505438802901\n",
      "P(L_ 3 = 1 , L_ 8 = 2  | Y =  2 ) =  0.11949783575792339\n",
      "P(L_ 3 = 2 , L_ 8 = 0  | Y =  2 ) =  0.11989801684544357\n",
      "P(L_ 3 = 2 , L_ 8 = 1  | Y =  2 ) =  0.1967422356504073\n",
      "P(L_ 3 = 2 , L_ 8 = 2  | Y =  2 ) =  0.25186114259506326\n",
      "Labelers =  (3, 9)\n",
      "P(L_ 3 = 0 , L_ 9 = 0  | Y =  2 ) =  0.013949137172298075\n",
      "P(L_ 3 = 0 , L_ 9 = 1  | Y =  2 ) =  0.05190138561843889\n",
      "P(L_ 3 = 0 , L_ 9 = 2  | Y =  2 ) =  0.05317297696499461\n",
      "P(L_ 3 = 1 , L_ 9 = 0  | Y =  2 ) =  0.036627897198075916\n",
      "P(L_ 3 = 1 , L_ 9 = 1  | Y =  2 ) =  0.13631340629654215\n",
      "P(L_ 3 = 1 , L_ 9 = 2  | Y =  2 ) =  0.13953380165873616\n",
      "P(L_ 3 = 2 , L_ 9 = 0  | Y =  2 ) =  0.06662509863921569\n",
      "P(L_ 3 = 2 , L_ 9 = 1  | Y =  2 ) =  0.24790505162637413\n",
      "P(L_ 3 = 2 , L_ 9 = 2  | Y =  2 ) =  0.25397124482532424\n",
      "Labelers =  (4, 5)\n",
      "P(L_ 4 = 0 , L_ 5 = 0  | Y =  2 ) =  0.016265719556818915\n",
      "P(L_ 4 = 0 , L_ 5 = 1  | Y =  2 ) =  0.056877229430246784\n",
      "P(L_ 4 = 0 , L_ 5 = 2  | Y =  2 ) =  0.028365811575275585\n",
      "P(L_ 4 = 1 , L_ 5 = 0  | Y =  2 ) =  0.04395173135586869\n",
      "P(L_ 4 = 1 , L_ 5 = 1  | Y =  2 ) =  0.26592796305714905\n",
      "P(L_ 4 = 1 , L_ 5 = 2  | Y =  2 ) =  0.1719963314547869\n",
      "P(L_ 4 = 2 , L_ 5 = 0  | Y =  2 ) =  0.0461191148027537\n",
      "P(L_ 4 = 2 , L_ 5 = 1  | Y =  2 ) =  0.24538836157054014\n",
      "P(L_ 4 = 2 , L_ 5 = 2  | Y =  2 ) =  0.1251077371965602\n",
      "Labelers =  (4, 6)\n",
      "P(L_ 4 = 0 , L_ 6 = 0  | Y =  2 ) =  0.012153210774697698\n",
      "P(L_ 4 = 0 , L_ 6 = 1  | Y =  2 ) =  0.04785485366341996\n",
      "P(L_ 4 = 0 , L_ 6 = 2  | Y =  2 ) =  0.041500696124223614\n",
      "P(L_ 4 = 1 , L_ 6 = 0  | Y =  2 ) =  0.057682248512920815\n",
      "P(L_ 4 = 1 , L_ 6 = 1  | Y =  2 ) =  0.22719375145107698\n",
      "P(L_ 4 = 1 , L_ 6 = 2  | Y =  2 ) =  0.19700002590380689\n",
      "P(L_ 4 = 2 , L_ 6 = 0  | Y =  2 ) =  0.04988295956683458\n",
      "P(L_ 4 = 2 , L_ 6 = 1  | Y =  2 ) =  0.19639555879524173\n",
      "P(L_ 4 = 2 , L_ 6 = 2  | Y =  2 ) =  0.17033669520777775\n",
      "Labelers =  (4, 7)\n",
      "P(L_ 4 = 0 , L_ 7 = 0  | Y =  2 ) =  0.021025042311932796\n",
      "P(L_ 4 = 0 , L_ 7 = 1  | Y =  2 ) =  0.04530621831923316\n",
      "P(L_ 4 = 0 , L_ 7 = 2  | Y =  2 ) =  0.03517749993117532\n",
      "P(L_ 4 = 1 , L_ 7 = 0  | Y =  2 ) =  0.09642145341541028\n",
      "P(L_ 4 = 1 , L_ 7 = 1  | Y =  2 ) =  0.21692217876889014\n",
      "P(L_ 4 = 1 , L_ 7 = 2  | Y =  2 ) =  0.16853239368350426\n",
      "P(L_ 4 = 2 , L_ 7 = 0  | Y =  2 ) =  0.08413047642155198\n",
      "P(L_ 4 = 2 , L_ 7 = 1  | Y =  2 ) =  0.18820653245755328\n",
      "P(L_ 4 = 2 , L_ 7 = 2  | Y =  2 ) =  0.14427820469074878\n",
      "Labelers =  (4, 8)\n",
      "P(L_ 4 = 0 , L_ 8 = 0  | Y =  2 ) =  0.023208516518493844\n",
      "P(L_ 4 = 0 , L_ 8 = 1  | Y =  2 ) =  0.03642237042848701\n",
      "P(L_ 4 = 0 , L_ 8 = 2  | Y =  2 ) =  0.041877873615360425\n",
      "P(L_ 4 = 1 , L_ 8 = 0  | Y =  2 ) =  0.1101532203683496\n",
      "P(L_ 4 = 1 , L_ 8 = 1  | Y =  2 ) =  0.173040871501412\n",
      "P(L_ 4 = 1 , L_ 8 = 2  | Y =  2 ) =  0.19868193399804313\n",
      "P(L_ 4 = 2 , L_ 8 = 0  | Y =  2 ) =  0.0950682588896148\n",
      "P(L_ 4 = 2 , L_ 8 = 1  | Y =  2 ) =  0.14930571904428477\n",
      "P(L_ 4 = 2 , L_ 8 = 2  | Y =  2 ) =  0.17224123563595448\n",
      "Labelers =  (4, 9)\n",
      "P(L_ 4 = 0 , L_ 9 = 0  | Y =  2 ) =  0.011897069056238729\n",
      "P(L_ 4 = 0 , L_ 9 = 1  | Y =  2 ) =  0.04426805405850318\n",
      "P(L_ 4 = 0 , L_ 9 = 2  | Y =  2 ) =  0.04534363744759936\n",
      "P(L_ 4 = 1 , L_ 9 = 0  | Y =  2 ) =  0.0564840420569486\n",
      "P(L_ 4 = 1 , L_ 9 = 1  | Y =  2 ) =  0.2102057542915558\n",
      "P(L_ 4 = 1 , L_ 9 = 2  | Y =  2 ) =  0.21518622951930028\n",
      "P(L_ 4 = 2 , L_ 9 = 0  | Y =  2 ) =  0.048821021896402354\n",
      "P(L_ 4 = 2 , L_ 9 = 1  | Y =  2 ) =  0.1816460351912962\n",
      "P(L_ 4 = 2 , L_ 9 = 2  | Y =  2 ) =  0.18614815648215532\n",
      "Labelers =  (5, 6)\n",
      "P(L_ 5 = 0 , L_ 6 = 0  | Y =  2 ) =  0.012730622376984064\n",
      "P(L_ 5 = 0 , L_ 6 = 1  | Y =  2 ) =  0.0501313967489391\n",
      "P(L_ 5 = 0 , L_ 6 = 2  | Y =  2 ) =  0.04347454658951815\n",
      "P(L_ 5 = 1 , L_ 6 = 0  | Y =  2 ) =  0.06802347957281456\n",
      "P(L_ 5 = 1 , L_ 6 = 1  | Y =  2 ) =  0.26787096121912024\n",
      "P(L_ 5 = 1 , L_ 6 = 2  | Y =  2 ) =  0.2322991132660012\n",
      "P(L_ 5 = 2 , L_ 6 = 0  | Y =  2 ) =  0.03896431690465448\n",
      "P(L_ 5 = 2 , L_ 6 = 1  | Y =  2 ) =  0.15344180594167933\n",
      "P(L_ 5 = 2 , L_ 6 = 2  | Y =  2 ) =  0.1330637573802889\n",
      "Labelers =  (5, 7)\n",
      "P(L_ 5 = 0 , L_ 7 = 0  | Y =  2 ) =  0.031407586584624204\n",
      "P(L_ 5 = 0 , L_ 7 = 1  | Y =  2 ) =  0.037079981036438336\n",
      "P(L_ 5 = 0 , L_ 7 = 2  | Y =  2 ) =  0.03784899809437875\n",
      "P(L_ 5 = 1 , L_ 7 = 0  | Y =  2 ) =  0.107345235020517\n",
      "P(L_ 5 = 1 , L_ 7 = 1  | Y =  2 ) =  0.2787209783462516\n",
      "P(L_ 5 = 1 , L_ 7 = 2  | Y =  2 ) =  0.1821273406911674\n",
      "P(L_ 5 = 2 , L_ 7 = 0  | Y =  2 ) =  0.06282415054375386\n",
      "P(L_ 5 = 2 , L_ 7 = 1  | Y =  2 ) =  0.13463397016298664\n",
      "P(L_ 5 = 2 , L_ 7 = 2  | Y =  2 ) =  0.1280117595198822\n",
      "Labelers =  (5, 8)\n",
      "P(L_ 5 = 0 , L_ 8 = 0  | Y =  2 ) =  0.024289969489307017\n",
      "P(L_ 5 = 0 , L_ 8 = 1  | Y =  2 ) =  0.03814737291431012\n",
      "P(L_ 5 = 0 , L_ 8 = 2  | Y =  2 ) =  0.04389922331182418\n",
      "P(L_ 5 = 1 , L_ 8 = 0  | Y =  2 ) =  0.12978894466156718\n",
      "P(L_ 5 = 1 , L_ 8 = 1  | Y =  2 ) =  0.20384419586150715\n",
      "P(L_ 5 = 1 , L_ 8 = 2  | Y =  2 ) =  0.2345604135348617\n",
      "P(L_ 5 = 2 , L_ 8 = 0  | Y =  2 ) =  0.07435108162558406\n",
      "P(L_ 5 = 2 , L_ 8 = 1  | Y =  2 ) =  0.11677739219836654\n",
      "P(L_ 5 = 2 , L_ 8 = 2  | Y =  2 ) =  0.13434140640267217\n",
      "Labelers =  (5, 9)\n",
      "P(L_ 5 = 0 , L_ 9 = 0  | Y =  2 ) =  0.012462734361267672\n",
      "P(L_ 5 = 0 , L_ 9 = 1  | Y =  2 ) =  0.04637441514232612\n",
      "P(L_ 5 = 0 , L_ 9 = 2  | Y =  2 ) =  0.047499416211847514\n",
      "P(L_ 5 = 1 , L_ 9 = 0  | Y =  2 ) =  0.06659323039403005\n",
      "P(L_ 5 = 1 , L_ 9 = 1  | Y =  2 ) =  0.24779867989967083\n",
      "P(L_ 5 = 1 , L_ 9 = 2  | Y =  2 ) =  0.25380164376423503\n",
      "P(L_ 5 = 2 , L_ 9 = 0  | Y =  2 ) =  0.03814616825429198\n",
      "P(L_ 5 = 2 , L_ 9 = 1  | Y =  2 ) =  0.1419467484993583\n",
      "P(L_ 5 = 2 , L_ 9 = 2  | Y =  2 ) =  0.1453769634729724\n",
      "Labelers =  (6, 7)\n",
      "P(L_ 6 = 0 , L_ 7 = 0  | Y =  2 ) =  0.024132493474432335\n",
      "P(L_ 6 = 0 , L_ 7 = 1  | Y =  2 ) =  0.05392536496097222\n",
      "P(L_ 6 = 0 , L_ 7 = 2  | Y =  2 ) =  0.04166056041904851\n",
      "P(L_ 6 = 1 , L_ 7 = 0  | Y =  2 ) =  0.09503225296306919\n",
      "P(L_ 6 = 1 , L_ 7 = 1  | Y =  2 ) =  0.2123548978029024\n",
      "P(L_ 6 = 1 , L_ 7 = 2  | Y =  2 ) =  0.164057013143767\n",
      "P(L_ 6 = 2 , L_ 7 = 0  | Y =  2 ) =  0.0824122257113935\n",
      "P(L_ 6 = 2 , L_ 7 = 1  | Y =  2 ) =  0.18415466678180192\n",
      "P(L_ 6 = 2 , L_ 7 = 2  | Y =  2 ) =  0.14227052474261276\n",
      "Labelers =  (6, 8)\n",
      "P(L_ 6 = 0 , L_ 8 = 0  | Y =  2 ) =  0.027347267625071378\n",
      "P(L_ 6 = 0 , L_ 8 = 1  | Y =  2 ) =  0.04295108051707587\n",
      "P(L_ 6 = 0 , L_ 8 = 2  | Y =  2 ) =  0.049420070712305836\n",
      "P(L_ 6 = 1 , L_ 8 = 0  | Y =  2 ) =  0.10769207951084067\n",
      "P(L_ 6 = 1 , L_ 8 = 1  | Y =  2 ) =  0.16913992142713538\n",
      "P(L_ 6 = 1 , L_ 8 = 2  | Y =  2 ) =  0.19461216297176268\n",
      "P(L_ 6 = 2 , L_ 8 = 0  | Y =  2 ) =  0.09339064864054622\n",
      "P(L_ 6 = 2 , L_ 8 = 1  | Y =  2 ) =  0.14667795902997255\n",
      "P(L_ 6 = 2 , L_ 8 = 2  | Y =  2 ) =  0.16876880956528947\n",
      "Labelers =  (6, 9)\n",
      "P(L_ 6 = 0 , L_ 9 = 0  | Y =  2 ) =  0.014276374198403191\n",
      "P(L_ 6 = 0 , L_ 9 = 1  | Y =  2 ) =  0.05203914164442935\n",
      "P(L_ 6 = 0 , L_ 9 = 2  | Y =  2 ) =  0.05340290301162052\n",
      "P(L_ 6 = 1 , L_ 9 = 0  | Y =  2 ) =  0.055253666102935216\n",
      "P(L_ 6 = 1 , L_ 9 = 1  | Y =  2 ) =  0.20634070842217173\n",
      "P(L_ 6 = 1 , L_ 9 = 2  | Y =  2 ) =  0.20984978938463167\n",
      "P(L_ 6 = 2 , L_ 9 = 0  | Y =  2 ) =  0.04767209270825129\n",
      "P(L_ 6 = 2 , L_ 9 = 1  | Y =  2 ) =  0.17773999347475408\n",
      "P(L_ 6 = 2 , L_ 9 = 2  | Y =  2 ) =  0.18342533105280276\n",
      "Labelers =  (7, 8)\n",
      "P(L_ 7 = 0 , L_ 8 = 0  | Y =  2 ) =  0.04604619095659611\n",
      "P(L_ 7 = 0 , L_ 8 = 1  | Y =  2 ) =  0.07231929016496216\n",
      "P(L_ 7 = 0 , L_ 8 = 2  | Y =  2 ) =  0.0832114910273368\n",
      "P(L_ 7 = 1 , L_ 8 = 0  | Y =  2 ) =  0.10289261142334319\n",
      "P(L_ 7 = 1 , L_ 8 = 1  | Y =  2 ) =  0.161601796705473\n",
      "P(L_ 7 = 1 , L_ 8 = 2  | Y =  2 ) =  0.18594052141686043\n",
      "P(L_ 7 = 2 , L_ 8 = 0  | Y =  2 ) =  0.07949119339651896\n",
      "P(L_ 7 = 2 , L_ 8 = 1  | Y =  2 ) =  0.12484787410374862\n",
      "P(L_ 7 = 2 , L_ 8 = 2  | Y =  2 ) =  0.14364903080516087\n",
      "Labelers =  (7, 9)\n",
      "P(L_ 7 = 0 , L_ 9 = 0  | Y =  2 ) =  0.023625238075335293\n",
      "P(L_ 7 = 0 , L_ 9 = 1  | Y =  2 ) =  0.08791161532911669\n",
      "P(L_ 7 = 0 , L_ 9 = 2  | Y =  2 ) =  0.09004011874444305\n",
      "P(L_ 7 = 1 , L_ 9 = 0  | Y =  2 ) =  0.05279192302833175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(L_ 7 = 1 , L_ 9 = 1  | Y =  2 ) =  0.1964435418955999\n",
      "P(L_ 7 = 1 , L_ 9 = 2  | Y =  2 ) =  0.2011994646217449\n",
      "P(L_ 7 = 2 , L_ 9 = 0  | Y =  2 ) =  0.04078497190592266\n",
      "P(L_ 7 = 2 , L_ 9 = 1  | Y =  2 ) =  0.15176468631663867\n",
      "P(L_ 7 = 2 , L_ 9 = 2  | Y =  2 ) =  0.15543844008286703\n",
      "Labelers =  (8, 9)\n",
      "P(L_ 8 = 0 , L_ 9 = 0  | Y =  2 ) =  0.026772557548585315\n",
      "P(L_ 8 = 0 , L_ 9 = 1  | Y =  2 ) =  0.09962319961934055\n",
      "P(L_ 8 = 0 , L_ 9 = 2  | Y =  2 ) =  0.10203423860853238\n",
      "P(L_ 8 = 1 , L_ 9 = 0  | Y =  2 ) =  0.04204866106147624\n",
      "P(L_ 8 = 1 , L_ 9 = 1  | Y =  2 ) =  0.156467472756626\n",
      "P(L_ 8 = 1 , L_ 9 = 2  | Y =  2 ) =  0.1602528271560815\n",
      "P(L_ 8 = 2 , L_ 9 = 0  | Y =  2 ) =  0.04838091439952814\n",
      "P(L_ 8 = 2 , L_ 9 = 1  | Y =  2 ) =  0.1800291711653887\n",
      "P(L_ 8 = 2 , L_ 9 = 2  | Y =  2 ) =  0.1843909576844411\n",
      "[[0.44892041 0.         0.1979985  0.21982931 0.23184051 0.19017902\n",
      "  0.18622118 0.21511018 0.19335238 0.20566561 0.17832659 0.21534878\n",
      "  0.22735624 0.15450669 0.20172626 0.16408343 0.21904401 0.15430887\n",
      "  0.21990254 0.16239705]\n",
      " [0.         0.50799138 0.21784672 0.251299   0.25973707 0.21976043\n",
      "  0.17928222 0.27548076 0.21908685 0.24149607 0.22216684 0.22309286\n",
      "  0.25370167 0.18114441 0.22784079 0.18436124 0.23503678 0.18238769\n",
      "  0.24336737 0.19228684]\n",
      " [0.1979985  0.21784672 0.43540153 0.         0.26050524 0.15062981\n",
      "  0.15495552 0.23144886 0.19619873 0.19385774 0.20690291 0.17760229\n",
      "  0.21541276 0.1616115  0.19570119 0.15588362 0.18745606 0.16322136\n",
      "  0.20551464 0.17090526]\n",
      " [0.21982931 0.251299   0.         0.48888167 0.2182242  0.24367396\n",
      "  0.19795223 0.24006919 0.20139753 0.23605548 0.17738624 0.24792807\n",
      "  0.25012696 0.16148309 0.21913068 0.1810149  0.25312182 0.16080962\n",
      "  0.24308221 0.17013913]\n",
      " [0.23184051 0.25973707 0.26050524 0.2182242  0.51368786 0.\n",
      "  0.19449837 0.26333964 0.22246368 0.23741316 0.21741743 0.23309633\n",
      "  0.27526077 0.17485439 0.23058991 0.1868226  0.24188333 0.18164757\n",
      "  0.26343245 0.17569369]\n",
      " [0.19017902 0.21976043 0.15062981 0.24367396 0.         0.42828814\n",
      "  0.16281213 0.21904468 0.18457486 0.19886245 0.17928874 0.19608302\n",
      "  0.20195262 0.15644138 0.19223117 0.15598237 0.20322145 0.15063889\n",
      "  0.19190522 0.17718   ]\n",
      " [0.18622118 0.17928222 0.15495552 0.19795223 0.19449837 0.16281213\n",
      "  0.38021984 0.         0.16341704 0.17686056 0.1508106  0.18152911\n",
      "  0.19288982 0.13013135 0.17056535 0.13937895 0.19099752 0.13014773\n",
      "  0.18675858 0.13668412]\n",
      " [0.21511018 0.27548076 0.23144886 0.24006919 0.26333964 0.21904468\n",
      "  0.         0.51132593 0.22118591 0.23688122 0.22154604 0.22743527\n",
      "  0.25550846 0.18221756 0.22958516 0.18541258 0.2379186  0.18464759\n",
      "  0.24516276 0.19329098]\n",
      " [0.19335238 0.21908685 0.19619873 0.20139753 0.22246368 0.18457486\n",
      "  0.16341704 0.22118591 0.43140346 0.         0.19624681 0.17986994\n",
      "  0.21551686 0.15384107 0.1907572  0.15915275 0.19972816 0.15428893\n",
      "  0.20678448 0.16318508]\n",
      " [0.20566561 0.24149607 0.19385774 0.23605548 0.23741316 0.19886245\n",
      "  0.17686056 0.23688122 0.         0.46379433 0.17608554 0.23789683\n",
      "  0.23435241 0.16046408 0.21227591 0.16605922 0.22435817 0.16093714\n",
      "  0.22634464 0.16902979]\n",
      " [0.17832659 0.22216684 0.20690291 0.17738624 0.21741743 0.17928874\n",
      "  0.1508106  0.22154604 0.19624681 0.17608554 0.41913287 0.\n",
      "  0.20676725 0.15432969 0.1867389  0.15727292 0.18427122 0.15512715\n",
      "  0.19686377 0.1649311 ]\n",
      " [0.21534878 0.22309286 0.17760229 0.24792807 0.23309633 0.19608302\n",
      "  0.18152911 0.22743527 0.17986994 0.23789683 0.         0.45739446\n",
      "  0.23335763 0.15409554 0.22011848 0.1582842  0.22961133 0.1542272\n",
      "  0.2266738  0.16123879]\n",
      " [0.22735624 0.25370167 0.21541276 0.25012696 0.27526077 0.20195262\n",
      "  0.19288982 0.25550846 0.21551686 0.23435241 0.20676725 0.23335763\n",
      "  0.50263478 0.         0.22556346 0.18345155 0.24130564 0.17530083\n",
      "  0.24531517 0.18374863]\n",
      " [0.15450669 0.18114441 0.1616115  0.16148309 0.17485439 0.15644138\n",
      "  0.13013135 0.18221756 0.15384107 0.16046408 0.15432969 0.15409554\n",
      "  0.         0.35092155 0.15758656 0.12699899 0.16075759 0.12646058\n",
      "  0.16709893 0.13432268]\n",
      " [0.20172626 0.22784079 0.19570119 0.21913068 0.23058991 0.19223117\n",
      "  0.17056535 0.22958516 0.1907572  0.21227591 0.1867389  0.22011848\n",
      "  0.22556346 0.15758656 0.44884473 0.         0.21263201 0.15804554\n",
      "  0.21716993 0.16656547]\n",
      " [0.16408343 0.18436124 0.15588362 0.1810149  0.1868226  0.15598237\n",
      "  0.13937895 0.18541258 0.15915275 0.16605922 0.15727292 0.1582842\n",
      "  0.18345155 0.12699899 0.         0.36413871 0.17419274 0.12732743\n",
      "  0.17688636 0.13402141]\n",
      " [0.21904401 0.23503678 0.18745606 0.25312182 0.24188333 0.20322145\n",
      "  0.19099752 0.2379186  0.19972816 0.22435817 0.18427122 0.22961133\n",
      "  0.24130564 0.16075759 0.21263201 0.17419274 0.47407528 0.\n",
      "  0.23407822 0.16848401]\n",
      " [0.15430887 0.18238769 0.16322136 0.16080962 0.18164757 0.15063889\n",
      "  0.13014773 0.18464759 0.15428893 0.16093714 0.15512715 0.1542272\n",
      "  0.17530083 0.12646058 0.15804554 0.12732743 0.         0.35193462\n",
      "  0.16788467 0.13439678]\n",
      " [0.21990254 0.24336737 0.20551464 0.24308221 0.26343245 0.19190522\n",
      "  0.18675858 0.24516276 0.20678448 0.22634464 0.19686377 0.2266738\n",
      "  0.24531517 0.16709893 0.21716993 0.17688636 0.23407822 0.16788467\n",
      "  0.48398431 0.        ]\n",
      " [0.16239705 0.19228684 0.17090526 0.17013913 0.17569369 0.17718\n",
      "  0.13668412 0.19329098 0.16318508 0.16902979 0.1649311  0.16123879\n",
      "  0.18374863 0.13432268 0.16656547 0.13402141 0.16848401 0.13439678\n",
      "  0.         0.37087279]]\n",
      "\n",
      "Condition number =  181.5865509497217 \n",
      "\n",
      "[[0.5004242  0.387563  ]\n",
      " [0.45909729 0.56623981]\n",
      " [0.27100543 0.63124965]\n",
      " [0.67402165 0.26832099]\n",
      " [0.49940803 0.53069969]\n",
      " [0.42987081 0.42640268]\n",
      " [0.43708518 0.31247511]\n",
      " [0.4633325  0.5685014 ]\n",
      " [0.38903648 0.48187603]\n",
      " [0.50339676 0.41661521]\n",
      " [0.29401042 0.56819355]\n",
      " [0.56813275 0.32546988]\n",
      " [0.52881637 0.47144416]\n",
      " [0.30230663 0.40883742]\n",
      " [0.44750991 0.45043493]\n",
      " [0.37769564 0.3479881 ]\n",
      " [0.57086411 0.35876896]\n",
      " [0.30084298 0.41280104]\n",
      " [0.52416203 0.43611984]\n",
      " [0.30724142 0.44667802]]\n",
      "[0.54365374 0.45634626]\n",
      "sig\n",
      " [[ 2.44230737e-01 -2.25047684e-01  1.26247858e-02 -1.09993643e-02\n",
      "   2.11171375e-03 -2.18537529e-03  1.20436188e-02 -1.14897184e-02\n",
      "   2.28608701e-03 -4.97103294e-03 -2.15351671e-03  3.22045817e-03\n",
      "   1.06796323e-04 -4.62780631e-05  3.12598405e-04 -2.17694670e-04\n",
      "   2.83221964e-04 -5.46919116e-04  1.66902696e-04 -1.91064659e-04]\n",
      " [-2.25047684e-01  2.47088134e-01 -1.29093177e-02  1.37354374e-02\n",
      "  -2.04371517e-03  2.28593570e-03 -1.05538663e-02  1.29360539e-02\n",
      "  -2.53020100e-03  8.19932853e-03  1.96277216e-03 -2.80925179e-03\n",
      "  -1.07424609e-04  4.75448680e-05 -2.46209633e-04  1.71580468e-04\n",
      "  -1.51578296e-04  6.31932146e-04 -1.52198001e-04  1.80230949e-04]\n",
      " [ 1.26247858e-02 -1.29093177e-02  2.13630371e-01 -1.76600514e-01\n",
      "   3.40480776e-02 -3.55375358e-02  5.44193445e-04 -5.82661144e-04\n",
      "   6.75148674e-05 -3.22955388e-04 -9.31802190e-05  1.39929608e-04\n",
      "   1.69242870e-03 -7.01419554e-04  1.20845737e-05 -7.83086306e-06\n",
      "  -1.13247823e-06 -1.77177305e-05  2.65586044e-03 -3.03540618e-03]\n",
      " [-1.09993643e-02  1.37354374e-02 -1.76600514e-01  2.09041785e-01\n",
      "  -2.97588104e-02  3.39426566e-02 -4.72535661e-04  6.76777292e-04\n",
      "  -1.63228054e-04  5.80198005e-04  7.69526767e-05 -1.08213621e-04\n",
      "  -1.37660368e-03  6.46513967e-04 -6.86939663e-06  4.02787399e-06\n",
      "   7.29332017e-06  2.40461289e-05 -2.39047701e-03  2.86079639e-03]\n",
      " [ 2.11171375e-03 -2.04371517e-03  3.40480776e-02 -2.97588104e-02\n",
      "   2.49569716e-01 -2.19979496e-01  1.51433211e-04 -1.38740468e-04\n",
      "   1.36218179e-04 -1.58649568e-04 -1.45967302e-05  2.22100774e-05\n",
      "   1.75087882e-02 -6.23677666e-03  1.11409975e-06 -4.11731977e-07\n",
      "   3.16570403e-06 -6.13337727e-06  1.54990789e-02 -1.59016516e-02]\n",
      " [-2.18537529e-03  2.28593570e-03 -3.55375358e-02  3.39426566e-02\n",
      "  -2.19979496e-01  2.44854426e-01 -1.38732020e-04  1.40337910e-04\n",
      "  -1.10241393e-04  1.50169497e-04  1.50140347e-05 -2.23957049e-05\n",
      "  -1.33692608e-02  6.23750034e-03 -1.18948625e-06  5.09774987e-07\n",
      "  -1.86070251e-06  5.79070950e-06 -1.54552712e-02  1.84595564e-02]\n",
      " [ 1.20436188e-02 -1.05538663e-02  5.44193445e-04 -4.72535661e-04\n",
      "   1.51433211e-04 -1.38732020e-04  2.31800386e-01 -1.91164961e-01\n",
      "   2.25902058e-03 -2.16610467e-03 -7.56473379e-05  1.16730096e-04\n",
      "   4.43884259e-06 -2.58563068e-06 -3.89961447e-06  7.77350839e-06\n",
      "   4.18775640e-03 -2.03605544e-04  1.63131388e-05 -1.83851469e-05]\n",
      " [-1.14897184e-02  1.29360539e-02 -5.82661144e-04  6.76777292e-04\n",
      "  -1.38740468e-04  1.40337910e-04 -1.91164961e-01  2.47127676e-01\n",
      "  -1.82421795e-03  1.99544677e-03  7.86066792e-05 -1.10860989e-04\n",
      "  -4.79179322e-06  2.68828397e-06  2.89046099e-06 -5.86675476e-06\n",
      "   1.04556615e-03  1.77310815e-03 -1.37881037e-05  1.59518473e-05]\n",
      " [ 2.28608701e-03 -2.53020100e-03  6.75148674e-05 -1.63228054e-04\n",
      "   1.36218179e-04 -1.10241393e-04  2.25902058e-03 -1.82421795e-03\n",
      "   2.43156145e-01 -1.98083641e-01  9.11619172e-03 -1.18623700e-02\n",
      "  -7.34884341e-08 -1.42750958e-06 -2.94334206e-03  2.74630087e-03\n",
      "   9.56250166e-05 -1.15612337e-04  1.98440341e-05 -2.23672350e-05]\n",
      " [-4.97103294e-03  8.19932853e-03 -3.22955388e-04  5.80198005e-04\n",
      "  -1.58649568e-04  1.50169497e-04 -2.16610467e-03  1.99544677e-03\n",
      "  -1.98083641e-01  2.46820742e-01 -1.24027386e-02  2.05353378e-02\n",
      "  -1.97093420e-06  2.26708138e-06  4.16724505e-03 -3.46585281e-03\n",
      "  -8.16710066e-05  1.22321237e-04 -2.00833738e-05  2.31638907e-05]\n",
      " [-2.15351671e-03  1.96277216e-03 -9.31802190e-05  7.69526767e-05\n",
      "  -1.45967302e-05  1.50140347e-05 -7.56473379e-05  7.86066792e-05\n",
      "   9.11619172e-03 -1.24027386e-02  2.24809668e-01 -1.75202324e-01\n",
      "  -8.54158521e-07  3.57652355e-07 -1.58564506e-03  6.67122608e-03\n",
      "  -1.90282952e-06  4.02787603e-06 -1.04583179e-06  1.18892306e-06]\n",
      " [ 3.22045817e-03 -2.80925179e-03  1.39929608e-04 -1.08213621e-04\n",
      "   2.22100774e-05 -2.23957049e-05  1.16730096e-04 -1.10860989e-04\n",
      "  -1.18623700e-02  2.05353378e-02 -1.75202324e-01  2.33575665e-01\n",
      "   1.27309009e-06 -5.28863827e-07  1.49954849e-02 -1.00593175e-02\n",
      "   3.09729597e-06 -5.49878049e-06  1.62698937e-06 -1.83350766e-06]\n",
      " [ 1.06796323e-04 -1.07424609e-04  1.69242870e-03 -1.37660368e-03\n",
      "   1.75087882e-02 -1.33692608e-02  4.43884259e-06 -4.79179322e-06\n",
      "  -7.34884341e-08 -1.97093420e-06 -8.54158521e-07  1.27309009e-06\n",
      "   2.49176438e-01 -1.74869048e-01  1.20014450e-07 -8.23503576e-08\n",
      "   1.58424594e-08 -1.69307815e-07  7.94659877e-04 -6.80231413e-04]\n",
      " [-4.62780631e-05  4.75448680e-05 -7.01419554e-04  6.46513967e-04\n",
      "  -6.23677666e-03  6.23750034e-03 -2.58563068e-06  2.68828397e-06\n",
      "  -1.42750958e-06  2.26708138e-06  3.57652355e-07 -5.28863827e-07\n",
      "  -1.74869048e-01  2.24960042e-01 -3.91673670e-08  2.36987488e-08\n",
      "  -3.90831623e-08  1.17350136e-07 -4.14668460e-04  4.90160736e-04]\n",
      " [ 3.12598405e-04 -2.46209633e-04  1.20845737e-05 -6.86939663e-06\n",
      "   1.11409975e-06 -1.18948625e-06 -3.89961447e-06  2.89046099e-06\n",
      "  -2.94334206e-03  4.16724505e-03 -1.58564506e-03  1.49954849e-02\n",
      "   1.20014450e-07 -3.91673670e-08  2.47381016e-01 -1.63420186e-01\n",
      "  -2.66392148e-07  2.91389275e-07  1.64433511e-08 -1.43394004e-08]\n",
      " [-2.17694670e-04  1.71580468e-04 -7.83086306e-06  4.02787399e-06\n",
      "  -4.11731977e-07  5.09774987e-07  7.77350839e-06 -5.86675476e-06\n",
      "   2.74630087e-03 -3.46585281e-03  6.67122608e-03 -1.00593175e-02\n",
      "  -8.23503576e-08  2.36987488e-08 -1.63420186e-01  2.31322758e-01\n",
      "   3.79021465e-07 -4.25138429e-07  3.81684031e-08 -4.62692586e-08]\n",
      " [ 2.83221964e-04 -1.51578296e-04 -1.13247823e-06  7.29332017e-06\n",
      "   3.16570403e-06 -1.86070251e-06  4.18775640e-03  1.04556615e-03\n",
      "   9.56250166e-05 -8.16710066e-05 -1.90282952e-06  3.09729597e-06\n",
      "   1.58424594e-08 -3.90831623e-08 -2.66392148e-07  3.79021465e-07\n",
      "   2.38167546e-01 -1.60952315e-01  4.75142785e-07 -5.12385837e-07]\n",
      " [-5.46919116e-04  6.31932146e-04 -1.77177305e-05  2.40461289e-05\n",
      "  -6.13337727e-06  5.79070950e-06 -2.03605544e-04  1.77310815e-03\n",
      "  -1.15612337e-04  1.22321237e-04  4.02787603e-06 -5.49878049e-06\n",
      "  -1.69307815e-07  1.17350136e-07  2.91389275e-07 -4.25138429e-07\n",
      "  -1.60952315e-01  2.24966878e-01 -6.86355639e-07  7.87359843e-07]\n",
      " [ 1.66902696e-04 -1.52198001e-04  2.65586044e-03 -2.39047701e-03\n",
      "   1.54990789e-02 -1.54552712e-02  1.63131388e-05 -1.37881037e-05\n",
      "   1.98440341e-05 -2.00833738e-05 -1.04583179e-06  1.62698937e-06\n",
      "   7.94659877e-04 -4.14668460e-04  1.64433511e-08  3.81684031e-08\n",
      "   4.75142785e-07 -6.86355639e-07  2.47820412e-01 -1.76450932e-01]\n",
      " [-1.91064659e-04  1.80230949e-04 -3.03540618e-03  2.86079639e-03\n",
      "  -1.59016516e-02  1.84595564e-02 -1.83851469e-05  1.59518473e-05\n",
      "  -2.23672350e-05  2.31638907e-05  1.18892306e-06 -1.83350766e-06\n",
      "  -6.80231413e-04  4.90160736e-04 -1.43394004e-08 -4.62692586e-08\n",
      "  -5.12385837e-07  7.87359843e-07 -1.76450932e-01  2.28502574e-01]]\n",
      "\n",
      "Condition number =  25.769492150103904 \n",
      "\n",
      "moment of truth!!!\n",
      "[[ 2.56287428e+01  2.33661129e+01 -8.46365174e-01 -9.01931653e-01\n",
      "  -3.02733861e-02 -1.43838264e-02 -8.09588262e-01 -6.55873208e-01\n",
      "  -5.98579698e-01 -7.37957104e-01 -1.04748444e-02 -4.54528877e-02\n",
      "   2.42643789e-03  1.73015882e-03 -6.65023548e-04  6.90481160e-04\n",
      "   4.55198023e-03  4.48620037e-03 -1.00576101e-04  2.02632420e-03]\n",
      " [ 2.33661129e+01  2.53854764e+01 -6.88302076e-01 -1.01897127e+00\n",
      "  -2.90969917e-02 -1.29921213e-02 -7.11057302e-01 -7.88884841e-01\n",
      "  -7.45974825e-01 -9.72398539e-01  6.68243012e-03  3.56189015e-02\n",
      "   2.55913134e-03  1.76842704e-03  6.36805780e-04 -7.48300302e-04\n",
      "  -3.03663698e-03 -1.09002874e-02 -1.28603928e-04  2.08189292e-03]\n",
      " [-8.46365174e-01 -6.88302076e-01  1.56315418e+01  1.31367398e+01\n",
      "  -8.23168055e-01 -2.93175877e-01  2.22129458e-03 -9.72822120e-04\n",
      "   4.46895038e-03 -1.38807749e-03 -2.29944110e-05  4.90829518e-04\n",
      "   1.31421891e-02  6.45893012e-03  1.74969203e-05 -2.59363252e-05\n",
      "   1.88404763e-05 -2.85925395e-04 -1.70896184e-03  8.12010195e-03]\n",
      " [-9.01931653e-01 -1.01897127e+00  1.31367398e+01  1.59532173e+01\n",
      "  -7.59693224e-01 -9.86042172e-01  2.95195019e-03  1.14643676e-03\n",
      "   3.55926655e-03 -1.64360225e-03  6.16017912e-05  4.99656911e-05\n",
      "   7.28336161e-04  1.98302948e-03 -3.06500381e-06  6.04149444e-06\n",
      "  -1.13329474e-04 -8.10501407e-05  5.54986678e-04  2.04324476e-03]\n",
      " [-3.02733861e-02 -2.90969917e-02 -8.23168055e-01 -7.59693224e-01\n",
      "   1.93974779e+01  1.73839540e+01 -1.58485151e-03  1.16481505e-05\n",
      "  -2.52273981e-03  9.34115679e-04 -9.37794834e-06 -1.81685185e-04\n",
      "  -8.57534040e-01 -6.11141715e-01 -5.12081434e-06  7.17163169e-06\n",
      "   2.52693798e-05  1.20370453e-04 -3.69776342e-01 -3.42688725e-01]\n",
      " [-1.43838264e-02 -1.29921213e-02 -2.93175877e-01 -9.86042172e-01\n",
      "   1.73839540e+01  1.98092255e+01 -6.43559640e-04  4.03167902e-05\n",
      "  -1.05912487e-03  3.82249052e-04 -2.46355566e-06 -8.25640854e-05\n",
      "  -4.58092310e-01 -4.20685829e-01 -2.46335423e-06  3.50317722e-06\n",
      "   8.24244828e-06  5.32398475e-05 -2.88317576e-01 -6.05178038e-01]\n",
      " [-8.09588262e-01 -7.11057302e-01  2.22129458e-03  2.95195019e-03\n",
      "  -1.58485151e-03 -6.43559640e-04  1.19818582e+01  9.27353572e+00\n",
      "  -3.15319332e-02  1.23726251e-02 -2.20740014e-04 -1.82922140e-03\n",
      "   1.56860180e-04  1.04442328e-04 -4.19829208e-05  5.50532644e-05\n",
      "  -5.67132263e-01 -4.67994691e-01 -9.46274827e-06  1.23733451e-04]\n",
      " [-6.55873208e-01 -7.88884841e-01 -9.72822120e-04  1.14643676e-03\n",
      "   1.16481505e-05  4.03167902e-05  9.27353572e+00  1.12361653e+01\n",
      "  -2.84645301e-03  1.30645583e-03 -4.80792406e-05 -4.50172117e-05\n",
      "   8.54686420e-06  3.74077980e-06  2.19897095e-06 -4.43548747e-06\n",
      "  -5.14738514e-01 -4.47816456e-01 -1.29519119e-06  4.83011168e-06]\n",
      " [-5.98579698e-01 -7.45974825e-01  4.46895038e-03  3.55926655e-03\n",
      "  -2.52273981e-03 -1.05912487e-03 -3.15319332e-02 -2.84645301e-03\n",
      "   1.19260761e+01  9.60754873e+00 -3.36407310e-01 -4.92535941e-01\n",
      "   2.40224586e-04  1.61851262e-04  2.96041307e-03 -7.27486619e-03\n",
      "   6.77367098e-04  2.01764231e-03 -1.37312407e-05  1.91357504e-04]\n",
      " [-7.37957104e-01 -9.72398539e-01 -1.38807749e-03 -1.64360225e-03\n",
      "   9.34115679e-04  3.82249052e-04  1.23726251e-02  1.30645583e-03\n",
      "   9.60754873e+00  1.18309213e+01 -3.99648106e-01 -8.51185485e-01\n",
      "  -9.16542908e-05 -6.11869734e-05 -2.07370337e-02  2.30849006e-02\n",
      "  -2.76540452e-04 -7.68461122e-04  5.46487829e-06 -7.24557363e-05]\n",
      " [-1.04748444e-02  6.68243012e-03 -2.29944110e-05  6.16017912e-05\n",
      "  -9.37794834e-06 -2.46355567e-06 -2.20740014e-04 -4.80792406e-05\n",
      "  -3.36407310e-01 -3.99648106e-01  1.07932100e+01  8.14088106e+00\n",
      "   1.29465494e-06  7.88346696e-07 -7.39968974e-01 -4.82022506e-01\n",
      "   6.33888641e-06  1.06745085e-05 -1.07555950e-07  9.49010939e-07]\n",
      " [-4.54528877e-02  3.56189015e-02  4.90829518e-04  4.99656911e-05\n",
      "  -1.81685185e-04 -8.25640854e-05 -1.82922140e-03 -4.50172117e-05\n",
      "  -4.92535941e-01 -8.51185485e-01  8.14088106e+00  1.04751501e+01\n",
      "   1.55871214e-05  1.08598855e-05 -8.11913528e-01 -3.59814476e-01\n",
      "   3.24819301e-05  1.31766170e-04 -7.47807359e-07  1.27673993e-05]\n",
      " [ 2.42643789e-03  2.55913134e-03  1.31421891e-02  7.28336161e-04\n",
      "  -8.57534040e-01 -4.58092310e-01  1.56860180e-04  8.54686420e-06\n",
      "   2.40224586e-04 -9.16542908e-05  1.29465494e-06  1.55871214e-05\n",
      "   8.89167396e+00  6.90078879e+00  4.02179971e-07 -5.48724616e-07\n",
      "  -3.05124904e-06 -1.07249446e-05  5.49691465e-04 -1.04126267e-02]\n",
      " [ 1.73015882e-03  1.76842704e-03  6.45893012e-03  1.98302948e-03\n",
      "  -6.11141715e-01 -4.20685829e-01  1.04442328e-04  3.74077981e-06\n",
      "   1.61851262e-04 -6.11869734e-05  7.88346695e-07  1.08598855e-05\n",
      "   6.90078879e+00  9.80420545e+00  2.88822284e-07 -3.97741482e-07\n",
      "  -1.92100195e-06 -7.37996438e-06 -3.89527311e-04 -9.27242669e-03]\n",
      " [-6.65023548e-04  6.36805780e-04  1.74969203e-05 -3.06500381e-06\n",
      "  -5.12081434e-06 -2.46335423e-06 -4.19829208e-05  2.19897095e-06\n",
      "   2.96041307e-03 -2.07370337e-02 -7.39968974e-01 -8.11913528e-01\n",
      "   4.02179968e-07  2.88822281e-07  7.64608869e+00  5.38733928e+00\n",
      "   5.62155114e-07  3.42029474e-06 -1.58508381e-08  3.37871262e-07]\n",
      " [ 6.90481160e-04 -7.48300302e-04 -2.59363252e-05  6.04149444e-06\n",
      "   7.17163169e-06  3.50317722e-06  5.50532644e-05 -4.43548747e-06\n",
      "  -7.27486619e-03  2.30849006e-02 -4.82022506e-01 -3.59814476e-01\n",
      "  -5.48724619e-07 -3.97741485e-07  5.38733928e+00  8.12758959e+00\n",
      "  -6.49135065e-07 -4.67530372e-06  2.01555157e-08 -4.64590625e-07]\n",
      " [ 4.55198023e-03 -3.03663698e-03  1.88404763e-05 -1.13329474e-04\n",
      "   2.52693798e-05  8.24244827e-06 -5.67132263e-01 -5.14738514e-01\n",
      "   6.77367098e-04 -2.76540452e-04  6.33888640e-06  3.24819301e-05\n",
      "  -3.05124904e-06 -1.92100195e-06  5.62155113e-07 -6.49135065e-07\n",
      "   8.15746057e+00  5.83981035e+00  2.28292291e-07 -2.29842115e-06]\n",
      " [ 4.48620037e-03 -1.09002874e-02 -2.85925395e-04 -8.10501407e-05\n",
      "   1.20370453e-04  5.32398475e-05 -4.67994691e-01 -4.47816456e-01\n",
      "   2.01764231e-03 -7.68461122e-04  1.06745085e-05  1.31766170e-04\n",
      "  -1.07249446e-05 -7.37996438e-06  3.42029473e-06 -4.67530372e-06\n",
      "   5.83981035e+00  8.62633388e+00  5.51455525e-07 -8.69426644e-06]\n",
      " [-1.00576101e-04 -1.28603928e-04 -1.70896184e-03  5.54986678e-04\n",
      "  -3.69776342e-01 -2.88317576e-01 -9.46274827e-06 -1.29519119e-06\n",
      "  -1.37312407e-05  5.46487830e-06 -1.07555949e-07 -7.47807358e-07\n",
      "   5.49691465e-04 -3.89527311e-04 -1.58508369e-08  2.01555167e-08\n",
      "   2.28292290e-07  5.51455525e-07  8.97103449e+00  6.92501322e+00]\n",
      " [ 2.02632420e-03  2.08189292e-03  8.12010195e-03  2.04324476e-03\n",
      "  -3.42688725e-01 -6.05178038e-01  1.23733451e-04  4.83011168e-06\n",
      "   1.91357504e-04 -7.24557363e-05  9.49010940e-07  1.27673993e-05\n",
      "  -1.04126267e-02 -9.27242669e-03  3.37871264e-07 -4.64590623e-07\n",
      "  -2.29842115e-06 -8.69426644e-06  6.92501322e+00  9.74896378e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic dataset\n",
    "np.random.seed(1)\n",
    "N = 10000\n",
    "M = 10\n",
    "K = 2\n",
    "EDGE_PROB=1.0\n",
    "data = SingleTaskTreeDepsGenerator(N, M, k=K, edge_prob=EDGE_PROB)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5004242 , 0.387563  ],\n",
       "       [0.45909729, 0.56623981],\n",
       "       [0.27100543, 0.63124965],\n",
       "       [0.67402165, 0.26832099],\n",
       "       [0.49940803, 0.53069969],\n",
       "       [0.42987081, 0.42640268],\n",
       "       [0.43708518, 0.31247511],\n",
       "       [0.4633325 , 0.5685014 ],\n",
       "       [0.38903648, 0.48187603],\n",
       "       [0.50339676, 0.41661521],\n",
       "       [0.29401042, 0.56819355],\n",
       "       [0.56813275, 0.32546988],\n",
       "       [0.52881637, 0.47144416],\n",
       "       [0.30230663, 0.40883742],\n",
       "       [0.44750991, 0.45043493],\n",
       "       [0.37769564, 0.3479881 ],\n",
       "       [0.57086411, 0.35876896],\n",
       "       [0.30084298, 0.41280104],\n",
       "       [0.52416203, 0.43611984],\n",
       "       [0.30724142, 0.44667802]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.mu_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 20)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.O_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1), (1, 2), (0, 3), (0, 4), (4, 5), (2, 6), (5, 7), (3, 8), (2, 9)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjgAAAI3CAYAAACWIyEjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3X2UbmddH/zvL4e8ECC8mCeISSBQUmpkQeA5KwpUDUUwSZXULmoTaUWbGnWJllX72Fifggv/KWUhqy0saApZQZcEBEVTiYQUfRa+JJhAA5JA5BixOQQTQiC8RBLOmd/zx9wHh8m8nZnZM7Pv/fmstdfc997X/O5rz33PnOt897X3ru4OAMA8OWa3OwAAsN0McACAuWOAAwDMHQMcAGDuGOAAAHPHAAcAmDsGOADA3DHAAQDmjgEOADB3HrbbHQAAdtb3P/8R/fl7D+/Ia334Yw9c293n7ciLLWGAAwAT8/l7D+fPrn3ijrzWvid86uQdeaFlHKICAOaOBAcAJqaTLGRht7sxKAkOADB3JDgAMDmdwy3BAQAYFQMcAJiYxTk4vSPLeqrqiqq6u6o+vsr2qqr/WlUHqupjVfXsjeyjAQ4AsJuuTLLWdXLOT3LmbLk0yZs2UtQcHACYoL1yFlV3f7CqzlijyYVJfq27O8kNVfWYqnpCd392rboSHABgSCdX1U1LlkuP8vtPTXLHkucHZ+vWJMEBgInpdA73+vNjtsk93b1/C99fK6xbt/MSHABgLzuY5PQlz09Lcud632SAAwATtFfOotqAq5P86Oxsqu9Kct96828Sh6gAgF1UVVclOTeLc3UOJnlVkmOTpLvfnOSaJBckOZDk/iQ/vpG6BjgAwK7p7ovX2d5JfuZo6xrgAMDEdJLD23P4aM8yBwcAmDsSHACYoG2aALxnSXAAgLkjwQGAielkJy/0tyskOADA3JHgAMAE7Y1bbQ5HggMAzB0JDgBMTKddBwcAYGwkOAAwNZ0cnu8AR4IDAMwfCQ4ATEzHWVQAAKMjwQGAyakcTu12JwYlwQEA5o4BDgAwdxyiAoCJ6SQLThMHABgXCQ4ATJBJxgAAIyPBAYCJ6UhwAABGR4IDABO00BIcAIBRkeAAwMSYgwMAMEISHACYmE7l8JxnHPO9dwDAJElwAGCCnEUFADAyEhwAmBhnUQEAjNCeTHCOq+P7hDxit7txVB79HYcGqXtCfX2QunffOtzPt3thkLqP+PYepO4XH3j4IHWTZGFhmP8hPfy4YT4XC7cN8zlOktq3b5C6ffjwIHVhJ30tX82D/cB8Ryo7bE8OcE7II/Kd9YLd7sZROf9dXxyk7pnH/80gdd/wjGcPUjdJ+sEHB6n77LcPU/e9f/0dg9RNkq985YRB6j7ziQcHqfvVc+8dpG6S7DvpkYPUPfzF+wapyzI1sn97e5j/EA3lQ/2BHX7FyuGe74M48713AMAk7ckEBwAYTidZmPOMY773DgCYJAkOAEyQ08QBAEZmSwOcqjqvqm6rqgNVddkK24+vqnfOtn+oqs7YyusBAFvXvXgW1U4su2XTr1xV+5K8Mcn5Sc5KcnFVnbWs2SVJvtDdT03y+iSv2ezrAQBs1FaGVuckOdDdt3f3g0nekeTCZW0uTPK22eN3J3lB1dgupgAA82chtSPLbtnKAOfUJHcseX5wtm7FNt19KMl9Sb5lC68JALCurZxFtdKwbPmlIzfSZrFh1aVJLk2SE3LiFroFAKxl8Wab832e0Vb27mCS05c8Py3Jnau1qaqHJXl0khWvBd/dl3f3/u7ef2yO30K3AICp20qCc2OSM6vqyUk+k+SiJD+yrM3VSV6W5PokL0nyB90ju0EIAMyd+b8X1aYHON19qKpenuTaJPuSXNHdt1TVq5Pc1N1XJ3lrkl+vqgNZTG4u2o5OAwCsZUtXMu7ua5Jcs2zdK5c8/lqSf7aV1wAAtpd7UQEAjJABDgAwd9xsEwAm6HDP93V3JTgAwNyR4ADAxHRq7i/0Z4CzTd51x7MHqfsnz/jtQeq+YZCqw7rx3icNUvd7TzswSN0k+ZuvnTRI3V994u8OUveS/u5B6iZJf/3QYLXZAUNdwuyYfcPU7cPD1GU0DHAAYIIW5vxCf/O9dwDAJElwAGBi3GwTAGCEJDgAMDGdch0cAICxkeAAwAS52SYAwMhIcABgYrqTw66DAwAwLhIcAJicykKcRQUAMCoGOADA3HGICgAmpmOSMQDA6EhwAGCC3GwTAGBkJDgAMDGdyoKbbQIAjIsEBwAmyBwcAICRkeAAwMR0koU5vw7OnhzgPPo7DuX8d31x2+u+645nb3vNIx553u2D1P3+nD1I3ed+dPt/vke87zXfM0jdk15wwyB1bxuk6kzdO0jZS/ofDlJ38c/eMBa++tVB6tbDhvkz1ocPD1J3sfhwP+fRWRjw5zyUY/Ztf80R/hj2uj05wAEAhlQ57GabAADjIsEBgImZwhyc+d47AGCSJDgAMEHm4AAAjIwEBwAmprvMwQEAGBsDHABg7jhEBQATdNghKgCAcZHgAMDEdJIFp4kDAIyLBAcAJqfMwQEAGBsJDgBMzOLNNs3BAQAYFQkOAEzQ4TnPODa9d1V1elX9YVV9oqpuqap/s0Kbc6vqvqq6eba8cmvdBQBY31YSnENJfr67P1JVj0ry4aq6rrtvXdbuj7r7B7bwOgDANuqUOTir6e7PdvdHZo+/nOQTSU7dro4BANNQVedV1W1VdaCqLlth+xNnR43+d1V9rKouWK/mtszBqaozkjwryYdW2PycqvpokjuT/LvuvmW9eifU13Pm8X+zHV37Jn/yjN/e9ppHfH/OHqz2ED711VMGq/0/X/O6Qeq+9O3PG6TuoLp3uwdzrw8d2u0uMDULh3e7B9tiYY/MwamqfUnemOSFSQ4mubGqrl52ROj/TfKb3f2mqjoryTVJzlir7pb3rqoemeS3kryiu7+0bPNHkjypu5+Z5L8l+Z016lxaVTdV1U333TsfHx4AYF3nJDnQ3bd394NJ3pHkwmVtOslJs8ePzmJosqYtDXCq6tgsDm5+o7sfEo9095e6+yuzx9ckObaqTl6pVndf3t37u3v/ox+3byvdAgDW0J0c7tqRJcnJRwKM2XLpsu6cmuSOJc8P5qFTXn45yb+oqoNZTG9+dr193PQhqqqqJG9N8onu/tVV2nxrkru6u6vqnCwOqD6/2dcEAEbnnu7ev8b2lWY7Lz++f3GSK7v7dVX1nCS/XlVP7+6F1YpuZQ7O85L8yyR/XlU3z9b9hyRPTJLufnOSlyT56ao6lORvk1zUbVICAPANB5OcvuT5aXnoIahLkpyXJN19fVWdkOTkJHevVnTTA5zu/uOsPOpa2uYNSd6w2dcAAIaxh04TvzHJmVX15CSfSXJRkh9Z1ub/JHlBkiur6tuTnJDkc2sV3RtTqAGASeruQ0lenuTaLF5y5je7+5aqenVVvXjW7OeT/MTsrOyrkvzYekeE3KoBACZm8UJ/eyfjmJ2IdM2yda9c8vjWLE6N2bC9s3cAANtEggMAE3R47Wm0oyfBAQDmjgQHACams6fOohqEBAcAmDsSHACYnL11FtUQ5nvvAIBJkuAAwAQtOIsKAGBcJDgAMDHdyWFnUQEAjIsEBwAmyFlUAAAjY4ADAMydPXmI6u5bH5E3POPZ2173Ddte8e8896NfHKTup756yiB1P/fcYfqbJC89ujvaw5b80K2fG6Tu625+4SB1k+QpP3LzYLVZdNfPPnew2vse7G2veei3btj2mmvplFs1AACMzZ5McACAYbnQHwDAyEhwAGBiOjEHBwBgbCQ4ADBBLvQHADAyEhwAmJp2HRwAgNGR4ADAxHRcBwcAYHQkOAAwQebgAACMjAQHACbGlYwBAEbIAAcAmDsOUQHABDlEBQAwMhIcAJiYjls1AACMjgQHACbIrRoAAEZmTyY43QvpBx/c7W4clfe95nsGqfs/X/O6Qeq+NM8bpC7stNf/1osHqXvc/fP9v9t59/B7Fgar/bkf/Nq21zx87XD9XVE7iwoAYHT2ZIIDAAzHrRoAAEZIggMAEyTBAQAYGQkOAEyMKxkDAIzQlhOcqvp0ki8nOZzkUHfvX7a9kvyXJBckuT/Jj3X3R7b6ugDA5vWcJzjbdYjq+d19zyrbzk9y5mz5ziRvmn0FABjEThyiujDJr/WiG5I8pqqesAOvCwBM1HYMcDrJ+6vqw1V16QrbT01yx5LnB2frAIBdspDakWW3bMchqud1951VdUqS66rqk939wSXbV9q7Xr5iNji6NElOyInb0C0AYKq2PMDp7jtnX++uqvckOSfJ0gHOwSSnL3l+WpI7V6hzeZLLk+SkYx73kAEQALA92s0211ZVj6iqRx15nORFST6+rNnVSX60Fn1Xkvu6+7NbeV0AgLVsNcF5fJL3LJ4JnocleXt3v6+qfipJuvvNSa7J4iniB7J4mviPb/E1AYAtcpr4Grr79iTPXGH9m5c87iQ/s5XXAQA4Gm7VAACT41YNAACjI8EBgAma9zk4EhwAYO5IcABgYjrzfx2cPTnAecS3d5799ge3ve6N9z5p22secdILbhik7kvf/rxB6rIzjjlxmKty94Pb//uRJH3o0CB1h3TGf7x+t7swCX/xlv2D1D3urmMHqXvGLw33uTjpqu2veU//7fYXnbg9OcABAAbUi1cznmfm4AAAc0eCAwATtJt3+t4JEhwAYO4Y4AAAc8chKgCYmI4L/QEAjI4EBwAmx802AQBGR4IDABPkQn8AACMjwQGACXIWFQDAyEhwAGBiuiU4AACjI8EBgAlyHRwAgJGR4ADABLkODgDAyEhwAGCCnEUFADAyezLB+eIDD897//o7tr3u9552YNtrHnHbYJUZs4X779/tLsC2OOYrw/xzcczX5ztFYPfsyQEOADCcTjlEBQAwNhIcAJigOT9LXIIDAMwfCQ4ATI2bbQIAjI8EBwCmaM4n4UhwAIC5I8EBgAkyBwcAYGQkOAAwQW0ODgDAuEhwAGBiOubgAACMjgQHAKamk0hwAACGU1XnVdVtVXWgqi5bpc0PV9WtVXVLVb19vZoSHABg11TVviRvTPLCJAeT3FhVV3f3rUvanJnkF5M8r7u/UFWnrFfXAAcAJmgPnSZ+TpID3X17klTVO5JcmOTWJW1+Iskbu/sLSdLdd69X1CEqAGA3nZrkjiXPD87WLfX3k/z9qvqTqrqhqs5br+imBzhV9bSqunnJ8qWqesWyNudW1X1L2rxys68HAGyj3qElObmqblqyXLqsJyvNdl6eLz0syZlJzk1ycZK3VNVj1tq9TR+i6u7bkpydfOP42WeSvGeFpn/U3T+w2dcBAEbtnu7ev8b2g0lOX/L8tCR3rtDmhu7+epK/qqrbsjjguXG1ott1iOoFSf6yu/96m+oBAIOpdO/MsgE3Jjmzqp5cVccluSjJ1cva/E6S5ydJVZ2cxUNWt69VdLsmGV+U5KpVtj2nqj6axdHYv+vuW1ZqNIusLk2SfSc/Ol/5ygnb1LW/8zdfO2nba35D3TtM3T00C2y3HXPiiYPUXbj//kHqjtHnf+I5g9W+78xh6j7lF64fpvAY1XDXNXnqK24YrDbT1t2HqurlSa5Nsi/JFd19S1W9OslN3X31bNuLqurWJIeT/D/d/fm16m55gDMbbb04i6dvLfeRJE/q7q9U1QVZHIGt+Geuuy9PcnmSHP+UU/2rDgBD2kP/0nb3NUmuWbbulUsed5J/O1s2ZDsOUZ2f5CPdfdfyDd39pe7+yuzxNUmOnUVLAACD2Y5DVBdnlcNTVfWtSe7q7q6qc7I4oFozUgIABtbzf7PNLQ1wqurELF558CeXrPupJOnuNyd5SZKfrqpDSf42yUWzmAkAYDBbGuB09/1JvmXZujcvefyGJG/YymsAAAOY87jBlYwBgLnjXlQAMEnzPQdHggMAzB0JDgBMkTk4AADjYoADAMwdh6gAYIocogIAGBcJDgBMTSeZ81s1SHAAgLkjwQGACZr3O0NKcACAuSPBAYApkuAAAIyLBAcApshZVAAA47InE5yHH/f1PPOJB7e97q8+8Xe3veYRl/Q/HKw2i/rBB3e7C3PvgccM9z+6n/vH7x2k7u/9wmMHqTukOv743e7CUesHHtjtLrDNyhwcAIBx2ZMJDgAwoI6zqAAAxkaCAwCTU86iAgAYGwMcAGDuOEQFAFNkkjEAwLhIcABgiiQ4AADjIsEBgCmS4AAAjIsEBwCmpuNCfwAAYyPBAYAJKnNwAADGRYIDAFMkwQEAGBcDHABg7hjgAABzxxwcAJigeT+Lak8OcBZuO5Svnnvvtte9pL9722v+nTn/pOwBfejQbnfhqH3+J54zSN0HHjPMBbq+7bV/OkjdJPm91z52sNpjc+J1Jw1S98//9KmD1E2Sp1x2/WC1YQh7coADAAzMlYwBAMbFAAcAmDsOUQHA1HTmfuqoBAcAmDsSHACYIgkOAMC4SHAAYILm/UJ/G0pwquqKqrq7qj6+ZN3jquq6qvrU7OuKV/GqqpfN2nyqql62XR0HAFjNRg9RXZnkvGXrLkvyge4+M8kHZs+/SVU9LsmrknxnknOSvGq1gRAAsIN6h5ZdsqEBTnd/MMnyeydcmORts8dvS/JPVvjW709yXXff291fSHJdHjpQAgDYVluZg/P47v5sknT3Z6vqlBXanJrkjiXPD87WPURVXZrk0iQ5ISduoVsAwLrMwdmSlW50seKPtLsv7+793b3/2Bw/cLcAgHm2lQHOXVX1hCSZfb17hTYHk5y+5PlpSe7cwmsCAFtUvXPLbtnKAOfqJEfOinpZkt9doc21SV5UVY+dTS5+0WwdAMBgNnqa+FVJrk/ytKo6WFWXJPlPSV5YVZ9K8sLZ81TV/qp6S5J0971JfiXJjbPl1bN1AMBu6tqZZZdsaJJxd1+8yqYXrND2piT/esnzK5JcsaneAQBsgisZA8AUOYsKAGBcDHAAgLnjEBUATJCbbQIAjMyeTHBq377sO+mR2163v35o22sesfDVrw5Wm/G678xh6v7cP37vIHV/77XuhbsT/sGj7hqk7l/dMdAHjvkkwQEAGJc9meAAAAPa5dso7AQJDgAwdyQ4ADBFEhwAgHGR4ADAFElwAADGRYIDABPkLCoAgJExwAEA5o4BDgAwd8zBAYApMgcHAGBcDHAAgLnjEBUATI2bbQIAjI8EBwCmSIIDADAuEhwAmCIJDgDAuEhwAGBiKvN/FtWeHOD04cM5/MX7drsbR6UeNsyPsg8dGqTuD936uUHqJsnrf+vFg9Q94z9eP0jdIT3lF4bp8+/9wmMHqcvO+PCzhgnPT8mfDlKXZY7Zt/01D29/yanbkwMcAGBgc57gmIMDAMwdCQ4ATI0rGQMAjI8EBwCmSIIDADAuEhwAmCIJDgDAuBjgAABzxyEqAJggp4kDAAyoqs6rqtuq6kBVXbZGu5dUVVfV/vVqGuAAwBT1Di3rqKp9Sd6Y5PwkZyW5uKrOWqHdo5L8XJIPbWT3DHAAgN10TpID3X17dz+Y5B1JLlyh3a8k+c9JvraRogY4ADA1O5XeLCY4J1fVTUuWS5f15tQkdyx5fnC27huq6llJTu/u39voLppkDAAM6Z7uXmvOTK2w7hsHt6rqmCSvT/JjR/OiBjgAMEF76Cyqg0lOX/L8tCR3Lnn+qCRPT/L/VVWSfGuSq6vqxd1902pFHaICAHbTjUnOrKonV9VxSS5KcvWRjd19X3ef3N1ndPcZSW5IsubgJjHAAYBp2iNnUXX3oSQvT3Jtkk8k+c3uvqWqXl1VL97s7q17iKqqrkjyA0nu7u6nz9a9NskPJnkwyV8m+fHu/uIK3/vpJF9OcjjJoXWOwQEAE9Td1yS5Ztm6V67S9tyN1NxIgnNlkvOWrbsuydO7+xlJ/iLJL67x/c/v7rMNbgBg76jemWW3rDvA6e4PJrl32br3zyKlZPFY2GkD9A0AYFO2Yw7Ov0ry+6ts6yTvr6oPr3DeOwCwW/bIHJyhbOk08ar6pSSHkvzGKk2e1913VtUpSa6rqk/OEqGVal2a5NIkOSEnbqVbu6IPH97tLhyV1938wsFqH3f/Spc0AICds+kEp6pelsXJxy/t7hXHaN195+zr3Unek8XLMa+ouy/v7v3dvf/YHL/ZbgEA69nZKxnvik0NcKrqvCT/Povnod+/SptHzG6Mlap6RJIXJfn4ZjsKALBR6w5wquqqJNcneVpVHayqS5K8IYtXFryuqm6uqjfP2n5bVR05zevxSf64qj6a5M+SvLe73zfIXgAALLHuHJzuvniF1W9dpe2dSS6YPb49yTO31DsAYNtVVr4B1DxxJWMAYO642SYATNHeudnmICQ4AMDckeAAwATt5m0UdoIEBwCYOxIcAJgiCQ4AwLhIcABgiiQ4AADjIsEBgKlpZ1EBAIyOBAcApkiCAwAwLhIcAJggc3AAAEbGAAcAmDsOUQHAFM35ISoDnO3S4/qkPOVHbt7tLrAFdfzxg9Q98bqTBqmbJP/gUXcNUvfDzxJEs8MWDu92D9gAAxwAmCCTjAEARkaCAwBT05n7OTgSHABg7khwAGCKJDgAAOMiwQGAiak4iwoAYHQkOAAwRRIcAIBxkeAAwATVyG4xdLQkOADA3JHgAMDUuJIxAMD4GOAAAHPHISoAmCAX+gMAGBkJDgBMkQQHAGBcJDgAMEHm4AAAjIwEB4ZUtds9OCp//qdPHaz2X91x5iB1T8mfDlIX5p4EBwBgXCQ4ADA1bQ4OAMDoSHAAYIokOAAA4yLBAYCJqZiDAwAwOusOcKrqiqq6u6o+vmTdL1fVZ6rq5tlywSrfe15V3VZVB6rqsu3sOACwBd07s+ySjSQ4VyY5b4X1r+/us2fLNcs3VtW+JG9Mcn6Ss5JcXFVnbaWzAAAbse4Ap7s/mOTeTdQ+J8mB7r69ux9M8o4kF26iDgDAUdnKHJyXV9XHZoewHrvC9lOT3LHk+cHZOgBgl1XvzLJbNjvAeVOSv5fk7CSfTfK6FdqsdBOeVXe1qi6tqpuq6qav54FNdgsAYJMDnO6+q7sPd/dCkv+RxcNRyx1McvqS56cluXONmpd39/7u3n9sjt9MtwCAjegdXHbJpgY4VfWEJU9/KMnHV2h2Y5Izq+rJVXVckouSXL2Z1wMAOBrrXuivqq5Kcm6Sk6vqYJJXJTm3qs7O4tjs00l+ctb225K8pbsv6O5DVfXyJNcm2Zfkiu6+ZZC9AACOSi3sdg+Gte4Ap7svXmH1W1dpe2eSC5Y8vybJQ04hBwAYkls1AMAUuVUDAMC4SHAAYILcbBMAYGQkOAAwNZ1dvRHmTpDgAABzZ+8mOLXSnR62aM5Hq/PuL96yf5C6x3xluF+Dp77ihkHq9gPD3M7kKZddP0hdYO8xBwcAYGT2boIDAAxHggMAMC4GOADA3HGICgAmpmKSMQDA6EhwAGBquuf+0ikSHABg7khwAGCCzMEBABgZCQ4ATJEEBwBgXCQ4ADBB5uAAAIyMBAcApqaTLMx3hCPBAQDmjgQHAKZovgMcCQ4AMH8kOAAwQc6iAgAYGQMcAGDuTOsQ1TH7hqu9cHi42iRJjrvr2EHqHvP1GqQuwJ7W832MSoIDAMydaSU4AEASk4wBAEZHggMAU9NxoT8AgLExwAGAiakk1b0jy4b6U3VeVd1WVQeq6rIVtv/bqrq1qj5WVR+oqietV9MABwDYNVW1L8kbk5yf5KwkF1fVWcua/e8k+7v7GUneneQ/r1fXAAcApmhhh5b1nZPkQHff3t0PJnlHkguXNujuP+zu+2dPb0hy2npFDXAAgCGdXFU3LVkuXbb91CR3LHl+cLZuNZck+f31XtRZVAAwQRudH7MN7unu/Wt1ZYV1K3auqv5Fkv1Jvne9FzXAAQB208Ekpy95flqSO5c3qqrvS/JLSb63ux9Yr6gBDgBMzd66Ds6NSc6sqicn+UySi5L8yNIGVfWsJP89yXndffdGipqDAwDsmu4+lOTlSa5N8okkv9ndt1TVq6vqxbNmr03yyCTvqqqbq+rq9epKcABgcnpP3U28u69Jcs2yda9c8vj7jramBAcAmDsSHACYIHcTBwAYGQMcAGDurHuIqqquSPIDSe7u7qfP1r0zydNmTR6T5IvdffYK3/vpJF9OcjjJoXUu9AMA7JQ9NMl4CBuZg3Nlkjck+bUjK7r7nx95XFWvS3LfGt///O6+Z7MdBAA4WusOcLr7g1V1xkrbqqqS/HCSf7S93QIABtNJbexGmKO11bOovjvJXd39qVW2d5L3V1Un+e/dffmGKw8RnfXh7a85Unf97HMHq/3we4b5rTnjl64fpC4A82erA5yLk1y1xvbndfedVXVKkuuq6pPd/cGVGs7uLnppkpyQE7fYLQBgTXM+B2fTZ1FV1cOS/NMk71ytTXffOft6d5L3JDlnjbaXd/f+7t5/bI7fbLcAALZ0mvj3Jflkdx9caWNVPaKqHnXkcZIXJfn4Fl4PANguvUPLLll3gFNVVyW5PsnTqupgVV0y23RRlh2eqqpvq6oj95J4fJI/rqqPJvmzJO/t7vdtX9cBAFa2kbOoLl5l/Y+tsO7OJBfMHt+e5Jlb7B8AMIAyBwcAYFzcbBMApkiCAwAwLhIcAJiaTjLnVzKW4AAAc0eCAwATU2lnUQEAjI0BDgAwdxyiAoApcogKAGBcJDgAMEUSHACAcZHgAMDUuNAfAMD4SHAAYIJc6A8AYGQkOAAwRXOe4BjgbJdj9g1Td+HwIGX3PTjcB/tzP/i1QeqedNUgZRm7oX73hjTQ7zXwdwxwAGByeu4THHNwAIC5I8EBgKnpSHAAAMZGggMAU+RKxgAA42KAAwDMHYeoAGCC3KoBAGBkJDgAMEUSHACAcZHgAMDUdJIFCQ4AwKhIcABgctxsEwBgdCQ4ADBFEhwAgHGR4ADAFElwAADGRYIDAFPjOjgAAOOzJxOcL+cL9/yvfvdfb7D5yUnuGbI/G3J4sMrD7N+b373tJf+u9oZbHtW+/dVm+rK79sZnczh7Y//G9ru3d8zz/o1x3560sy/XSS/s7EvusD05wOnu/2ujbavqpu7eP2R/dtM8798871tCtiBCAAAIAUlEQVRi/8bO/o3XPO8bG+cQFQAwd/ZkggMADMxp4nve5bvdgYHN8/7N874l9m/s7N94zfO+sUHVcz6CAwC+2aOPe3w/91sv3pHXet8d/+XDuzEnah4SHACAb2IODgBM0ZwfwRlFglNV51XVbVV1oKouW2H78VX1ztn2D1XVGTvfy82pqtOr6g+r6hNVdUtV/ZsV2pxbVfdV1c2z5ZW70dfNqqpPV9Wfz/p+0wrbq6r+6+z9+1hVPXs3+rkZVfW0Je/LzVX1pap6xbI2o3r/quqKqrq7qj6+ZN3jquq6qvrU7OtjV/nel83afKqqXrZzvd64VfbvtVX1ydnn7z1V9ZhVvnfNz/JesMr+/XJVfWbJZ/CCVb53zb+1u22VfXvnkv36dFXdvMr37vn3ju215wc4VbUvyRuTnJ/krCQXV9VZy5pdkuQL3f3UJK9P8pqd7eWWHEry89397Um+K8nPrLB/SfJH3X32bHn1znZxWzx/1veVjsOen+TM2XJpkjftaM+2oLtvO/K+JPm/k9yf5D0rNB3T+3dlkvOWrbssyQe6+8wkH5g9/yZV9bgkr0rynUnOSfKq1QZCu+zKPHT/rkvy9O5+RpK/SPKLa3z/Wp/lveDKPHT/kuT1Sz6D1yzfuMG/tbvtyizbt+7+50t+B38ryW+v8f17/b3bWd07s+ySPT/AyeIfygPdfXt3P5jkHUkuXNbmwiRvmz1+d5IXVFXtYB83rbs/290fmT3+cpJPJDl1d3u14y5M8mu96IYkj6mqJ+x2pzbhBUn+srs3ehXuPam7P5jk3mWrl/6OvS3JP1nhW78/yXXdfW93fyGLg4aV/qHdVSvtX3e/v7sPzZ7ekOS0He/YNlnl/duIjfyt3VVr7dvsb/4PJ7lqRzvFnjWGAc6pSe5Y8vxgHjoA+Eab2R+p+5J8y470bhvNDq09K8mHVtj8nKr6aFX9flV9x452bOs6yfur6sNVdekK2zfyHo/BRVn9j+uY378keXx3fzZZHJQnOWWFNvPyPv6rJL+/yrb1Pst72ctnh+CuWCVZG/v7991J7uruT62yfczv3QB2KL2R4KxppSRm+U9sI232tKp6ZBbj1Vd095eWbf5Ikid19zOT/Lckv7PT/dui53X3s7MYff9MVX3Psu3z8P4dl+TFSd61wuaxv38bNQ/v4y9l8bDxb6zSZL3P8l71piR/L8nZST6b5HUrtBn7+3dx1k5vxvresUljGOAcTHL6kuenJblztTZV9bAkj87mItpdUVXHZnFw8xvd/ZDjx939pe7+yuzxNUmOraqTd7ibm9bdd86+3p3F+SnnLGuykfd4rzs/yUe6+67lG8b+/s3cdeSw4ezr3Su0GfX7OJsU/QNJXtqrXCBsA5/lPam77+ruw929kOR/ZOV+j/b9m/3d/6dJ3rlam7G+d4PpJAsLO7PskjEMcG5McmZVPXn2v+SLkly9rM3VSY6csfGSJH+w2h+ovWZ23PitST7R3b+6SptvPTKnqKrOyeL79vmd6+XmVdUjqupRRx4neVGSjy9rdnWSH52dTfVdSe47cjhkRFb93+OY378llv6OvSzJ767Q5tokL6qqx84Ogbxotm7Pq6rzkvz7JC/u7vtXabORz/KetGxO2w9l5X5v5G/tXvV9ST7Z3QdX2jjm947N2/PXwenuQ1X18iz+odyX5IruvqWqXp3kpu6+OosDhF+vqgNZTG4u2r0eH7XnJfmXSf58yemN/yHJE5Oku9+cxUHbT1fVoSR/m+SisQzgkjw+yXtm/74/LMnbu/t9VfVTyTf275okFyQ5kMWzkH58l/q6KVV1YpIXJvnJJeuW7t+o3r+quirJuUlOrqqDWTwz6j8l+c2quiTJ/0nyz2Zt9yf5qe7+1919b1X9Shb/oUySV3f3nktSV9m/X0xyfJLrZp/VG7r7p6rq25K8pbsvyCqf5V3YhTWtsn/nVtXZWfx/+6cz+6wu3b/V/tbuwi6saqV96+63ZoX5b2N873bc3v0ztC3cqgEAJubRx57Sz/2Wl+zIa73vrjftyq0a9nyCAwAMYM4DjjHMwQEAOCoGOADA3HGICgAmp5MFh6gAAEZFggMAU9PJ4nUf55cEBwCYOxIcAJgic3AAAMZFggMAU+RCfwAA4yLBAYCp6U4WnEUFADAqEhwAmCJzcAAAxkWCAwAT1ObgAACMiwQHACanzcEBABgbAxwAYO44RAUAU9Nxs00AgLGR4ADAFLXTxAEARkWCAwAT00naHBwAgHGR4ADA1HSbgwMAMDYGOAAwQb3QO7JsRFWdV1W3VdWBqrpshe3HV9U7Z9s/VFVnrFfTAAcA2DVVtS/JG5Ocn+SsJBdX1VnLml2S5Avd/dQkr0/ymvXqGuAAwBT1ws4s6zsnyYHuvr27H0zyjiQXLmtzYZK3zR6/O8kLqqrWKmqAAwDsplOT3LHk+cHZuhXbdPehJPcl+Za1ijqLCgAm5sv5wrX/q9998g693AlVddOS55d39+VLnq+UxCyfvLORNt/EAAcAJqa7z9vtPixxMMnpS56fluTOVdocrKqHJXl0knvXKuoQFQCwm25McmZVPbmqjktyUZKrl7W5OsnLZo9fkuQPuluCAwDsTd19qKpenuTaJPuSXNHdt1TVq5Pc1N1XJ3lrkl+vqgNZTG4uWq9urTMAAgAYHYeoAIC5Y4ADAMwdAxwAYO4Y4AAAc8cABwCYOwY4AMDcMcABAOaOAQ4AMHf+f8019jmvEoYbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# mask the diagonals so we don't get influenced by them unfairly\n",
    "sg_no_diag = np.copy(data.sig_inv)\n",
    "for i in range(M):\n",
    "    sg_no_diag[i*2:i*2+2,i*2:i*2+2] = np.zeros([2,2])\n",
    "\n",
    "visualize_matrix(np.abs(sg_no_diag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating Z...\n",
      "[Epoch 0] Loss: 1128.407593\n",
      "[Epoch 1000] Loss: 0.012238\n",
      "[Epoch 2000] Loss: 0.012238\n",
      "[Epoch 3000] Loss: 0.012238\n",
      "[Epoch 4000] Loss: 0.012238\n",
      "[Epoch 4999] Loss: 0.012238\n",
      "Estimating \\mu...\n",
      "[Epoch 0] Loss: 14.685292\n",
      "[Epoch 1000] Loss: 0.000002\n",
      "[Epoch 2000] Loss: 0.000000\n",
      "[Epoch 3000] Loss: 0.000000\n",
      "[Epoch 4000] Loss: 0.000000\n",
      "[Epoch 4999] Loss: 0.000000\n",
      "Average absolute error: 0.000638746893010983\n",
      "Average absolute error -- cols swapped: 0.13478459300640178\n"
     ]
    }
   ],
   "source": [
    "lm = LabelModel(k=data.k, class_balance=data.p)\n",
    "\n",
    "# Get the exact O_inv\n",
    "O_inv = np.linalg.inv(data.O_true)\n",
    "\n",
    "# Generate c_data: clique data structure\n",
    "# Normally this is assembled while computing O, but if we pass in O\n",
    "# ourselves, we need to construct this data structure too...\n",
    "lm._set_constants(data.L)\n",
    "lm._set_dependencies(data.E)\n",
    "c_data = {}\n",
    "for i in range(data.m):\n",
    "    c_data[i] = {\n",
    "        'start_index': i*data.k,\n",
    "        'end_index': (i+1)*data.k,\n",
    "        'max_cliques': set([j for j in lm.c_tree.nodes() \n",
    "            if i in lm.c_tree.node[j]['members']])\n",
    "    }\n",
    "\n",
    "lm.train(\n",
    "    data.L,\n",
    "    deps=data.E,\n",
    "    all_unary_cliques=True,\n",
    "    higher_order_cliques=False,\n",
    "    n_epochs=5000,\n",
    "    print_every=1000,\n",
    "    lr=0.01,\n",
    "    l2=0,\n",
    "    O_inv_prec=1024,\n",
    "    O=data.O_true,\n",
    "    O_inv=O_inv,\n",
    "    c_data=c_data\n",
    ")\n",
    "\n",
    "mu_est = lm.mu.detach().numpy() # Note: we can swap column order\n",
    "mu_est_swapped = lm.mu.detach().numpy()[:,::-1] # Note: we can swap column order\n",
    "print(f\"Average absolute error: {np.mean(np.abs(mu_est - data.mu_true))}\")\n",
    "print(f\"Average absolute error -- cols swapped: {np.mean(np.abs(mu_est_swapped - data.mu_true))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the `LabelModel`\n",
    "\n",
    "Note that:\n",
    "* The `train` method assembles other data structures, such as the dependencies junction tree, etc.\n",
    "* The `higher_order_cliques` kwarg controls whether or not to include them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LabelModel(k=data.k, class_balance=data.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.config['higher_order_cliques'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Generate the \"correct\" mu\n",
    "lm._set_constants(data.L)\n",
    "lm._set_dependencies(data.E)\n",
    "mu = compute_mu(lm._get_augmented_label_matrix(data.L.todense()), data.Y, K, data.p)\n",
    "\n",
    "# Compute O, O_inv, P based on L\n",
    "lm._generate_O(data.L.todense())\n",
    "O = lm.O.numpy()\n",
    "print(O)\n",
    "d, d = O.shape\n",
    "O_inv = np.linalg.inv(O)\n",
    "P = np.diag(data.p)\n",
    "\n",
    "JJT = np.linalg.inv(np.linalg.inv(P) - mu.T @ O_inv @ mu)\n",
    "ZZT = O_inv @ mu @ JJT @ mu.T @ O_inv.T'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that JJT is indeed PSD ==> ZZT is rank k\n",
    "#np.linalg.eig(JJT)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.linalg.eig((ZZT + ZZT.T)/2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.train(\n",
    "    data.L,\n",
    "    deps=data.E,\n",
    "    all_unary_cliques=True,\n",
    "    higher_order_cliques=True,\n",
    "    n_epochs=50000,\n",
    "    print_every=5000,\n",
    "    lr=0.0001,\n",
    "    l2=0,\n",
    "    O_inv_prec=1024,\n",
    "    #O_inv=ZZT\n",
    ")\n",
    "\n",
    "lm._set_constants(data.L)\n",
    "lm._set_dependencies(data.E)\n",
    "mu = compute_mu(lm._get_augmented_label_matrix(data.L.todense()), data.Y, K, data.p)\n",
    "\n",
    "\n",
    "# Test against the true parameter values\n",
    "mu_est = lm.mu.detach().numpy()\n",
    "print(mu)\n",
    "print(mu_est)\n",
    "print(f\"Average absolute error: {np.mean(np.abs(mu_est - mu))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check that the true $Z$ gets lower loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(np.linalg.eig(O)[0])[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "O = lm.O.numpy()\n",
    "d, d = O.shape\n",
    "O_inv = lm.O_inv.numpy()\n",
    "mask = lm.mask.numpy()\n",
    "P = lm.P.numpy()\n",
    "\n",
    "JJT = np.linalg.inv(np.linalg.inv(P) - mu.T @ O_inv @ mu)\n",
    "ZZT = O_inv @ mu @ JJT @ mu.T @ O_inv.T\n",
    "\n",
    "np.linalg.norm((O_inv + ZZT) * mask)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seed=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_matrix(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize_matrix(np.abs((O_inv + ZZT) * mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.c_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_est = lm.Z.detach().numpy()\n",
    "visualize_matrix(np.abs((O_inv + Z_est @ Z_est.T) * mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seed=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_matrix(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_matrix(np.abs((O_inv + ZZT) * mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_est = lm.Z.detach().numpy()\n",
    "visualize_matrix(np.abs((O_inv + Z_est @ Z_est.T) * mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seed=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_matrix(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_matrix(np.abs((O_inv + ZZT) * mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_est = lm.Z.detach().numpy()\n",
    "visualize_matrix(np.abs((O_inv + Z_est @ Z_est.T) * mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_matrix(np.abs(mu_est - mu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_matrix(np.abs(mu_est - mu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.c_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying to solve with `scipy.optimize.minimize`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "O_inv = lm.O_inv.numpy()\n",
    "mask = lm.mask.numpy()\n",
    "\n",
    "z0 = np.random.randn(lm.d * lm.k)\n",
    "l import LabelModl import LabelModel\n",
    "from metal.label_model.utils import (\n",
    "    compute_mu,\n",
    "    compute_covariance,\n",
    "    compute_inv_covariance,\n",
    "    print_matrix,el\n",
    "from metal.label_model.utils import (\n",
    "    compute_mu,\n",
    "    compute_covariance,\n",
    "    compute_inv_covariance,\n",
    "    print_matrix,\n",
    "def objective_fn(z):\n",
    "    Z = z.reshape(-1, data.k)\n",
    "    return np.linalg.norm( (O_inv + Z @ Z.T) * mask )**2\n",
    "\n",
    "def gradient_fn(z):\n",
    "    Z = z.reshape(-1, data.k)\n",
    "    X = (O_inv + Z @ Z.T) * mask\n",
    "    return np.ravel(X @ Z)\n",
    "\n",
    "res = minimize(objective_fn, z0, jac=gradient_fn, method='BFGS')\n",
    "Z = res['x'].reshape(-1, data.k)\n",
    "res['fun']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "O = lm.O.numpy()\n",
    "P = lm.P.numpy()\n",
    "I_k = np.eye(data.k)\n",
    "Q = O @ Z @ np.linalg.inv(I_k + Z.T @ O @ Z) @ Z.T @ O\n",
    "\n",
    "mu0 = np.random.randn(lm.d * lm.k)\n",
    "\n",
    "def objective_fn_2(mu):\n",
    "    M = mu.reshape(-1, data.k)\n",
    "    return np.linalg.norm(Q - M @ P @ M.T)**2 + np.linalg.norm(np.sum(M @ P, 1) - np.diag(O))**2\n",
    "\n",
    "res_2 = minimize(objective_fn_2, mu0, method='BFGS')\n",
    "M = res_2['x'].reshape(-1, data.k)\n",
    "res_2['fun']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test against the true parameter values\n",
    "print(f\"Average absolute error: {np.mean(np.abs(M - mu))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the inverse covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = compute_inv_covariance(\n",
    "    lm._get_augmented_label_matrix(data.L.todense()),\n",
    "    data.Y,\n",
    "    data.k,\n",
    "    data.p\n",
    ")\n",
    "visualize_matrix(np.abs(J))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_matrix(lm.mask.numpy(), fig_size=[5,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "O_inv = lm.O_inv.numpy()\n",
    "Z = lm.Z.detach().numpy()\n",
    "mask = lm.mask.numpy()\n",
    "visualize_matrix(np.abs((O_inv + Z@Z.T) * mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at the internal 'bookkeeping' of cliques..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.c_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependency edge weights\n",
    "[((i,j), data.theta[(i,j)]) for i,j in data.E]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
