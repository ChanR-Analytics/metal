{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lfs/1/annhe/anaconda3/envs/metal/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from data_gen_utils import *\n",
    "import sys\n",
    "sys.path.append(\"../\") # go to parent dir\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import mpmath\n",
    "\n",
    "from synthetic.generate import SingleTaskTreeDepsGenerator\n",
    "from metal.label_model import LabelModel, CliqueTree\n",
    "from metal.label_model.utils import (\n",
    "    compute_mu,\n",
    "    compute_covariance,\n",
    "    compute_inv_covariance,\n",
    "    print_matrix,\n",
    "    visualize_matrix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 6\n",
    "n = 10000\n",
    "K = 1\n",
    "dg = DataGenerator(M,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg.generate_O(k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (2, 3), (4, 5)]\n"
     ]
    }
   ],
   "source": [
    "print(dg.deps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (2, 3), (4, 5)]\n"
     ]
    }
   ],
   "source": [
    "# remove deps\n",
    "print(dg.deps_no_diag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.  1. -1. ...  1.  1. -1.]\n",
      " [ 1.  1. -1. ...  1. -1. -1.]\n",
      " [ 1.  1.  1. ...  1.  1. -1.]\n",
      " [ 1.  1.  1. ... -1. -1. -1.]\n",
      " [-1.  1.  1. ... -1. -1. -1.]\n",
      " [-1.  1.  1. ... -1. -1. -1.]]\n"
     ]
    }
   ],
   "source": [
    "print(dg.L)\n",
    "\n",
    "w,h = (dg.L).shape\n",
    "L = np.zeros((w,h),dtype=float)\n",
    "for i in range(w):\n",
    "    for j in range(h):\n",
    "        if dg.L[i,j] > 0:\n",
    "            L[i,j] = 1\n",
    "        else:\n",
    "            L[i,j] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. ... 1. 1. 0.]\n",
      " [1. 1. 0. ... 1. 0. 0.]\n",
      " [1. 1. 1. ... 1. 1. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]]\n",
      "[(0, 1), (2, 3), (4, 5)]\n"
     ]
    }
   ],
   "source": [
    "print(L)\n",
    "print(dg.deps_no_diag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LabelModel(k=1)\n",
    "lm.config['higher_order_cliques'] = False\n",
    "lm.config['verbose'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I GOT HERE\n",
      "I GOT HERE 2\n",
      "I GOT HERE 3\n",
      "INIT 1\n",
      "GET CLIQUE TREE 1\n",
      "GET CLIQUE TREE 2\n",
      "GET CLIQUE TREE 3\n",
      "GET CLIQUE TREE 4\n",
      "GET CLIQUE TREE 5\n",
      "INIT 2\n",
      "CLIQUE TREE 1\n",
      "START INDEX:  9\n",
      "I GOT HERE 4\n",
      "L AUG SAHPE:  (10000, 9)\n",
      "ALL UNARY CLIQUES\n",
      "HIGHER ORDER CLIQUES\n",
      "(9, 9)\n",
      "[[0.4956 0.2772 0.2858 0.2136 0.3181 0.2395 0.2227 0.2772 0.1826]\n",
      " [0.2772 0.3097 0.2081 0.1815 0.2509 0.2024 0.1883 0.2772 0.157 ]\n",
      " [0.2858 0.2081 0.4974 0.2509 0.3003 0.2183 0.204  0.1854 0.2509]\n",
      " [0.2136 0.1815 0.2509 0.2919 0.2368 0.1939 0.1808 0.1626 0.2509]\n",
      " [0.3181 0.2509 0.3003 0.2368 0.4979 0.3038 0.3038 0.2254 0.2043]\n",
      " [0.2395 0.2024 0.2183 0.1939 0.3038 0.3263 0.3038 0.1815 0.1668]\n",
      " [0.2227 0.1883 0.204  0.1808 0.3038 0.3038 0.3038 0.1686 0.1558]\n",
      " [0.2772 0.2772 0.1854 0.1626 0.2254 0.1815 0.1686 0.2772 0.1403]\n",
      " [0.1826 0.157  0.2509 0.2509 0.2043 0.1668 0.1558 0.1403 0.2509]]\n",
      "Computing O^{-1}...\n",
      "L AUG SAHPE:  (10000, 9)\n",
      "ALL UNARY CLIQUES\n",
      "HIGHER ORDER CLIQUES\n",
      "O unnorm   [4956.0  2772.0  2858.0  2136.0  3181.0  2395.0  2227.0  2772.0  1826.0]\n",
      "[2772.0  3097.0  2081.0  1815.0  2509.0  2024.0  1883.0  2772.0  1570.0]\n",
      "[2858.0  2081.0  4974.0  2509.0  3003.0  2183.0  2040.0  1854.0  2509.0]\n",
      "[2136.0  1815.0  2509.0  2919.0  2368.0  1939.0  1808.0  1626.0  2509.0]\n",
      "[3181.0  2509.0  3003.0  2368.0  4979.0  3038.0  3038.0  2254.0  2043.0]\n",
      "[2395.0  2024.0  2183.0  1939.0  3038.0  3263.0  3038.0  1815.0  1668.0]\n",
      "[2227.0  1883.0  2040.0  1808.0  3038.0  3038.0  3038.0  1686.0  1558.0]\n",
      "[2772.0  2772.0  1854.0  1626.0  2254.0  1815.0  1686.0  2772.0  1403.0]\n",
      "[1826.0  1570.0  2509.0  2509.0  2043.0  1668.0  1558.0  1403.0  2509.0]\n",
      "n:  10000.0\n",
      "Estimating Z...\n",
      "[Epoch 0] Loss: 141.489807\n",
      "[Epoch 1000] Loss: 6.952316\n",
      "[Epoch 2000] Loss: 6.952316\n",
      "[Epoch 3000] Loss: 6.952316\n",
      "[Epoch 4000] Loss: 6.952316\n",
      "[Epoch 5000] Loss: 6.952316\n",
      "[Epoch 6000] Loss: 6.952316\n",
      "[Epoch 7000] Loss: 6.952316\n",
      "[Epoch 8000] Loss: 6.952316\n",
      "[Epoch 9000] Loss: 6.952316\n",
      "[Epoch 10000] Loss: 6.952316\n",
      "[Epoch 11000] Loss: 6.952316\n",
      "[Epoch 12000] Loss: 6.952316\n",
      "[Epoch 13000] Loss: 6.952316\n",
      "[Epoch 14000] Loss: 6.952316\n",
      "[Epoch 15000] Loss: 6.952316\n",
      "[Epoch 16000] Loss: 6.952316\n",
      "[Epoch 17000] Loss: 6.952316\n",
      "[Epoch 18000] Loss: 6.952316\n",
      "[Epoch 19000] Loss: 6.952316\n",
      "[Epoch 20000] Loss: 6.952316\n",
      "[Epoch 21000] Loss: 6.952316\n",
      "[Epoch 22000] Loss: 6.952316\n",
      "[Epoch 23000] Loss: 6.952316\n",
      "[Epoch 24000] Loss: 6.952316\n",
      "[Epoch 25000] Loss: 6.952316\n",
      "[Epoch 26000] Loss: 6.952316\n",
      "[Epoch 27000] Loss: 6.952316\n",
      "[Epoch 28000] Loss: 6.952316\n",
      "[Epoch 29000] Loss: 6.952316\n",
      "[Epoch 30000] Loss: 6.952316\n",
      "[Epoch 31000] Loss: 6.952316\n",
      "[Epoch 32000] Loss: 6.952316\n",
      "[Epoch 33000] Loss: 6.952316\n",
      "[Epoch 34000] Loss: 6.952316\n",
      "[Epoch 35000] Loss: 6.952316\n",
      "[Epoch 36000] Loss: 6.952316\n",
      "[Epoch 37000] Loss: 6.952316\n",
      "[Epoch 38000] Loss: 6.952316\n",
      "[Epoch 39000] Loss: 6.952316\n",
      "[Epoch 40000] Loss: 6.952316\n",
      "[Epoch 41000] Loss: 6.952316\n",
      "[Epoch 42000] Loss: 6.952316\n",
      "[Epoch 43000] Loss: 6.952316\n",
      "[Epoch 44000] Loss: 6.952316\n",
      "[Epoch 45000] Loss: 6.952316\n",
      "[Epoch 46000] Loss: 6.952316\n",
      "[Epoch 47000] Loss: 6.952316\n",
      "[Epoch 48000] Loss: 6.952316\n",
      "[Epoch 49000] Loss: 6.952316\n",
      "Estimating \\mu...\n",
      "[Epoch 0] Loss: 32.248734\n",
      "[Epoch 1000] Loss: 0.072031\n",
      "[Epoch 2000] Loss: 0.072031\n",
      "[Epoch 3000] Loss: 0.072031\n",
      "[Epoch 4000] Loss: 0.072031\n",
      "[Epoch 5000] Loss: 0.072031\n",
      "[Epoch 6000] Loss: 0.072031\n",
      "[Epoch 7000] Loss: 0.072031\n",
      "[Epoch 8000] Loss: 0.072031\n",
      "[Epoch 9000] Loss: 0.072031\n",
      "[Epoch 10000] Loss: 0.072031\n",
      "[Epoch 11000] Loss: 0.072031\n",
      "[Epoch 12000] Loss: 0.072031\n",
      "[Epoch 13000] Loss: 0.072031\n",
      "[Epoch 14000] Loss: 0.072031\n",
      "[Epoch 15000] Loss: 0.072031\n",
      "[Epoch 16000] Loss: 0.072031\n"
     ]
    }
   ],
   "source": [
    "lm.train(L=dg.L.T,\n",
    "         deps=dg.deps_no_diag,\n",
    "         all_unary_cliques=True,\n",
    "        higher_order_cliques=True,\n",
    "        n_epochs=50000,\n",
    "        print_every=5000,\n",
    "        lr=0.0001,\n",
    "        l2=0,\n",
    "        O_inv_prec=1024,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm._set_constants(dg.L.T)\n",
    "#lm._set_dependencies(dg.deps_no_diag)\n",
    "mu = compute_mu(lm._get_augmented_label_matrix(dg.L.T), dg.Y.T, K, np.full(K, 1/K))\n",
    "\n",
    "\n",
    "# Test against the true parameter values\n",
    "mu_est = lm.mu.detach().numpy()\n",
    "print(mu_est)\n",
    "print(f\"Average absolute error: {np.mean(np.abs(mu_est - mu))}\")\n",
    "\n",
    "mu_est_sm = mu_est[:6]\n",
    "mu_true = dg.mu\n",
    "print(f\"Average absolute error: {np.mean(np.abs(mu_est_sm - mu_true))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.train(L=L.T,\n",
    "         deps=dg.deps_no_diag,\n",
    "         all_unary_cliques=True,\n",
    "        higher_order_cliques=True,\n",
    "        n_epochs=50000,\n",
    "        print_every=5000,\n",
    "        lr=0.0001,\n",
    "        l2=0,\n",
    "        O_inv_prec=1024,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm._set_constants(L.T)\n",
    "#lm._set_dependencies(dg.deps_no_diag)\n",
    "Y = np.zeros(dg.Y.shape,dtype=float)\n",
    "for i in range(n):\n",
    "    if dg.Y[i] > 0:\n",
    "        Y[i] = 1\n",
    "    else:\n",
    "        Y[i] = 0\n",
    "mu = compute_mu(lm._get_augmented_label_matrix(L.T), Y.T, K, np.full(K, 1/K))\n",
    "\n",
    "\n",
    "# Test against the true parameter values\n",
    "mu_est = lm.mu.detach().numpy()\n",
    "print(mu_est)\n",
    "print(f\"Average absolute error: {np.mean(np.abs(mu_est - mu))}\")\n",
    "\n",
    "mu_est_sm = mu_est[:6]\n",
    "mu_true = dg.mu\n",
    "print(f\"Average absolute error: {np.mean(np.abs(mu_est_sm - mu_true))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
