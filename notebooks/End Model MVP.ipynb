{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metal.utils import hard_to_soft\n",
    "\n",
    "N = 1200\n",
    "X = np.random.random((N,2)) * 2 - 1\n",
    "\n",
    "Y = np.zeros((N,1))\n",
    "Y[:,0] = (X[:,0] > X[:,1] + 0.5).astype(int) + 1\n",
    "\n",
    "X = torch.tensor(X, dtype=torch.float)\n",
    "Y = torch.tensor(Y, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate into splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting batchnorm=True to batchnorm=False\n",
      "Reaffirming dropout=0.0\n",
      "Overwriting layer_output_dims=[100, 50] to layer_output_dims=[2]\n",
      "Overwriting task_head_output_dims=None to task_head_output_dims=2\n",
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): IdentityModule()\n",
      "  )\n",
      "  (1): Linear(in_features=2, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "X_train = X[:1000]\n",
    "X_dev   = X[1000:1100]\n",
    "X_test  = X[1100:]\n",
    "\n",
    "Y_train = Y[:1000, 0]\n",
    "Y_dev   = Y[1000:1100]\n",
    "Y_test  = Y[1100:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting batchnorm=True to batchnorm=False\n",
      "Reaffirming dropout=0.0\n",
      "Overwriting layer_output_dims=[100, 50] to layer_output_dims=[2]\n",
      "Overwriting task_head_output_dims=None to task_head_output_dims=2\n",
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): IdentityModule()\n",
      "  )\n",
      "  (1): Linear(in_features=2, out_features=2, bias=True)\n",
      ")\n",
      "Reaffirming n_epochs=40\n",
      "Reaffirming print_every=5\n",
      "[E:1]\tTrain Loss: 0.540\tDev score: 0.710\n",
      "[E:5]\tTrain Loss: 0.398\tDev score: 0.810\n",
      "[E:10]\tTrain Loss: 0.304\tDev score: 0.900\n",
      "[E:15]\tTrain Loss: 0.266\tDev score: 0.950\n",
      "[E:20]\tTrain Loss: 0.249\tDev score: 0.950\n",
      "[E:25]\tTrain Loss: 0.237\tDev score: 0.970\n",
      "[E:30]\tTrain Loss: 0.231\tDev score: 0.970\n",
      "[E:35]\tTrain Loss: 0.226\tDev score: 0.970\n",
      "[E:40]\tTrain Loss: 0.223\tDev score: 0.970\n",
      "Accuracy: 0.930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.93"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from metal.end_model.baselines import LogisticRegression\n",
    "em = LogisticRegression(input_dim=2)\n",
    "em.train(X_train, Y_train, X_dev, Y_dev, n_epochs=40, print_every=5)\n",
    "em.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-layer NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting seed=None to seed=1\n",
      "Reaffirming dropout=0.0\n",
      "Overwriting batchnorm=True to batchnorm=False\n",
      "Overwriting layer_output_dims=[100, 50] to layer_output_dims=[2, 4, 2]\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): IdentityModule()\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=4, bias=True)\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=2, bias=True)\n",
      "  )\n",
      "  (3): Linear(in_features=2, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "Reaffirming n_epochs=40\n",
      "Reaffirming print_every=5\n",
      "[E:1]\tTrain Loss: 0.688\tDev score: 0.710\n",
      "[E:5]\tTrain Loss: 0.568\tDev score: 0.710\n",
      "[E:10]\tTrain Loss: 0.528\tDev score: 0.710\n",
      "[E:15]\tTrain Loss: 0.440\tDev score: 0.720\n",
      "[E:20]\tTrain Loss: 0.324\tDev score: 0.910\n",
      "[E:25]\tTrain Loss: 0.227\tDev score: 0.940\n",
      "[E:30]\tTrain Loss: 0.186\tDev score: 0.980\n",
      "[E:35]\tTrain Loss: 0.157\tDev score: 0.980\n",
      "[E:40]\tTrain Loss: 0.146\tDev score: 0.990\n",
      "Accuracy: 0.990\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.99"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from metal.end_model import EndModel\n",
    "\n",
    "em = EndModel(\n",
    "    seed=1,\n",
    "    dropout=0.0,\n",
    "    batchnorm=False,\n",
    "    layer_output_dims=[2,4,2],\n",
    ")\n",
    "em.train(X_train, Y_train, X_dev, Y_dev, n_epochs=40, print_every=5)\n",
    "em.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y = np.zeros((N,2))\n",
    "# Y[:,0] = (X[:,0] > X[:,1] + 0.5).astype(int) + 1\n",
    "# Y[:,1] = (X[:,0] > X[:,1] + 0.25).astype(int) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from metal.end_model import EndModel\n",
    "# from metal.structs import TaskGraph\n",
    "# from metal.utils import hard_to_soft\n",
    "\n",
    "# Y_train = [Y[:1000, 0],     Y[:1000, 1]]\n",
    "# Y_dev   = [Y[1000:1100, 0], Y[1000:1100, 1]]\n",
    "# Y_test  = [Y[1100:, 0],     Y[1100:, 1]]\n",
    "\n",
    "# Y_train = [hard_to_soft(Y_t, k=2) for Y_t in Y_train]\n",
    "\n",
    "# edges = [(0,1)]\n",
    "# cards = [2,2]\n",
    "# tg = TaskGraph(edges, cards)\n",
    "\n",
    "# em = EndModel(\n",
    "#     label_map=[[1,2],[1,2]], \n",
    "#     task_graph=tg,\n",
    "#     seed=1,\n",
    "#     dropout=0.0,\n",
    "#     layer_output_dims=[2,10,4,2],\n",
    "#     head_layers=[2,3],\n",
    "#     pass_predictions=True,\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metal]",
   "language": "python",
   "name": "conda-env-metal-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
