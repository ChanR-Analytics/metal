{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning models often have many hyperparameters that need to be tuned to achieve maximal performance (e.g: learning rate, dropout rate, number of layers, layer size, etc) . This motivates the need for hyperparameter tuners that intelligently search the space of hyperparameters for a high performing model. \n",
    "\n",
    "To address this, MeTaL supports multiple hyperparameter tuners with an easy to use interface which allows users to streamline the hyperparameter optimization process. This tutorial covers utilizing MeTaL's hyperparameter tuners to tune an EndModel for maximal performance. Currently, two hyperparameter algorithms are supported:\n",
    "\n",
    "- <b>Random Search</b>\n",
    "- <b>Hyperband</b>\n",
    "\n",
    "The tutorial is broken down into the following sections \n",
    "\n",
    "1. <b>Setting up the Problem and Loading the Data</b>\n",
    "2. <b>Defining the Search Space</b>\n",
    "3. <b>Performing Random Search</b>\n",
    "4. <b>Performing Hyperband Search</b>\n",
    "5. <b>Comparing Random Search against Hyperband Search</b>\n",
    "\n",
    "Let's begin!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Before beginning, we first need to make sure that the metal/ directory is on our Python path. If the following cell runs without an error, you're all set. If not, make sure that you've installed snorkel-metal with pip or conda (or that you've added the repo to your path if you're running from source; for example, running source add_to_path.sh from the repository root)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dfs/scratch0/maxlam/metal/metal/analysis.py:13: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"/dfs/scratch0/maxlam/local_software/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/dfs/scratch0/maxlam/local_software/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/dfs/scratch0/maxlam/env3.6/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/dfs/scratch0/maxlam/env3.6/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/dfs/scratch0/maxlam/env3.6/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/dfs/scratch0/maxlam/env3.6/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/dfs/scratch0/maxlam/local_software/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/dfs/scratch0/maxlam/local_software/lib/python3.6/asyncio/base_events.py\", line 1426, in _run_once\n",
      "    handle._run()\n",
      "  File \"/dfs/scratch0/maxlam/local_software/lib/python3.6/asyncio/events.py\", line 127, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/dfs/scratch0/maxlam/env3.6/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/dfs/scratch0/maxlam/env3.6/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/dfs/scratch0/maxlam/env3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/dfs/scratch0/maxlam/env3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/dfs/scratch0/maxlam/env3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/dfs/scratch0/maxlam/env3.6/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/dfs/scratch0/maxlam/env3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/dfs/scratch0/maxlam/env3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/dfs/scratch0/maxlam/env3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/dfs/scratch0/maxlam/env3.6/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/dfs/scratch0/maxlam/env3.6/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/dfs/scratch0/maxlam/env3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/dfs/scratch0/maxlam/env3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/dfs/scratch0/maxlam/env3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/dfs/scratch0/maxlam/env3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-0bcf71c7dfbe>\", line 4, in <module>\n",
      "    get_ipython().run_line_magic('matplotlib', 'inline')\n",
      "  File \"/dfs/scratch0/maxlam/env3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2131, in run_line_magic\n",
      "    result = fn(*args,**kwargs)\n",
      "  File \"<decorator-gen-107>\", line 2, in matplotlib\n",
      "  File \"/dfs/scratch0/maxlam/env3.6/lib/python3.6/site-packages/IPython/core/magic.py\", line 187, in <lambda>\n",
      "    call = lambda f, *a, **k: f(*a, **k)\n",
      "  File \"/dfs/scratch0/maxlam/env3.6/lib/python3.6/site-packages/IPython/core/magics/pylab.py\", line 99, in matplotlib\n",
      "    gui, backend = self.shell.enable_matplotlib(args.gui)\n",
      "  File \"/dfs/scratch0/maxlam/env3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3049, in enable_matplotlib\n",
      "    pt.activate_matplotlib(backend)\n",
      "  File \"/dfs/scratch0/maxlam/env3.6/lib/python3.6/site-packages/IPython/core/pylabtools.py\", line 311, in activate_matplotlib\n",
      "    matplotlib.pyplot.switch_backend(backend)\n",
      "  File \"/dfs/scratch0/maxlam/env3.6/lib/python3.6/site-packages/matplotlib/pyplot.py\", line 231, in switch_backend\n",
      "    matplotlib.use(newbackend, warn=False, force=True)\n",
      "  File \"/dfs/scratch0/maxlam/env3.6/lib/python3.6/site-packages/matplotlib/__init__.py\", line 1410, in use\n",
      "    reload(sys.modules['matplotlib.backends'])\n",
      "  File \"/dfs/scratch0/maxlam/local_software/lib/python3.6/importlib/__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"/dfs/scratch0/maxlam/env3.6/lib/python3.6/site-packages/matplotlib/backends/__init__.py\", line 16, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "  matplotlib.use(\"TkAgg\")\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import metal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Problem and Loading the Data\n",
    "\n",
    "First let's set up our problem and load our data. For the purposes of this tutorial (and to keep the search process short) we will use the small model introduced in the basic tutorial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load basic tutorial data\n",
    "from metal.utils import split_data\n",
    "import pickle\n",
    "\n",
    "with open(\"data/basics_tutorial.pkl\", 'rb') as f:\n",
    "    X, Y, L, D = pickle.load(f)\n",
    "    \n",
    "Xs, Ys, Ls, Ds = split_data(X, Y, L, D, splits=[0.8, 0.1, 0.1], stratify_by=Y, seed=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define and train our label model like in the basic tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing O...\n",
      "Estimating \\mu...\n",
      "[E:0]\tTrain Loss: 6.036\n",
      "[E:250]\tTrain Loss: 0.029\n",
      "[E:500]\tTrain Loss: 0.029\n",
      "[E:750]\tTrain Loss: 0.029\n",
      "[E:999]\tTrain Loss: 0.029\n",
      "Finished Training\n",
      "Accuracy: 0.879\n",
      "Precision: 0.771\n",
      "Recall: 0.724\n",
      "F1: 0.746\n",
      "Accuracy: 0.836\n",
      "Precision: 0.623\n",
      "Recall: 0.841\n",
      "F1: 0.716\n"
     ]
    }
   ],
   "source": [
    "# Train a the label model\n",
    "from metal.label_model import LabelModel\n",
    "label_model = LabelModel(k=2, seed=123)\n",
    "\n",
    "label_model.train(Ls[0], Y_dev=Ys[1], n_epochs=1000, print_every=250, lr=0.01, l2=1e-1)\n",
    "score = label_model.score(Ls[1], Ys[1])\n",
    "scores = label_model.score(Ls[1], Ys[1], metric=['precision', 'recall', 'f1'])\n",
    "\n",
    "from metal.label_model.baselines import MajorityLabelVoter\n",
    "\n",
    "mv = MajorityLabelVoter(seed=123)\n",
    "scores = mv.score(Ls[1], Ys[1], metric=['accuracy', 'precision', 'recall', 'f1'])\n",
    "Y_train_ps = label_model.predict_proba(Ls[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define our EndModel and verify that it successfully runs and achieves a decent score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.5)\n",
      "  )\n",
      "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "Saving model at iteration 0 with best score 0.761\n",
      "[E:0]\tTrain Loss: 0.561\tDev score: 0.761\n",
      "Saving model at iteration 1 with best score 0.902\n",
      "[E:1]\tTrain Loss: 0.468\tDev score: 0.902\n",
      "[E:2]\tTrain Loss: 0.458\tDev score: 0.840\n",
      "[E:3]\tTrain Loss: 0.451\tDev score: 0.870\n",
      "[E:4]\tTrain Loss: 0.450\tDev score: 0.818\n",
      "Restoring best model from iteration 1 with score 0.902\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    202     0    \n",
      " l=2    44     754   \n"
     ]
    }
   ],
   "source": [
    "# Train an end model\n",
    "from metal.end_model import EndModel\n",
    "\n",
    "end_model_basic = EndModel([1000,10,2], \n",
    "                     batchnorm=True,\n",
    "                     dropout=.5,\n",
    "                     l2=.1,\n",
    "                     \n",
    "                     seed=123)\n",
    "\n",
    "end_model_basic.train(Xs[0], Y_train_ps, Xs[1], Ys[1], l2=0.1, batch_size=256, \n",
    "                n_epochs=5, print_every=1, validation_metric='f1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. Notice that our F1 is around .902. In the sections below we will try to optimize the hyperparameters of this EndModel to achieve an even higher score!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Search Space\n",
    "\n",
    "Before starting the hyperparameter tuning process, we need to specify the space of the hyperparameters we're searching. \n",
    "\n",
    "For the purposes of this tutorial we search over the following hyperparameters:\n",
    "- <b>n_epochs</b>: Integer representing the number of epochs to train\n",
    "- <b>batchnorm</b>: Boolean representing whether to use batch-normalization\n",
    "- <b>lr</b>: Float representing the learning rate for optimization\n",
    "- <b>layer_out_dims</b>: The architecture of our neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    'n_epochs': [1, 5, 10],\n",
    "    'batchnorm' : [True, False],\n",
    "    'dropout': [0, .1, .2, .3, .4, .5],\n",
    "    'lr': {'range': [1e-5, 1], 'scale': 'log'},\n",
    "    'layer_out_dims' : [[1000,10,2], [1000, 100, 2]],\n",
    "    'print_every': 5,\n",
    "    'data_loader_config': [{\"batch_size\": 256, \"num_workers\": 1}],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a breakdown of what each line in the configuration means:\n",
    "\n",
    "- `'n_epochs': [1, 5, 10],`: This specifies that the hyperparameter tuner may train the model for either 1, 5 or 10 epochs\n",
    "- `'batchnorm' : [True, False],`: This specifies that a model instantiated by the tuner may have batchnorm as either True or False\n",
    "- `dropout': [0, .1, .2, .3, .4, .5]`: Like the above, this specifies that the dropout parameter of an instantiated model may be one of 0, .1, .2, .3, .4, or .5\n",
    "- `'lr': {'range': [1e-5, 1], 'scale': 'log'}`: This specifies that the learning rate of the training of a model may range from 1e-5 to 1, and that the tuner samples the learning rate on a log scale\n",
    "- `'layer_out_dims' : [[1000,10,2], [1000, 100, 2]]`: This specifies that upon instantiation of the model, the structure of the fully connected network can either be [1000, 10, 2] or [1000, 100, 2]; in the latter case, this means the network takes a 1000 dimensional input, has a hidden layer with 100 features and an output layer with 2 classes\n",
    "- `'print_every': 5`: This specifies that the model should print status updates every 5 iterations of training.\n",
    "- `'data_loader_config': [{\"batch_size\": 256, \"num_workers\": 1}],`: This specifies to use a batch of 256 for optimization\n",
    "\n",
    "Now that our search space is defined, let's start optimizing hyperparameters!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing Random Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While simple, random search has proven to be a powerful and efficient algorithm for tuning hyperparameters (see http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf for why). Let's use the RandomSearch tuner to find a good set of hyperparameters for our EndModel. Note that although we only do hyperparameter optimization for the EndModel, the tuners may also be used to do hyperparameter optimization for LabelModels.\n",
    "\n",
    "To start, let's import the RandomSearchTuner and instantiate our RandomSearchTuner to optimize an EndModel model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metal.tuners.random_tuner import RandomSearchTuner\n",
    "rs_tuner = RandomSearchTuner(EndModel, seed=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's define our training and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_args = [Xs[0], Y_train_ps]\n",
    "X_dev, Y_dev = Xs[1], Ys[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And just like that we're prepped to launch our random search! Performing the search is just as easy and requires just a single call to the `search` function.\n",
    "\n",
    "Most of the arguments to the `search` function below are self explanatory, but there are a couple of key arguments to watch out for:\n",
    "- `max_search` : This specifies the number of configurations to search over. As it is set to 20 below, this means we search over 20 random models and return the best one\n",
    "- `verbose`: This specifies whether the tuner should be verbose or not and can be used to turn on/off the its logging feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.4)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[1] Testing {'n_epochs': 10, 'batchnorm': True, 'dropout': 0.4, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 4.624229978283888e-05}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.646\n",
      "[E:0]\tTrain Loss: 0.697\tDev score: 0.646\n",
      "Saving model at iteration 1 with best score 0.725\n",
      "Saving model at iteration 2 with best score 0.791\n",
      "Saving model at iteration 3 with best score 0.825\n",
      "Saving model at iteration 4 with best score 0.847\n",
      "Saving model at iteration 5 with best score 0.885\n",
      "[E:5]\tTrain Loss: 0.594\tDev score: 0.885\n",
      "Saving model at iteration 6 with best score 0.886\n",
      "Saving model at iteration 7 with best score 0.895\n",
      "Saving model at iteration 8 with best score 0.920\n",
      "[E:9]\tTrain Loss: 0.565\tDev score: 0.913\n",
      "Restoring best model from iteration 8 with score 0.920\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    242    88    \n",
      " l=2     4     666   \n",
      "F1: 0.841\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2)\n",
      "  )\n",
      "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[2] Testing {'n_epochs': 5, 'batchnorm': False, 'dropout': 0.2, 'layer_out_dims': [1000, 10, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 1.827334249624349e-05}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.748\n",
      "[E:0]\tTrain Loss: 0.663\tDev score: 0.748\n",
      "Saving model at iteration 1 with best score 0.752\n",
      "Saving model at iteration 3 with best score 0.754\n",
      "[E:4]\tTrain Loss: 0.649\tDev score: 0.754\n",
      "Restoring best model from iteration 3 with score 0.754\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1     0      0    \n",
      " l=2    246    754   \n",
      "F1: 0.008\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.1)\n",
      "  )\n",
      "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[3] Testing {'n_epochs': 1, 'batchnorm': False, 'dropout': 0.1, 'layer_out_dims': [1000, 10, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.6366544570068935}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.756\n",
      "[E:0]\tTrain Loss: 1.446\tDev score: 0.756\n",
      "Restoring best model from iteration 0 with score 0.756\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1     2      0    \n",
      " l=2    244    754   \n",
      "F1: 0.016\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.1)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[4] Testing {'n_epochs': 10, 'batchnorm': False, 'dropout': 0.1, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.31643979593790955}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.754\n",
      "[E:0]\tTrain Loss: 3.022\tDev score: 0.754\n",
      "[E:5]\tTrain Loss: 0.585\tDev score: 0.754\n",
      "[E:9]\tTrain Loss: 0.576\tDev score: 0.754\n",
      "Restoring best model from iteration 0 with score 0.754\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1     0      0    \n",
      " l=2    246    754   \n",
      "F1: 0.000\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[5] Testing {'n_epochs': 1, 'batchnorm': False, 'dropout': 0.3, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.007292621889903268}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.980\n",
      "[E:0]\tTrain Loss: 0.488\tDev score: 0.980\n",
      "Restoring best model from iteration 0 with score 0.980\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    222     0    \n",
      " l=2    24     754   \n",
      "F1: 0.951\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.4)\n",
      "  )\n",
      "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[6] Testing {'n_epochs': 5, 'batchnorm': True, 'dropout': 0.4, 'layer_out_dims': [1000, 10, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 1.670624993426239e-05}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.582\n",
      "[E:0]\tTrain Loss: 0.660\tDev score: 0.582\n",
      "Saving model at iteration 1 with best score 0.647\n",
      "Saving model at iteration 2 with best score 0.662\n",
      "Saving model at iteration 3 with best score 0.667\n",
      "Saving model at iteration 4 with best score 0.698\n",
      "[E:4]\tTrain Loss: 0.637\tDev score: 0.698\n",
      "Restoring best model from iteration 4 with score 0.698\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    123    211   \n",
      " l=2    123    543   \n",
      "F1: 0.404\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.1)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[7] Testing {'n_epochs': 10, 'batchnorm': True, 'dropout': 0.1, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.5013839780330771}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.912\n",
      "[E:0]\tTrain Loss: 4.209\tDev score: 0.912\n",
      "Saving model at iteration 2 with best score 0.948\n",
      "[E:5]\tTrain Loss: 0.438\tDev score: 0.866\n",
      "[E:9]\tTrain Loss: 0.388\tDev score: 0.925\n",
      "Restoring best model from iteration 2 with score 0.948\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    203     9    \n",
      " l=2    43     745   \n",
      "F1: 0.894\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.5)\n",
      "  )\n",
      "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[8] Testing {'n_epochs': 10, 'batchnorm': True, 'dropout': 0.5, 'layer_out_dims': [1000, 10, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.008520966193723056}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.950\n",
      "[E:0]\tTrain Loss: 0.594\tDev score: 0.950\n",
      "[E:5]\tTrain Loss: 0.443\tDev score: 0.916\n",
      "[E:9]\tTrain Loss: 0.433\tDev score: 0.922\n",
      "Restoring best model from iteration 0 with score 0.950\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    197     2    \n",
      " l=2    49     752   \n",
      "F1: 0.893\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.5)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[9] Testing {'n_epochs': 10, 'batchnorm': True, 'dropout': 0.5, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.003970906941573151}\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model at iteration 0 with best score 0.929\n",
      "[E:0]\tTrain Loss: 0.527\tDev score: 0.929\n",
      "Saving model at iteration 1 with best score 0.959\n",
      "[E:5]\tTrain Loss: 0.377\tDev score: 0.916\n",
      "[E:9]\tTrain Loss: 0.351\tDev score: 0.930\n",
      "Restoring best model from iteration 1 with score 0.959\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    202     1    \n",
      " l=2    44     753   \n",
      "F1: 0.928\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[10] Testing {'n_epochs': 10, 'batchnorm': False, 'dropout': 0, 'layer_out_dims': [1000, 10, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.0003777251862528499}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.768\n",
      "[E:0]\tTrain Loss: 0.689\tDev score: 0.768\n",
      "Saving model at iteration 2 with best score 0.775\n",
      "Saving model at iteration 3 with best score 0.877\n",
      "Saving model at iteration 4 with best score 0.944\n",
      "Saving model at iteration 5 with best score 0.966\n",
      "[E:5]\tTrain Loss: 0.460\tDev score: 0.966\n",
      "Saving model at iteration 6 with best score 0.972\n",
      "Saving model at iteration 7 with best score 0.974\n",
      "Saving model at iteration 8 with best score 0.977\n",
      "[E:9]\tTrain Loss: 0.448\tDev score: 0.977\n",
      "Restoring best model from iteration 8 with score 0.977\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    223     0    \n",
      " l=2    23     754   \n",
      "F1: 0.951\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.2)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[11] Testing {'n_epochs': 5, 'batchnorm': True, 'dropout': 0.2, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.0011538361363759827}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.987\n",
      "[E:0]\tTrain Loss: 0.583\tDev score: 0.987\n",
      "[E:4]\tTrain Loss: 0.337\tDev score: 0.919\n",
      "Restoring best model from iteration 0 with score 0.987\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    242    10    \n",
      " l=2     4     744   \n",
      "F1: 0.976\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[12] Testing {'n_epochs': 5, 'batchnorm': False, 'dropout': 0.5, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.002945528656127802}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.996\n",
      "[E:0]\tTrain Loss: 0.497\tDev score: 0.996\n",
      "[E:4]\tTrain Loss: 0.424\tDev score: 0.946\n",
      "Restoring best model from iteration 0 with score 0.996\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    246     1    \n",
      " l=2     0     753   \n",
      "F1: 0.996\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[13] Testing {'n_epochs': 5, 'batchnorm': False, 'dropout': 0, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.0026338666324303645}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.996\n",
      "[E:0]\tTrain Loss: 0.493\tDev score: 0.996\n",
      "[E:4]\tTrain Loss: 0.401\tDev score: 0.927\n",
      "Restoring best model from iteration 0 with score 0.996\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    243     1    \n",
      " l=2     3     753   \n",
      "F1: 0.992\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.1)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[14] Testing {'n_epochs': 5, 'batchnorm': True, 'dropout': 0.1, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.022267690733296888}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.900\n",
      "[E:0]\tTrain Loss: 0.500\tDev score: 0.900\n",
      "Saving model at iteration 1 with best score 0.921\n",
      "Saving model at iteration 2 with best score 0.938\n",
      "[E:4]\tTrain Loss: 0.374\tDev score: 0.898\n",
      "Restoring best model from iteration 2 with score 0.938\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    184     6    \n",
      " l=2    62     748   \n",
      "F1: 0.838\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.3)\n",
      "  )\n",
      "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[15] Testing {'n_epochs': 10, 'batchnorm': True, 'dropout': 0.3, 'layer_out_dims': [1000, 10, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.007561031383400367}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.927\n",
      "[E:0]\tTrain Loss: 0.504\tDev score: 0.927\n",
      "Saving model at iteration 1 with best score 0.943\n",
      "[E:5]\tTrain Loss: 0.421\tDev score: 0.924\n",
      "[E:9]\tTrain Loss: 0.404\tDev score: 0.903\n",
      "Restoring best model from iteration 1 with score 0.943\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    177     0    \n",
      " l=2    69     754   \n",
      "F1: 0.829\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3)\n",
      "  )\n",
      "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[16] Testing {'n_epochs': 10, 'batchnorm': False, 'dropout': 0.3, 'layer_out_dims': [1000, 10, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 2.3005563286765607e-05}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.439\n",
      "[E:0]\tTrain Loss: 0.708\tDev score: 0.439\n",
      "Saving model at iteration 1 with best score 0.510\n",
      "Saving model at iteration 2 with best score 0.582\n",
      "Saving model at iteration 3 with best score 0.654\n",
      "Saving model at iteration 4 with best score 0.689\n",
      "Saving model at iteration 5 with best score 0.708\n",
      "[E:5]\tTrain Loss: 0.663\tDev score: 0.708\n",
      "Saving model at iteration 6 with best score 0.726\n",
      "Saving model at iteration 7 with best score 0.753\n",
      "Saving model at iteration 9 with best score 0.771\n",
      "[E:9]\tTrain Loss: 0.631\tDev score: 0.771\n",
      "Restoring best model from iteration 9 with score 0.771\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    47     33    \n",
      " l=2    199    721   \n",
      "F1: 0.212\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.3)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[17] Testing {'n_epochs': 5, 'batchnorm': True, 'dropout': 0.3, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 9.272176167778152e-05}\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model at iteration 0 with best score 0.769\n",
      "[E:0]\tTrain Loss: 0.665\tDev score: 0.769\n",
      "Saving model at iteration 1 with best score 0.876\n",
      "Saving model at iteration 2 with best score 0.925\n",
      "Saving model at iteration 3 with best score 0.934\n",
      "Saving model at iteration 4 with best score 0.956\n",
      "[E:4]\tTrain Loss: 0.552\tDev score: 0.956\n",
      "Restoring best model from iteration 4 with score 0.956\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    239    38    \n",
      " l=2     7     716   \n",
      "F1: 0.900\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.4)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[18] Testing {'n_epochs': 1, 'batchnorm': True, 'dropout': 0.4, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 1.0175385317479292e-05}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.508\n",
      "[E:0]\tTrain Loss: 0.773\tDev score: 0.508\n",
      "Restoring best model from iteration 0 with score 0.508\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    171    430   \n",
      " l=2    75     324   \n",
      "F1: 0.380\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.1)\n",
      "  )\n",
      "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[19] Testing {'n_epochs': 5, 'batchnorm': True, 'dropout': 0.1, 'layer_out_dims': [1000, 10, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.07210322639680222}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.974\n",
      "[E:0]\tTrain Loss: 0.485\tDev score: 0.974\n",
      "[E:4]\tTrain Loss: 0.429\tDev score: 0.930\n",
      "Restoring best model from iteration 0 with score 0.974\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    215     1    \n",
      " l=2    31     753   \n",
      "F1: 0.921\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[20] Testing {'n_epochs': 1, 'batchnorm': True, 'dropout': 0, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.003860152812810654}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.932\n",
      "[E:0]\tTrain Loss: 0.549\tDev score: 0.932\n",
      "Restoring best model from iteration 0 with score 0.932\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    178     0    \n",
      " l=2    68     754   \n",
      "F1: 0.840\n",
      "============================================================\n",
      "[SUMMARY]\n",
      "Best model: [12]\n",
      "Best config: {'n_epochs': 5, 'batchnorm': False, 'dropout': 0.5, 'layer_out_dims': [1000, 100, 2], 'print_every': 5, 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.002945528656127802, 'seed': 134}\n",
      "Best score: 0.9959349593495935\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "best_rs_model = rs_tuner.search(search_space, X_dev, Y_dev, train_args=train_args, max_search=20, metric='f1', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome, our best random search model achieves an F1 of ~.996 which outperforms the model we had previously (F1 ~ .90). Can we do even better than random search by either attaining the same accuracy faster or achieving a higher score? The following section walks through using the <b>Hyperband</b> tuner, which recent research has shown to be more efficient than random search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing Hyperband Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While random search performs surprisingly well, we can be more efficient if we adaptively allocate more compute resources for configurations that perform well than to those that don't. For example if a configuration seems to yield a really poor model after the first epoch of training, it's unlikely it'll perform well even after more training, so we can early-terminate the training of this configuration to save compute. This is the core idea behind the <b>Hyperband</b> algorithm which recent research has shown to outperform various algorithms including random search. (See https://arxiv.org/abs/1603.06560 if interested!)\n",
    "\n",
    "Running Hyperband is just as easy as running random search. Let's import the HyperbandTuner and instantiate it. \n",
    "\n",
    "Note that there is one extra argument to initialize the HyperbandTuner:\n",
    "- `hyperband_epochs_budget`: This specifies the number of total epochs of training the tuner can perform in its search for a performant model. This is used to create the Hyperband search schedule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================\n",
      "|           Hyperband Schedule          |\n",
      "=========================================\n",
      "Table consists of tuples of (num configs, num_resources_per_config)which specify how many configs to run andfor how many epochs. \n",
      "Each bracket starts with a list of random configurations which is successively halved according the schedule.\n",
      "See the Hyperband paper (https://arxiv.org/pdf/1603.06560.pdf) for more details.\n",
      "-----------------------------------------\n",
      "Bracket 0: (9, 2) (3, 8) (1, 26)\n",
      "Bracket 1: (3, 8) (1, 26)\n",
      "Bracket 2: (3, 26)\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from metal.tuners.hyperband_tuner import HyperbandTuner\n",
    "hb_tuner = HyperbandTuner(EndModel, hyperband_epochs_budget=200, seed=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can launch the Hyperband search process using the same `search` call. Note that since the Hyperband schedule already limits the amount of compute we do, we don't have to set the `max_search` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[0 Testing {'n_epochs': 2, 'batchnorm': False, 'dropout': 0, 'layer_out_dims': [1000, 10, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.3700237151852522}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.754\n",
      "[E:0]\tTrain Loss: 0.994\tDev score: 0.754\n",
      "[E:1]\tTrain Loss: 0.578\tDev score: 0.754\n",
      "Restoring best model from iteration 0 with score 0.754\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1     0      0    \n",
      " l=2    246    754   \n",
      "F1: 0.000\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.1)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[1 Testing {'n_epochs': 2, 'batchnorm': False, 'dropout': 0.1, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.019515100267567337}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.979\n",
      "[E:0]\tTrain Loss: 0.499\tDev score: 0.979\n",
      "[E:1]\tTrain Loss: 0.458\tDev score: 0.978\n",
      "Restoring best model from iteration 0 with score 0.979\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    224     1    \n",
      " l=2    22     753   \n",
      "F1: 0.956\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.4)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[2 Testing {'n_epochs': 2, 'batchnorm': False, 'dropout': 0.4, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 7.089807415516936e-05}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.766\n",
      "[E:0]\tTrain Loss: 0.696\tDev score: 0.766\n",
      "[E:1]\tTrain Loss: 0.641\tDev score: 0.757\n",
      "Restoring best model from iteration 0 with score 0.766\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    86     87    \n",
      " l=2    160    667   \n",
      "F1: 0.355\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.2)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[3 Testing {'n_epochs': 2, 'batchnorm': True, 'dropout': 0.2, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.0004837052086066461}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.965\n",
      "[E:0]\tTrain Loss: 0.593\tDev score: 0.965\n",
      "Saving model at iteration 1 with best score 0.975\n",
      "[E:1]\tTrain Loss: 0.522\tDev score: 0.975\n",
      "Restoring best model from iteration 1 with score 0.975\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    242    20    \n",
      " l=2     4     734   \n",
      "F1: 0.951\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[4 Testing {'n_epochs': 2, 'batchnorm': False, 'dropout': 0.2, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.000903579845523744}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.937\n",
      "[E:0]\tTrain Loss: 0.537\tDev score: 0.937\n",
      "Saving model at iteration 1 with best score 0.991\n",
      "[E:1]\tTrain Loss: 0.458\tDev score: 0.991\n",
      "Restoring best model from iteration 1 with score 0.991\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    239     1    \n",
      " l=2     7     753   \n",
      "F1: 0.988\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.4)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[5 Testing {'n_epochs': 2, 'batchnorm': False, 'dropout': 0.4, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 2.3251656081342196e-05}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.744\n",
      "[E:0]\tTrain Loss: 0.678\tDev score: 0.744\n",
      "Saving model at iteration 1 with best score 0.761\n",
      "[E:1]\tTrain Loss: 0.663\tDev score: 0.761\n",
      "Restoring best model from iteration 1 with score 0.761\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    10     10    \n",
      " l=2    236    744   \n",
      "F1: 0.098\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2)\n",
      "  )\n",
      "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[6 Testing {'n_epochs': 2, 'batchnorm': False, 'dropout': 0.2, 'layer_out_dims': [1000, 10, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.0019223627877981123}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.798\n",
      "[E:0]\tTrain Loss: 0.573\tDev score: 0.798\n",
      "Saving model at iteration 1 with best score 0.971\n",
      "[E:1]\tTrain Loss: 0.473\tDev score: 0.971\n",
      "Restoring best model from iteration 1 with score 0.971\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    205     0    \n",
      " l=2    41     754   \n",
      "F1: 0.933\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[7 Testing {'n_epochs': 2, 'batchnorm': False, 'dropout': 0.5, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.007342476624077729}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.972\n",
      "[E:0]\tTrain Loss: 0.495\tDev score: 0.972\n",
      "[E:1]\tTrain Loss: 0.457\tDev score: 0.966\n",
      "Restoring best model from iteration 0 with score 0.972\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    224     1    \n",
      " l=2    22     753   \n",
      "F1: 0.944\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.1)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[8 Testing {'n_epochs': 2, 'batchnorm': False, 'dropout': 0.1, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.00047921510264231735}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.757\n",
      "[E:0]\tTrain Loss: 0.562\tDev score: 0.757\n",
      "Saving model at iteration 1 with best score 0.984\n",
      "[E:1]\tTrain Loss: 0.471\tDev score: 0.984\n",
      "Restoring best model from iteration 1 with score 0.984\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    230     0    \n",
      " l=2    16     754   \n",
      "F1: 0.962\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[9 Testing {'n_epochs': 8, 'batchnorm': False, 'dropout': 0.2, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.000903579845523744}\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model at iteration 0 with best score 0.937\n",
      "[E:0]\tTrain Loss: 0.537\tDev score: 0.937\n",
      "Saving model at iteration 1 with best score 0.991\n",
      "[E:5]\tTrain Loss: 0.426\tDev score: 0.957\n",
      "[E:7]\tTrain Loss: 0.410\tDev score: 0.957\n",
      "Restoring best model from iteration 1 with score 0.991\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    237     1    \n",
      " l=2     9     753   \n",
      "F1: 0.984\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.1)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[10 Testing {'n_epochs': 8, 'batchnorm': False, 'dropout': 0.1, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.00047921510264231735}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.757\n",
      "[E:0]\tTrain Loss: 0.562\tDev score: 0.757\n",
      "Saving model at iteration 1 with best score 0.984\n",
      "[E:5]\tTrain Loss: 0.437\tDev score: 0.973\n",
      "[E:7]\tTrain Loss: 0.428\tDev score: 0.959\n",
      "Restoring best model from iteration 1 with score 0.984\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    229     0    \n",
      " l=2    17     754   \n",
      "F1: 0.966\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.1)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[11 Testing {'n_epochs': 8, 'batchnorm': False, 'dropout': 0.1, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.019515100267567337}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.979\n",
      "[E:0]\tTrain Loss: 0.499\tDev score: 0.979\n",
      "[E:5]\tTrain Loss: 0.394\tDev score: 0.953\n",
      "[E:7]\tTrain Loss: 0.378\tDev score: 0.926\n",
      "Restoring best model from iteration 0 with score 0.979\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    225     0    \n",
      " l=2    21     754   \n",
      "F1: 0.958\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[12 Testing {'n_epochs': 26, 'batchnorm': False, 'dropout': 0.2, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.000903579845523744}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.937\n",
      "[E:0]\tTrain Loss: 0.537\tDev score: 0.937\n",
      "Saving model at iteration 1 with best score 0.991\n",
      "[E:5]\tTrain Loss: 0.426\tDev score: 0.957\n",
      "[E:10]\tTrain Loss: 0.380\tDev score: 0.942\n",
      "[E:15]\tTrain Loss: 0.343\tDev score: 0.947\n",
      "[E:20]\tTrain Loss: 0.327\tDev score: 0.928\n",
      "[E:25]\tTrain Loss: 0.320\tDev score: 0.933\n",
      "Restoring best model from iteration 1 with score 0.991\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    235     1    \n",
      " l=2    11     753   \n",
      "F1: 0.986\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.1)\n",
      "  )\n",
      "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[13 Testing {'n_epochs': 8, 'batchnorm': True, 'dropout': 0.1, 'layer_out_dims': [1000, 10, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.0012901865145961697}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.991\n",
      "[E:0]\tTrain Loss: 0.534\tDev score: 0.991\n",
      "[E:5]\tTrain Loss: 0.401\tDev score: 0.903\n",
      "[E:7]\tTrain Loss: 0.381\tDev score: 0.896\n",
      "Restoring best model from iteration 0 with score 0.991\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    237     1    \n",
      " l=2     9     753   \n",
      "F1: 0.977\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[14 Testing {'n_epochs': 8, 'batchnorm': False, 'dropout': 0, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.0014465786197803271}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.997\n",
      "[E:0]\tTrain Loss: 0.506\tDev score: 0.997\n",
      "[E:5]\tTrain Loss: 0.410\tDev score: 0.956\n",
      "[E:7]\tTrain Loss: 0.384\tDev score: 0.947\n",
      "Restoring best model from iteration 0 with score 0.997\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    244     1    \n",
      " l=2     2     753   \n",
      "F1: 0.994\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[15 Testing {'n_epochs': 8, 'batchnorm': False, 'dropout': 0.2, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.007585836552838511}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.974\n",
      "[E:0]\tTrain Loss: 0.489\tDev score: 0.974\n",
      "[E:5]\tTrain Loss: 0.375\tDev score: 0.912\n",
      "[E:7]\tTrain Loss: 0.355\tDev score: 0.895\n",
      "Restoring best model from iteration 0 with score 0.974\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    222     0    \n",
      " l=2    24     754   \n",
      "F1: 0.951\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[16 Testing {'n_epochs': 26, 'batchnorm': False, 'dropout': 0, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.0014465786197803271}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.997\n",
      "[E:0]\tTrain Loss: 0.506\tDev score: 0.997\n",
      "[E:5]\tTrain Loss: 0.410\tDev score: 0.956\n",
      "[E:10]\tTrain Loss: 0.344\tDev score: 0.931\n",
      "[E:15]\tTrain Loss: 0.311\tDev score: 0.922\n",
      "[E:20]\tTrain Loss: 0.307\tDev score: 0.918\n",
      "[E:25]\tTrain Loss: 0.303\tDev score: 0.908\n",
      "Restoring best model from iteration 0 with score 0.997\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    244     1    \n",
      " l=2     2     753   \n",
      "F1: 0.994\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[17 Testing {'n_epochs': 26, 'batchnorm': False, 'dropout': 0, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 4.6632716175331675e-05}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.754\n",
      "[E:0]\tTrain Loss: 0.662\tDev score: 0.754\n",
      "[E:5]\tTrain Loss: 0.526\tDev score: 0.754\n",
      "Saving model at iteration 6 with best score 0.755\n",
      "Saving model at iteration 7 with best score 0.770\n",
      "Saving model at iteration 8 with best score 0.806\n",
      "Saving model at iteration 9 with best score 0.850\n",
      "Saving model at iteration 10 with best score 0.889\n",
      "[E:10]\tTrain Loss: 0.475\tDev score: 0.889\n",
      "Saving model at iteration 11 with best score 0.922\n",
      "Saving model at iteration 12 with best score 0.942\n",
      "Saving model at iteration 13 with best score 0.957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model at iteration 14 with best score 0.963\n",
      "Saving model at iteration 15 with best score 0.972\n",
      "[E:15]\tTrain Loss: 0.455\tDev score: 0.972\n",
      "Saving model at iteration 16 with best score 0.977\n",
      "Saving model at iteration 18 with best score 0.978\n",
      "Saving model at iteration 19 with best score 0.980\n",
      "Saving model at iteration 20 with best score 0.981\n",
      "[E:20]\tTrain Loss: 0.450\tDev score: 0.981\n",
      "Saving model at iteration 22 with best score 0.982\n",
      "[E:25]\tTrain Loss: 0.446\tDev score: 0.982\n",
      "Restoring best model from iteration 22 with score 0.982\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    228     0    \n",
      " l=2    18     754   \n",
      "F1: 0.962\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.3)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[18 Testing {'n_epochs': 26, 'batchnorm': True, 'dropout': 0.3, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.05250533013212389}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.986\n",
      "[E:0]\tTrain Loss: 0.513\tDev score: 0.986\n",
      "[E:5]\tTrain Loss: 0.405\tDev score: 0.925\n",
      "[E:10]\tTrain Loss: 0.357\tDev score: 0.903\n",
      "[E:15]\tTrain Loss: 0.339\tDev score: 0.903\n",
      "[E:20]\tTrain Loss: 0.331\tDev score: 0.913\n",
      "[E:25]\tTrain Loss: 0.321\tDev score: 0.926\n",
      "Restoring best model from iteration 0 with score 0.986\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    226     0    \n",
      " l=2    20     754   \n",
      "F1: 0.969\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.2)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[19 Testing {'n_epochs': 26, 'batchnorm': True, 'dropout': 0.2, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.14487792589370782}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.908\n",
      "[E:0]\tTrain Loss: 0.971\tDev score: 0.908\n",
      "Saving model at iteration 1 with best score 0.953\n",
      "[E:5]\tTrain Loss: 0.402\tDev score: 0.906\n",
      "[E:10]\tTrain Loss: 0.352\tDev score: 0.931\n",
      "[E:15]\tTrain Loss: 0.339\tDev score: 0.926\n",
      "[E:20]\tTrain Loss: 0.333\tDev score: 0.874\n",
      "[E:25]\tTrain Loss: 0.338\tDev score: 0.925\n",
      "Restoring best model from iteration 1 with score 0.953\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    211     5    \n",
      " l=2    35     749   \n",
      "F1: 0.918\n",
      "============================================================\n",
      "[SUMMARY]\n",
      "Best model: [14]\n",
      "Best config: {'n_epochs': 26, 'batchnorm': False, 'dropout': 0, 'layer_out_dims': [1000, 100, 2], 'print_every': 5, 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.0014465786197803271, 'seed': 137}\n",
      "Best score: 0.9938900203665988\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "best_hb_model = hb_tuner.search(search_space, X_dev, Y_dev, train_args=train_args, metric='f1', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome, we achieved an F1 ~.994, which beat our initial score of F1 ~.90 and essentially matches the score achieved by random search (F1 ~.996). The next section will compare the performances of random search and Hyperband using the logged data -- and investigate when to use which algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Random Search against Hyperband Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During `search`, MeTaL hyperparameter tuners track useful statistics. Currently these include\n",
    "* Time elapsed\n",
    "* Best score\n",
    "* Best configuration\n",
    "\n",
    "We will analyze these statistics to compare random search against Hyperband. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's extract the statistics captured by our tuners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "hb_stats = hb_tuner.get_run_stats()\n",
    "rs_stats = rs_tuner.get_run_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at a few of the collected datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'time_elapsed': 1.9016749858856201,\n",
       "  'best_score': 0,\n",
       "  'best_config': {'n_epochs': 2,\n",
       "   'batchnorm': False,\n",
       "   'dropout': 0,\n",
       "   'layer_out_dims': [1000, 10, 2],\n",
       "   'print_every': 5,\n",
       "   'data_loader_config': {'batch_size': 256, 'num_workers': 1},\n",
       "   'lr': 0.3700237151852522,\n",
       "   'seed': 123}},\n",
       " {'time_elapsed': 3.67757248878479,\n",
       "  'best_score': 0.9556025369978859,\n",
       "  'best_config': {'n_epochs': 8,\n",
       "   'batchnorm': False,\n",
       "   'dropout': 0.1,\n",
       "   'layer_out_dims': [1000, 100, 2],\n",
       "   'print_every': 5,\n",
       "   'data_loader_config': {'batch_size': 256, 'num_workers': 1},\n",
       "   'lr': 0.019515100267567337,\n",
       "   'seed': 124}},\n",
       " {'time_elapsed': 9.00398874282837,\n",
       "  'best_score': 0.9876543209876543,\n",
       "  'best_config': {'n_epochs': 26,\n",
       "   'batchnorm': False,\n",
       "   'dropout': 0.2,\n",
       "   'layer_out_dims': [1000, 100, 2],\n",
       "   'print_every': 5,\n",
       "   'data_loader_config': {'batch_size': 256, 'num_workers': 1},\n",
       "   'lr': 0.000903579845523744,\n",
       "   'seed': 127}}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hb_stats[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_run_stats` returns a list of datapoints, where each datapoint (captured by a dictionary) specifies the current elapsed timestamp, the best score achieved for that timestamp and the best hyperparameter configuration for the score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data and understand its format, let's compare the performances of random search and hyperband by plotting the best scores they achieve across time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XmcVNWZ//HP001DA7JvEgHBjU1WW8ANURbRKJqMGokaNS6vJBqXzGR+ZnGJozOacZxfNCTzM8Z13DVGRiExEhnHOCogiGwKKirEAIKAYhddXfX8/ri3iurq6u6i6dtd3fV9v6gXddd6aun73HPOveeYuyMiIgJQ0tIBiIhI4VBSEBGRNCUFERFJU1IQEZE0JQUREUlTUhARkTQlBRERSVNSEBGRNCUFERFJa9fSAeyt3r17++DBg1s6DBGRVmXJkiWfunufhtZrdUlh8ODBLF68uKXDEBFpVczsw3zWU/WRiIikKSmIiEiakoKIiKQpKYiISFpkScHM7jWzzWa2oo7lZmZ3mtk6M1tuZuOjikVERPITZUnhfmBmPctPBg4NH5cBv44wFhERyUNkScHdXwa21bPK6cCDHngN6G5m/aOKR0REGtaS9ykcAHycMb0hnPdJ9opmdhlBaYJBgwY1S3AiInvL3XEH37EBlv4nyWGn4n1H4oTznT3PU+sDnqxjvtd83rVjOzq1j/aw3SpuXnP3u4G7ASoqKjSodAPSP0yyflyN/GEmwxm19gMkkx6+Zu1tg0WZ8/askwxjzLXtnmU1t02m31fteJIZfzxkvddkxmeQc59hvJmxJJM1PwNqxF4zXjL2vyfGHPvM+uxT31X2/Mx91txfzfeeTNb+bmvsM+u9ko4/9z4zP6fs95752WfvM/Ozz37v6e1y/eZy/kYzl2Vum2N+rhhz/dZzzSd7We6DcN3b1o6hxBOcULKM2aV/ZkrJMgy4ecEnPJA4Ka+/23zcfMbhnDfpwCbbXy4tmRQ2AgMzpgeE81q1HZVxFr6zmQWrN/PWhu0kkh7ND7OOP47UgUFaPzMoMcPC54YR/gvmh88tXCe9rMRqzLdwYbC/YD+Z29Z4rRz7zI4h3AQzC/aXtU/C9YNlueMvLSkJ5mXtM1cMqfhrvVbGPmvG2HD8liO2GtvWmpe5fs353Xb/jVGb5zJq81z2q9rCrrJeLNn/Ilbtfzq9yw/gH6yefabjyRF/jhiPHNyjyX9n2VoyKcwFrjCzx4CJwA53r1V11Bp8uHUXL67ezIurNrFo/Taqk06vzu2ZeFBPytuV1vvDzPljZ+9/mHlv2wQ/zDrjSc+ra597Dkxkx8ueAxM55lv4OVHHe61rn6mDDDk++8zvJHvbzIMnWe8188CVGU/OA3i43p5tasdT6+CZWkEKVyIO7/4BljwA614M5h0yDY64kM6HncSE0jImtGyEjRZZUjCzR4EpQG8z2wDcAJQBuPt/APOAU4B1wJfARVHF0tQSSWfZx5/xp1WbWbB6E2s3fwHAYf3249LJBzFteF/GDuxBaYn+uEValHtwAE/sDv6v3g2JqpqP6tTzzHVS2+RYXrkdVv0evtgEXb4Ck38I48+H7m2jvTOypODusxtY7sDlUb1+U9u1u5r/WbuFF1dv5s9rNrNtVxXtSowJQ3oye8Igpg3vx6BenVo6TJHml0zUPtjWOLDmOBinl9e1TebBuI595rNNoqrp329pBzj4BDjiQjhkOpS2iqbZvLWtd9PE/rq9kgVrgmqh/31vK1WJJF3L23HCsL5MHd6P4w/rQ7eOZS0dprR17rkPgDkPtrnOeutZntcBvK4z6XCeJ5v2/VoptOsApWXBAbi0PbRrH/yf+SjrCOXd9kw3tE16eftwnbJ6tslcnrmfMmjj1XtKChmSSWfFX3ek2wdWfbITgMG9OvGtow5k6vB+VAzuQVmpegdpU9yDs928zlDrOBtt1ME4z2qLZLzp33ODB87w//ads5bnODhnb5N9IM0+8NZ7MG4PJaVN/34lb0oKwKadMX6xYC0LVm9i087dlBgccWAPrj15GNOG9+PgPp3V+LevkskGzlCb8mCczz6z5tHEl22VtKv/bDM1r31nKO3R8Blq9vK9PhhnLC9p1+bPdqXxlBSAucv+yiOvf8RJI/sxY8T+nDCsLz07t2/psFqeO3yyDFbNhS+31nEwzrMOOVndxMFZwwfOdh2CeR26ZC1vqLogn+X1VTG0hxKVJqV1UlIAdlUFB6xfnXuErhgC2P4RvP0kvPU4fPpOcGbZqXfdRf8OXaBTr/yrExqstshjeUmpznZFIqCkAMTiSdqXlhR3QojtgFXPBongw1eCeYOOglP/HUacAZ16tmx8ItIslBSAWDxBeVkRFverq+C9BfDWY/DO/KDqp+fBcMJPYNRZ0HNIS0coIs1MSYFUUiiSKx7cYeOSIBGseBoqtwVVP0dcAKPPgQPGq1pGpIgpKQCV8QQd27fxpLDtA1j+BCx/HLa9F9TNDzslSASHTA3q60Wk6CkpEJYU2rXBpPDlNlj5TJAMPn4tmDf4ODj2GhgxK7jxR0Qkg5ICUBlPUt5WSgrVu+HdPwYlgrUvBJeD9hkGU28I2gm6D2x4HyJStJQUSJUUWnFDszt89FqQCFY+A7Ht0LkvHHkJjP4G9B+jdgIRyYuSAkFS6NGpFd6s9um6IBEsfxy2fwjtOsLwU4N2goOm0NY66hKR6OmoQZAUOraWq492fQorfgfLHwuuIsLgoONhyo+ChNChS0tHKCKtmJICwc1rBX2fQrwyuI9g+ePBgB7Jauh3OEz/Jxh1JnT9SktHKCJthJICBXpJajIJH/4lKBGsmgu7d0KX/jDpe0E7wf6Ht3SEItIGKSkQVB91KJRLUjevCUoEbz8JOz6G9vvB8Fkw+mwYMlndCotIpJQUCNsUWrKk8Pmm4O7i5Y/BJ28Fg4wcfGJwGemwU4LulUVEmkHRJ4XqRJJ4wpv/5rWqXbBmXpAI3nsJPAH9x8JJ/xK0E+zXt3njERFBSYFYdTCUYMf2zdDQnEzABy8H1UOr/wuqvoBuA+GYq4J2gr7Doo9BRKQeSgrxBEC0HeL9bUVQInj7Kfj8E+jQFUZ+DcacA4OO1oAsIlIwij4pVFZFlBR2/jVoLF7+BGxaEQxUc8h0mPkvcNjMYNBxEZECU/RJYXd1EyaF3Z8H1ULLH4f3/xtwOKACTrk9KBl07r3vryEiEqGiTwqVVWGbQmOTQqIa3n8pbCd4DqorofuBcPw/wqizofchTRitiEi0ij4pxNIlhb2o13cPLh1d/njQTrBrM5R3D9oIxpwDAyeqAzoRaZWKPinsdZvCxiXw++/BljVQUgaHnRQkgkNnBIPLi4i0YkWfFFJXH+VdfdR1AHTsqQHtRaRNKvqkUBnfy+qjLv3g2/MjjEhEpOUU/QXyu+NBQ3Ok9ymIiLQSRZ8UYk15SaqISCsXaVIws5lm9o6ZrTOza3MsH2RmL5nZUjNbbmanRBlPLqmG5lYzyI6ISIQiSwpmVgrMAU4GRgCzzWxE1mo/BZ5w93HAOcCvooqnLjFVH4mIpEVZUpgArHP39929CngMOD1rHQe6hs+7AX+NMJ6cKuMJ2peWUFqi+wpERKK8+ugA4OOM6Q3AxKx1bgReMLPvA52BaRHGk1MsnqBDIQ/FKSLSjFr6aDgbuN/dBwCnAA+ZWa2YzOwyM1tsZou3bNnSpAHE4gm1J4iIhKJMChuBgRnTA8J5mS4GngBw9/8FyoFavca5+93uXuHuFX369GnSIGPxhNoTRERCUSaFRcChZjbEzNoTNCTPzVrnI2AqgJkNJ0gKTVsUaEClSgoiImmRJQV3rwauAP4IrCa4ymilmd1kZrPC1f4euNTM3gIeBS50d48qplxi8eTedYYnItKGRdrNhbvPA+Zlzbs+4/kq4JgoY2hIpaqPRETSiv4UebeSgohIWtEnhaCkUPQfg4gIoKRALJ5UQ7OISEhJQdVHIiJpRZ8U1NAsIrJH0SeF3fGkkoKISKiok0Ii6VQl1KYgIpJS1EkhtrdDcYqItHFFfTRMjc/csb1KCiIiUORJIV1SaKekICICSgoAlKukICIC1NP3kZndRTAyWk7ufmUkETWj9FCc7Yo6N4qIpNV3NFwMLCHozno8sDZ8jAXaRx9a9NSmICJSU50lBXd/AMDMvgscG3aFjZn9B/A/zRNetPZcfaSkICIC+bUp9AC6ZkzvF85r9Sqr1NAsIpIpn/EUbgWWmtlLgAGTgRujDKq5xKqDNoWO7dWmICICeSQFd7/PzOYDE8NZ/8fd/xZtWM0jVX3UQSUFEREgj+ojMzNgGjDG3Z8F2pvZhMgjawYxNTSLiNSQT73Jr4CjgNnh9OfAnMgiakZqaBYRqSmfNoWJ7j7ezJYCuPtnZtY2Lkmt0n0KIiKZ8jkaxs2slPBGNjPrAyQjjaqZxKoTlJUa7UqVFEREIL+kcCfwDNDXzG4BXgH+OdKomklllQbYERHJlM/VRw+b2RJgKsElqWe4++rII2sGu6uVFEREMjWYFMzsTuAxd28TjcuZKqsSGmBHRCRDPtVHS4Cfmtl7Zna7mVVEHVRzicWTGmBHRCRDg0dEd3/A3U8BjgTeAW4zs7WRR9YMKuMqKYiIZNqb0+RDgGHAgcCaaMJpXrF4gg5KCiIiafnc0fzzsGRwE/A2UOHup0UeWTOIxdXQLCKSKZ+b194DjnL3T6MOprnF4kn2V5uCiEhaPkfE3wAzzex6ADMb1Fb6PqpUSUFEpIZ8ksIc2nDfR2poFhHZI5+kMNHdLwdiEPR9RJ7DcZrZTDN7x8zWmdm1daxztpmtMrOVZvZI3pE3AbUpiIjUlE+bQqP6Pgq3mQNMBzYAi8xsrruvyljnUOBHwDFhR3t9G/EeGi24T0FJQUQkJcq+jyYA69z9fXevAh4DTs9a51JgTlj6wN035x35PkoknaqEbl4TEckUZd9HBwAfZ0xvYM/obSmHAZjZX4BS4EZ3/0M+ge+r9AA7KimIiKTVmRTMrKu77zSznsBm4NGMZT3dfVsTvf6hwBRgAPCymY1y9+1ZsVwGXAYwaNCgJnhZDbAjIpJLfSWFR4BTCfo+coJSQub/BzWw743AwIzpAeG8TBuA1909DnxgZu8SJIlFmSu5+93A3QAVFRXewOvmpVIlBRGRWupMCu5+avj/kEbuexFwqJkNIUgG5wDfzFrn9wSXut5nZr0JqpPeb+Tr7ZVYPGgr76A2BRGRtHyuPsLMDiDo8yi9vru/XN827l5tZlcAfyRoL7jX3Vea2U3AYnefGy6bYWargATwQ3ff2ri3snfUpiAiUls+4yncBnwDSB24Iag+qjcpALj7PGBe1rzrM5478IPw0azUpiAiUls+JYUzgKHuvjvqYJpTuk2hvZKCiEhKPhXq7wNlUQfS3FJtCuXtlBRERFLquyT1LoJqoi+BZWa2AEiXFtz9yujDi05luvpIDc0iIin1VR8tDv9fAsxthlialdoURERqq++S1AcAzKwzEHP3RDhdCnRonvCis1tJQUSklnzqThYAHTOmOwIvRhNO81FDs4hIbfkkhXJ3/yI1ET7vFF1IzWNPQ7PaFEREUvI5Iu4ys/GpCTM7AqiMLqTmURlPUFZqtCtVUhARScnnPoWrgSfN7K8E/R7tT9BlRasWiyd0OaqISJZ8us5eZGbDgKHhrHeiDal5xOIJytWeICJSQ151J2EvpiuBfsB/EPRu2qoFo66p6khEJFODR0Uzm2RmdwIfAs8S9Hk0LOrAolZZlVBneCIiWepMCmb2z2a2FrgFWA6MA7a4+wOp4TNbs1h1QvcoiIhkqa9N4RLgXeDXwH+5+24za5IBbgpBZZWSgohItvqqj/oDNwOnAe+Z2UNARzPLawyGQherTiopiIhkqa+biwTwB+APZtaBYGjOjsBGM1vg7tmjqLUqsaoE/bq0+t46RESaVF5n/eFYCk8DT5tZV4IxFlq1WHVCXVyIiGTZ66ogd98JPBhBLM2qsko3r4mIZCvaC/VjcZUURESyFW9SqE7SQTeviYjUkM/Na53M7Doz+004faiZnRp9aNFJJJ2q6qRuXhMRyZLPqfJ9BMNwHhVObyS4VLXV2l2tAXZERHLJJykc7O4/B+IA7v4lQW+prVZlVTjAjpKCiEgN+SSFKjPrCDiAmR1MUHJotWLV4QA7alMQEakhn0tSbyC4iW2gmT0MHANcGGVQUUuVFFR9JCJSU71JwcwMWAN8HZhEUG10lbt/2gyxRSYWV1IQEcml3qTg7m5m89x9FPB8M8UUuVRSUJuCiEhN+VSqv2lmR0YeSTOKxVNtCkoKIiKZ8mlTmAica2YfArsIqpDc3UdHGlmEKlVSEBHJKZ+kcFLkUTSzPW0KuvpIRCRTg0dFd/8Q6E4wrsJpQPdwXqtVqYZmEZGc8unm4irgYaBv+PhPM/t+Pjs3s5lm9o6ZrTOza+tZ7+/MzM2sIt/A98VuJQURkZzyqT66GJjo7rsAzOw24H+Bu+rbyMxKgTnAdGADsMjM5rr7qqz1ugBXAa/vffiNs6ehWdVHIiKZ8jkqGpDImE6QXzcXE4B17v6+u1cBjwGn51jvn4DbgFge+2wSqj4SEcktn5LCfcDrZvZMOH0G8Ns8tjsA+DhjegPBlUxpZjYeGOjuz5vZD/PYZ5OIxRO0KzHKSlVSEBHJ1GBScPc7zGwhcGw46yJ3X7qvL2xmJcAd5NFlhpldBlwGMGjQoH19aSrjCV2OKiKSQ4NJwcwmASvd/c1wuquZTXT3htoANgIDM6YHhPNSugCHAwuD3jTYH5hrZrPcfXHmjtz9buBugIqKCm8o5obE4kk6KCmIiNSST/3Jr4EvMqa/COc1ZBFwqJkNMbP2wDnA3NRCd9/h7r3dfbC7DwZeA2olhCgEQ3Gq6khEJFteDc3unj47d/ck+VU7VQNXAH8EVgNPuPtKM7vJzGY1NuCmEIsnKG+nkoKISLZ8GprfN7Mr2VM6+B7wfj47d/d5wLysedfXse6UfPbZFCrjCTq2V1IQEcmWT0nhO8DRBO0BGwmuILosyqCippKCiEhu+VQDbSZoD2gzKuNJunUsa+kwREQKTp0lBTO71MwODZ+bmd1rZjvMbHl4f0GrtTueoLydGppFRLLVd2S8ClgfPp8NjAEOAn4A/CLasKJVGU/obmYRkRzqSwrV7h4Pn58KPOjuW939RaBz9KFFJ6ab10REcqovKSTNrL+ZlQNTgRczlnWMNqxoxeJJdYYnIpJDfQ3N1wOLgVJgrruvBDCz48nzktRCVRlPUK5LUkVEaqkzKbj7c2Z2INDF3T/LWLQY+EbkkUUkmXSqqpO6JFVEJId6L0kN70r+LGverkgjilisOhyfWSUFEZFaiq5iPT3Aji5JFRGppeiOjKkBdlRSEBGprVFJwcyGNXUgzSWmUddEROrU2JLCC00aRTOqrFJSEBGpS50NzWZ2Z12LgO7RhBO93dVKCiIidanv6qOLgL8HdudYNjuacKJXWRU0NOuOZhGR2upLCouAFe7+avYCM7sxsogitqdNoeja2EVEGlRfUjgTiOVa4O5DogknepVqaBYRqVN9p8v7ufuXzRZJM0mVFFR9JCJSW31J4fepJ2b2dDPE0ixSSaGDqo9ERGqp78hoGc8PijqQ5pK6o1klBRGR2upLCl7H81ZNN6+JiNStvobmMWa2k6DE0DF8Tjjt7t418ugiUBlP0K7EKCtV9ZGISLb6us5uk6fSwQA7bfKtiYjss6I7Xdb4zCIidSu6pLA7ntCNayIidSi6o2NlPKErj0RE6lB0SSGm6iMRkToVXVJQSUFEpG5FlxRi8aTuZhYRqUPRHR1jKimIiNSpKJOC2hRERHKLNCmY2Uwze8fM1pnZtTmW/8DMVpnZcjNbYGYHRhkPpO5TKLpcKCKSl8iOjmZWCswBTgZGALPNbETWakuBCncfDTwF/DyqeFJi8aSqj0RE6hDlKfMEYJ27v+/uVcBjwOmZK7j7SxljNrwGDIgwHkDVRyIi9YkyKRwAfJwxvSGcV5eLgfm5FpjZZWa22MwWb9mypdEBJZPO7mr1fSQiUpeCqFw3s/OACuBfcy1397vdvcLdK/r06dPo19ldHYyloKQgIpJbfV1n76uNwMCM6QHhvBrMbBrwE+B4d98dYTzp8Zk7qqFZRCSnKI+Oi4BDzWyImbUHzgHmZq5gZuOA/wfMcvfNEcYCaIAdEZGGRJYU3L0auAL4I7AaeMLdV5rZTWY2K1ztX4H9gCfNbJmZza1jd00iXVJor6QgIpJLlNVHuPs8YF7WvOsznk+L8vWzpUoKHdopKYiI5FJUlesxlRREROpVZEkhvPqoXVG9bRGRvBXV0bGySiUFEZH6FFVSiFXr6iMRkfoUVVJIlRTK1dAsIpJTUSWFWOqO5vZF9bZFRPIW6SWphWa3bl4TyUs8HmfDhg3EYrGWDkX2Unl5OQMGDKCsrKxR2xdVUkg3NCspiNRrw4YNdOnShcGDB2NmLR2O5Mnd2bp1Kxs2bGDIkCGN2kdR1aPEqhOUlhhlpUX1tkX2WiwWo1evXkoIrYyZ0atXr30q4RXV0bGySgPsiORLCaF12tfvraiSQqxaQ3GKtBb77bdfjen777+fK664ItLXXLhwIaeeemok+x48eDCffvppJPtuSkV1hIxVadQ1Ecmturq6pUMoCMWVFKqVFERau88//5whQ4YQj8cB2LlzZ3p6ypQpXHXVVYwdO5bDDz+cN954A4Bdu3bx7W9/mwkTJjBu3DieffZZICh9zJo1ixNPPJGpU6em9/fVr36VoUOH8p3vfIdkMriU/bvf/S4VFRWMHDmSG264IR3P4MGDueGGGxg/fjyjRo1izZo1AGzdupUZM2YwcuRILrnkEty92T6jfVF0Vx+pTUFk7/zsv1ay6q87m3SfI77SlRtOG1nvOpWVlYwdOzY9vW3bNmbNmkWXLl2YMmUKzz//PGeccQaPPfYYX//619OXYH755ZcsW7aMl19+mW9/+9usWLGCW265hRNPPJF7772X7du3M2HCBKZNCzppfvPNN1m+fDk9e/Zk4cKFvPHGG6xatYoDDzyQmTNn8rvf/Y4zzzyTW265hZ49e5JIJJg6dSrLly9n9OjRAPTu3Zs333yTX/3qV9x+++3cc889/OxnP+PYY4/l+uuv5/nnn+e3v/1tk36GUSmukkI8qTYFkVaiY8eOLFu2LP246aab0ssuueQS7rvvPgDuu+8+LrroovSy2bNnAzB58mR27tzJ9u3beeGFF7j11lsZO3YsU6ZMIRaL8dFHHwEwffp0evbsmd5+woQJHHTQQZSWljJ79mxeeeUVAJ544gnGjx/PuHHjWLlyJatWrUpv8/Wvfx2AI444gvXr1wPw8ssvc9555wHw1a9+lR49ejT1RxSJ4iopxBN0KS+qtyyyzxo6o28JxxxzDOvXr2fhwoUkEgkOP/zw9LLsq2/MDHfn6aefZujQoTWWvf7663Tu3LnW+tnTH3zwAbfffjuLFi2iR48eXHjhhTUu++zQoQMApaWlrb5toqhOm2NxtSmItBXf+ta3+OY3v1mjlADw+OOPA/DKK6/QrVs3unXrxkknncRdd92VrtdfunRpnft94403+OCDD0gmkzz++OMce+yx7Ny5k86dO9OtWzc2bdrE/PnzG4xv8uTJPPLIIwDMnz+fzz77rLFvtVkV1WlzLK42BZG24txzz+WnP/1puroopby8nHHjxhGPx7n33nsBuO6667j66qsZPXo0yWSSIUOG8Nxzz+Xc75FHHskVV1zBunXrOOGEE/ja175GSUkJ48aNY9iwYQwcOJBjjjmmwfhuuOEGZs+ezciRIzn66KMZNGjQvr/pZmCtpUU8paKiwhcvXtyobSf98wImH9abn585pomjEmlbVq9ezfDhw1s6jHo99dRTPPvsszz00EPpeVOmTOH222+noqKiBSNrebm+PzNb4u4NfjBFVVKoVPWRSJvw/e9/n/nz5zNv3ryGV5a9UlRJQdVHIm3DXXfdlXP+woULmzeQNqhoGpqTSWd3dZIOSgoiInUqmqSwOxxgRyUFEZG6FU1SiKUH2CmatywisteK5ghZGdcAOyIiDSmapBDTUJwirUppaWm6Y7vTTjuN7du3N8l+169fX+MO6H3x2muvMXHiRMaOHcvw4cO58cYbm2S/dbnwwgt56qmnIn2NokkKlUoKIq1Kqu+jFStW0LNnT+bMmdPSIdVywQUXcPfdd6fjPPvss/d5ny3dTUbRJIVYPGhoVpuCSOtz1FFHsXHjRgC++OILpk6dmu6qOtUN9vr16xk+fDiXXnopI0eOZMaMGVRWVgKwZMkSxowZw5gxY2okl1gsxkUXXcSoUaMYN24cL730EhB0qX3GGWcwffp0Bg8ezC9/+UvuuOMOxo0bx6RJk9i2bRsAmzdvpn///kBQshkxYgRQd1fd69ev57jjjmP8+PGMHz+eV199FQgupT3uuOOYNWtWeh8PPvggo0ePZsyYMZx//vnpmF9++WWOPvpoDjrooEhKDUVzn0JMbQoijTP/Wvjb2027z/1Hwcm35rVqIpFgwYIFXHzxxUDQjcUzzzxD165d+fTTT5k0aRKzZs0CYO3atTz66KP85je/4eyzz+bpp5/mvPPO46KLLuKXv/wlkydP5oc//GF633PmzMHMePvtt1mzZg0zZszg3XffBWDFihUsXbqUWCzGIYccwm233cbSpUu55pprePDBB7n66qu55pprGDp0KFOmTGHmzJlccMEFlJeX19lVd9++ffnTn/5EeXk5a9euZfbs2aR6aHjzzTdZsWIFQ4YMYeXKldx88828+uqr9O7dO52EAD755BNeeeUV1qxZw6xZszjzzDOb5CtJKZrTZrUpiLQuqfEU9t9/fzZt2sT06dMBcHd+/OMfM3r0aKZNm8bGjRvZtGkTAEOGDEmPwZDqxnr79u1s376dyZMnA9Q4637llVfS3VsPGzaMAw88MJ0UTjjhBLp06UKfPn3o1q0bp512GgCjRo1Kd499/fXXs3jxYmbMmMEjjzzCzJkzAersqjsej3PppZcyatQozjrrrBrdb0+YMIEhQ4YA8Oc//5kXCnMFAAAKBklEQVSzzjqL3r17A9To2vuMM86gpKSEESNGpN93U4q0pGBmM4FfAKXAPe5+a9byDsCDwBHAVuAb7r4+iljSVx+1V1IQ2St5ntE3tVSbwpdffslJJ53EnDlzuPLKK3n44YfZsmULS5YsoaysjMGDB6e7sU51YQ1BdU6q+qgxMvdVUlKSni4pKalR73/wwQfz3e9+l0svvZQ+ffqwdevWOrvqvvHGG+nXrx9vvfUWyWSS8vLy9LLsLrzziSuKvusiKymYWSkwBzgZGAHMNrMRWatdDHzm7ocA/w7cFlU86TaFdkoKIq1Jp06duPPOO/m3f/s3qqur2bFjB3379qWsrIyXXnqJDz/8sN7tu3fvTvfu3dOD5Tz88MPpZccdd1x6+t133+Wjjz6qdSCvz/PPP58+MK9du5bS0lK6d+9eZ1fdO3bsoH///pSUlPDQQw+RSCRy7vfEE0/kySefZOvWrQA1qo+iFmX10QRgnbu/7+5VwGPA6VnrnA48ED5/Cphq2SNcNJFK3bwm0mqNGzeO0aNH8+ijj3LuueeyePFiRo0axYMPPsiwYcMa3P6+++7j8ssvZ+zYsTXOrr/3ve+RTCYZNWoU3/jGN7j//vtrnIk35KGHHmLo0KGMHTuW888/n4cffpjS0lKuu+464vE4o0ePZuTIkVx33XXp13vggQcYM2YMa9asqbN0MHLkSH7yk59w/PHHM2bMGH7wgx/kHdO+iqzrbDM7E5jp7peE0+cDE939iox1VoTrbAin3wvX+bSu/Ta26+x7/ud9bn5+NctvnEHX8rK93l6kmLSGrrOlbvvSdXarOG02s8vMbLGZLd6yZUuj9jGoZydOPnx/XX0kIlKPKBuaNwIDM6YHhPNyrbPBzNoB3QganGtw97uBuyEoKTQmmBkj92fGyP0bs6mISNGIsqSwCDjUzIaYWXvgHGBu1jpzgQvC52cCf/bWNhSciEgbEllJwd2rzewK4I8El6Te6+4rzewmYLG7zwV+CzxkZuuAbQSJQ0QKgLsT0XUfEqF9Pa+O9D4Fd58HzMuad33G8xhwVpQxiMjeKy8vZ+vWrfTq1UuJoRVxd7Zu3Vrj/oe9VTTdXIhI/gYMGMCGDRto7IUd0nLKy8sZMGBAo7dXUhCRWsrKytJdLkhxaRWXpIqISPNQUhARkTQlBRERSYusm4uomNkWoL4esHoDdXaT0cIKOTYo7PgKOTYo7PgKOTYo7PgKOTbYu/gOdPc+Da3U6pJCQ8xscT79e7SEQo4NCju+Qo4NCju+Qo4NCju+Qo4NoolP1UciIpKmpCAiImltMSnc3dIB1KOQY4PCjq+QY4PCjq+QY4PCjq+QY4MI4mtzbQoiItJ4bbGkICIijdRmkoKZzTSzd8xsnZldWwDx3Gtmm8PR5VLzeprZn8xsbfh/jxaKbaCZvWRmq8xspZldVWDxlZvZG2b2Vhjfz8L5Q8zs9fA7fjzskr1FmFmpmS01s+cKMLb1Zva2mS0zs8XhvEL5brub2VNmtsbMVpvZUQUU29DwM0s9dprZ1QUU3zXh38MKM3s0/Dtp8t9dm0gKZlYKzAFOBkYAs81sRMtGxf3AzKx51wIL3P1QYEE43RKqgb939xHAJODy8PMqlPh2Aye6+xhgLDDTzCYBtwH/7u6HAJ8BF7dQfABXAaszpgspNoAT3H1sxuWKhfLd/gL4g7sPA8YQfIYFEZu7vxN+ZmOBI4AvgWcKIT4zOwC4Eqhw98MJhiM4hyh+d+7e6h/AUcAfM6Z/BPyoAOIaDKzImH4H6B8+7w+809IxhrE8C0wvxPiATsCbwESCm3Ta5frOmzmmAQQHhxOB5wArlNjC118P9M6a1+LfLcHIih8QtmUWUmw5Yp0B/KVQ4gMOAD4GehJ0ZPoccFIUv7s2UVJgzweWsiGcV2j6ufsn4fO/Af1aMhgAMxsMjANep4DiC6tnlgGbgT8B7wHb3b06XKUlv+P/C/wjkAyne1E4sQE48IKZLTGzy8J5hfDdDgG2APeFVW/3mFnnAokt2znAo+HzFo/P3TcCtwMfAZ8AO4AlRPC7aytJodXxILW36KVfZrYf8DRwtbvvzFzW0vG5e8KDYvwAYAIwrKViyWRmpwKb3X1JS8dSj2PdfTxBderlZjY5c2ELfrftgPHAr919HLCLrKqYlv7dAYT18rOAJ7OXtVR8YTvG6QSJ9StAZ2pXTzeJtpIUNgIDM6YHhPMKzSYz6w8Q/r+5pQIxszKChPCwu/+u0OJLcfftwEsERePuZpYaA6SlvuNjgFlmth54jKAK6RcFEhuQPqvE3TcT1IlPoDC+2w3ABnd/PZx+iiBJFEJsmU4G3nT3TeF0IcQ3DfjA3be4exz4HcFvscl/d20lKSwCDg1b4tsTFP3mtnBMucwFLgifX0BQl9/szMwIxsde7e53ZCwqlPj6mFn38HlHgvaO1QTJ4cyWjM/df+TuA9x9MMHv7M/ufm4hxAZgZp3NrEvqOUHd+AoK4Lt1978BH5vZ0HDWVGBVIcSWZTZ7qo6gMOL7CJhkZp3Cv9/UZ9f0v7uWbtBpwoaYU4B3Ceqef1IA8TxKUPcXJzhDupig7nkBsBZ4EejZQrEdS1AEXg4sCx+nFFB8o4GlYXwrgOvD+QcBbwDrCIr2HVr4O54CPFdIsYVxvBU+Vqb+Fgroux0LLA6/298DPQoltjC+zsBWoFvGvIKID/gZsCb8m3gI6BDF7053NIuISFpbqT4SEZEmoKQgIiJpSgoiIpKmpCAiImlKCiIikqakICIiaUoKUrTMrFdGN8l/M7ONGdOvRvSa48zst/Us72Nmf4jitUXy0a7hVUTaJnffSnAzFWZ2I/CFu98e8cv+GLi5npi2mNknZnaMu/8l4lhEalFJQSQHM/si/H+Kmf23mT1rZu+b2a1mdq4FgwC9bWYHh+v1MbOnzWxR+Dgmxz67AKPd/a1w+viMksnSVPcUBHf6nttMb1WkBiUFkYaNAb4DDAfOBw5z9wnAPcD3w3V+QTDYyZHA34XLslUQdFGQ8g/A5R70BnscUBnOXxxOizQ7VR+JNGyRh/3pm9l7wAvh/LeBE8Ln04ARQV9lAHQ1s/3c/YuM/fQnGE8g5S/AHWb2MPA7d98Qzt9M0D2ySLNTUhBp2O6M58mM6SR7/oZKgEnuHqtnP5VAeWrC3W81s+cJOiP8i5md5O5rwnUq69iHSKRUfSTSNF5gT1USZjY2xzqrgUMy1jnY3d9299sIun9PDSR0GDWrmUSajZKCSNO4Eqgws+VmtoqgDaKGsBTQLaNB+WozW2Fmywm6WJ8fzj8BeL45ghbJpq6zRZqRmV0DfO7uuRqiU+u8DJzu7p81X2QiAZUURJrXr6nZRlGDmfUB7lBCkJaikoKIiKSppCAiImlKCiIikqakICIiaUoKIiKSpqQgIiJp/x+XM1sv00S+7wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_score_vs_time(rs_data, hb_data):\n",
    "    plt.cla()\n",
    "    \n",
    "    xs_hyperband = [x[\"time_elapsed\"] for x in hb_data]\n",
    "    ys_hyperband = [x[\"best_score\"] for x in hb_data]\n",
    "    xs_rs = [x[\"time_elapsed\"] for x in rs_data]\n",
    "    ys_rs = [x[\"best_score\"] for x in rs_data]\n",
    "    \n",
    "    plt.plot(xs_hyperband, ys_hyperband, label=\"Hyperband\")\n",
    "    plt.plot(xs_rs, ys_rs, label=\"RandomSearch\")\n",
    "    \n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"F1 Score Achieved\")\n",
    "    \n",
    "    plt.legend(loc=\"best\")\n",
    "    \n",
    "plot_score_vs_time(rs_stats, hb_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting! Our plot shows that Hyperband finds a good solution very fast, much faster than random search. \n",
    "\n",
    "From the plot above, we see that Hyperband finds its best solution at around time 10s, whereas it takes random search around 70s to achieve a comparable score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data above is very encouraging, however our previous setup may have been too simplistic. Let's make our search problem harder by expanding the search space and search time and comparing the performances of our tuners."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's define a harder search space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "harder_search_space = {\n",
    "    'n_epochs': [1, 5, 10, 20, 40],\n",
    "    'batchnorm' : [True, False],\n",
    "    'dropout': [0, .1, .2, .3, .4, .5],\n",
    "    'lr': {'range': [1e-7, 1], 'scale': 'log'},\n",
    "    'layer_out_dims' : [[1000,10,2], [1000, 100, 2], [1000, 20, 2], [1000, 30, 2], [1000, 40, 2], [1000, 50, 2], [1000, 70, 2], [1000, 500, 2], [1000, 700, 2]],\n",
    "    'print_every': 5,\n",
    "    'data_loader_config': [{\"batch_size\": 256, \"num_workers\": 1}],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's create our tuners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================\n",
      "|           Hyperband Schedule          |\n",
      "=========================================\n",
      "Table consists of tuples of (num configs, num_resources_per_config)which specify how many configs to run andfor how many epochs. \n",
      "Each bracket starts with a list of random configurations which is successively halved according the schedule.\n",
      "See the Hyperband paper (https://arxiv.org/pdf/1603.06560.pdf) for more details.\n",
      "-----------------------------------------\n",
      "Bracket 0: (27, 1) (9, 5) (3, 17) (1, 52)\n",
      "Bracket 1: (9, 5) (3, 17) (1, 52)\n",
      "Bracket 2: (6, 17) (2, 52)\n",
      "Bracket 3: (4, 53)\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "rs_tuner_harder = RandomSearchTuner(EndModel, seed=123)\n",
    "hb_tuner_harder = HyperbandTuner(EndModel, hyperband_epochs_budget=800, seed=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then run the search process (this may take a few minutes!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[1] Testing {'n_epochs': 10, 'batchnorm': False, 'dropout': 0, 'layer_out_dims': [1000, 10, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.3700237151852522}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.754\n",
      "[E:0]\tTrain Loss: 0.994\tDev score: 0.754\n",
      "[E:5]\tTrain Loss: 0.577\tDev score: 0.754\n",
      "[E:9]\tTrain Loss: 0.577\tDev score: 0.754\n",
      "Restoring best model from iteration 0 with score 0.754\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1     0      0    \n",
      " l=2    246    754   \n",
      "F1: 0.000\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.1)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[2] Testing {'n_epochs': 5, 'batchnorm': False, 'dropout': 0.1, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 1.827334249624349e-05}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.742\n",
      "[E:0]\tTrain Loss: 0.676\tDev score: 0.742\n",
      "Saving model at iteration 1 with best score 0.753\n",
      "Saving model at iteration 2 with best score 0.755\n",
      "[E:4]\tTrain Loss: 0.624\tDev score: 0.754\n",
      "Restoring best model from iteration 2 with score 0.755\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1     0      0    \n",
      " l=2    246    754   \n",
      "F1: 0.008\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.4)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[3] Testing {'n_epochs': 10, 'batchnorm': False, 'dropout': 0.4, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.6366544570068935}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.754\n",
      "[E:0]\tTrain Loss: 8.673\tDev score: 0.754\n",
      "Saving model at iteration 1 with best score 0.755\n",
      "[E:5]\tTrain Loss: 0.577\tDev score: 0.754\n",
      "[E:9]\tTrain Loss: 0.580\tDev score: 0.754\n",
      "Restoring best model from iteration 1 with score 0.755\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1     1      0    \n",
      " l=2    245    754   \n",
      "F1: 0.008\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.2)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[4] Testing {'n_epochs': 5, 'batchnorm': True, 'dropout': 0.2, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.31643979593790955}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.902\n",
      "[E:0]\tTrain Loss: 1.850\tDev score: 0.902\n",
      "Saving model at iteration 1 with best score 0.909\n",
      "Saving model at iteration 3 with best score 0.979\n",
      "[E:4]\tTrain Loss: 0.446\tDev score: 0.894\n",
      "Restoring best model from iteration 3 with score 0.979\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    236     6    \n",
      " l=2    10     748   \n",
      "F1: 0.957\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[5] Testing {'n_epochs': 1, 'batchnorm': False, 'dropout': 0.2, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.007292621889903268}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.976\n",
      "[E:0]\tTrain Loss: 0.486\tDev score: 0.976\n",
      "Restoring best model from iteration 0 with score 0.976\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    223     0    \n",
      " l=2    23     754   \n",
      "F1: 0.953\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.4)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[6] Testing {'n_epochs': 5, 'batchnorm': False, 'dropout': 0.4, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 1.670624993426239e-05}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.718\n",
      "[E:0]\tTrain Loss: 0.680\tDev score: 0.718\n",
      "Saving model at iteration 1 with best score 0.760\n",
      "[E:4]\tTrain Loss: 0.638\tDev score: 0.754\n",
      "Restoring best model from iteration 1 with score 0.760\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    14     22    \n",
      " l=2    232    732   \n",
      "F1: 0.140\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2)\n",
      "  )\n",
      "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[7] Testing {'n_epochs': 5, 'batchnorm': False, 'dropout': 0.2, 'layer_out_dims': [1000, 10, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.5013839780330771}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.754\n",
      "[E:0]\tTrain Loss: 0.972\tDev score: 0.754\n",
      "[E:4]\tTrain Loss: 0.578\tDev score: 0.754\n",
      "Restoring best model from iteration 0 with score 0.754\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1     0      0    \n",
      " l=2    246    754   \n",
      "F1: 0.000\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[8] Testing {'n_epochs': 1, 'batchnorm': False, 'dropout': 0.5, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.008520966193723056}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.974\n",
      "[E:0]\tTrain Loss: 0.495\tDev score: 0.974\n",
      "Restoring best model from iteration 0 with score 0.974\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    221     0    \n",
      " l=2    25     754   \n",
      "F1: 0.953\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.1)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[9] Testing {'n_epochs': 10, 'batchnorm': False, 'dropout': 0.1, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.003970906941573151}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.995\n",
      "[E:0]\tTrain Loss: 0.491\tDev score: 0.995\n",
      "[E:5]\tTrain Loss: 0.385\tDev score: 0.921\n",
      "[E:9]\tTrain Loss: 0.333\tDev score: 0.911\n",
      "Restoring best model from iteration 0 with score 0.995\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    244     1    \n",
      " l=2     2     753   \n",
      "F1: 0.994\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.3)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[10] Testing {'n_epochs': 1, 'batchnorm': True, 'dropout': 0.3, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.0003777251862528499}\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model at iteration 0 with best score 0.948\n",
      "[E:0]\tTrain Loss: 0.605\tDev score: 0.948\n",
      "Restoring best model from iteration 0 with score 0.948\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    243    58    \n",
      " l=2     3     696   \n",
      "F1: 0.909\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[11] Testing {'n_epochs': 10, 'batchnorm': False, 'dropout': 0.3, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.0011538361363759827}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.983\n",
      "[E:0]\tTrain Loss: 0.518\tDev score: 0.983\n",
      "Saving model at iteration 1 with best score 0.991\n",
      "[E:5]\tTrain Loss: 0.423\tDev score: 0.969\n",
      "[E:9]\tTrain Loss: 0.386\tDev score: 0.938\n",
      "Restoring best model from iteration 1 with score 0.991\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    237     1    \n",
      " l=2     9     753   \n",
      "F1: 0.981\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.3)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[12] Testing {'n_epochs': 10, 'batchnorm': True, 'dropout': 0.3, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.002945528656127802}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.975\n",
      "[E:0]\tTrain Loss: 0.567\tDev score: 0.975\n",
      "[E:5]\tTrain Loss: 0.344\tDev score: 0.905\n",
      "[E:9]\tTrain Loss: 0.328\tDev score: 0.918\n",
      "Restoring best model from iteration 0 with score 0.975\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    226     1    \n",
      " l=2    20     753   \n",
      "F1: 0.946\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.1)\n",
      "  )\n",
      "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[13] Testing {'n_epochs': 1, 'batchnorm': False, 'dropout': 0.1, 'layer_out_dims': [1000, 10, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.0026338666324303645}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.763\n",
      "[E:0]\tTrain Loss: 0.549\tDev score: 0.763\n",
      "Restoring best model from iteration 0 with score 0.763\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1     7      0    \n",
      " l=2    239    754   \n",
      "F1: 0.071\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[14] Testing {'n_epochs': 5, 'batchnorm': False, 'dropout': 0, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.022267690733296888}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.984\n",
      "[E:0]\tTrain Loss: 0.501\tDev score: 0.984\n",
      "[E:4]\tTrain Loss: 0.411\tDev score: 0.974\n",
      "Restoring best model from iteration 0 with score 0.984\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    231     1    \n",
      " l=2    15     753   \n",
      "F1: 0.967\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5)\n",
      "  )\n",
      "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[15] Testing {'n_epochs': 1, 'batchnorm': False, 'dropout': 0.5, 'layer_out_dims': [1000, 10, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.007561031383400367}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.884\n",
      "[E:0]\tTrain Loss: 0.541\tDev score: 0.884\n",
      "Restoring best model from iteration 0 with score 0.884\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    115     0    \n",
      " l=2    131    754   \n",
      "F1: 0.658\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3)\n",
      "  )\n",
      "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[16] Testing {'n_epochs': 10, 'batchnorm': False, 'dropout': 0.3, 'layer_out_dims': [1000, 10, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 2.3005563286765607e-05}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.439\n",
      "[E:0]\tTrain Loss: 0.708\tDev score: 0.439\n",
      "Saving model at iteration 1 with best score 0.510\n",
      "Saving model at iteration 2 with best score 0.582\n",
      "Saving model at iteration 3 with best score 0.654\n",
      "Saving model at iteration 4 with best score 0.689\n",
      "Saving model at iteration 5 with best score 0.708\n",
      "[E:5]\tTrain Loss: 0.663\tDev score: 0.708\n",
      "Saving model at iteration 6 with best score 0.726\n",
      "Saving model at iteration 7 with best score 0.753\n",
      "Saving model at iteration 9 with best score 0.771\n",
      "[E:9]\tTrain Loss: 0.631\tDev score: 0.771\n",
      "Restoring best model from iteration 9 with score 0.771\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    47     33    \n",
      " l=2    199    721   \n",
      "F1: 0.212\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[17] Testing {'n_epochs': 1, 'batchnorm': False, 'dropout': 0, 'layer_out_dims': [1000, 10, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 9.272176167778152e-05}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.757\n",
      "[E:0]\tTrain Loss: 0.670\tDev score: 0.757\n",
      "Restoring best model from iteration 0 with score 0.757\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1     3      0    \n",
      " l=2    243    754   \n",
      "F1: 0.024\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[18] Testing {'n_epochs': 10, 'batchnorm': False, 'dropout': 0, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 1.0175385317479292e-05}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.744\n",
      "[E:0]\tTrain Loss: 0.677\tDev score: 0.744\n",
      "Saving model at iteration 1 with best score 0.759\n",
      "[E:5]\tTrain Loss: 0.636\tDev score: 0.754\n",
      "[E:9]\tTrain Loss: 0.605\tDev score: 0.754\n",
      "Restoring best model from iteration 1 with score 0.759\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    11      6    \n",
      " l=2    235    748   \n",
      "F1: 0.084\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.3)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[19] Testing {'n_epochs': 5, 'batchnorm': True, 'dropout': 0.3, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.07210322639680222}\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model at iteration 0 with best score 0.983\n",
      "[E:0]\tTrain Loss: 0.549\tDev score: 0.983\n",
      "[E:4]\tTrain Loss: 0.418\tDev score: 0.931\n",
      "Restoring best model from iteration 0 with score 0.983\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    230     2    \n",
      " l=2    16     752   \n",
      "F1: 0.960\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.4)\n",
      "  )\n",
      "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[20] Testing {'n_epochs': 10, 'batchnorm': True, 'dropout': 0.4, 'layer_out_dims': [1000, 10, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.003860152812810654}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.959\n",
      "[E:0]\tTrain Loss: 0.689\tDev score: 0.959\n",
      "[E:5]\tTrain Loss: 0.436\tDev score: 0.941\n",
      "[E:9]\tTrain Loss: 0.424\tDev score: 0.913\n",
      "Restoring best model from iteration 0 with score 0.959\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    246    35    \n",
      " l=2     0     719   \n",
      "F1: 0.917\n",
      "============================================================\n",
      "[SUMMARY]\n",
      "Best model: [9]\n",
      "Best config: {'n_epochs': 10, 'batchnorm': False, 'dropout': 0.1, 'layer_out_dims': [1000, 100, 2], 'print_every': 5, 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.003970906941573151, 'seed': 131}\n",
      "Best score: 0.9938900203665988\n",
      "============================================================\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.4)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[0 Testing {'n_epochs': 1, 'batchnorm': True, 'dropout': 0.4, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 4.624229978283888e-05}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.646\n",
      "[E:0]\tTrain Loss: 0.697\tDev score: 0.646\n",
      "Restoring best model from iteration 0 with score 0.646\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    187    287   \n",
      " l=2    59     467   \n",
      "F1: 0.536\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2)\n",
      "  )\n",
      "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[1 Testing {'n_epochs': 1, 'batchnorm': False, 'dropout': 0.2, 'layer_out_dims': [1000, 10, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 2.3824193576331065e-05}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.751\n",
      "[E:0]\tTrain Loss: 0.662\tDev score: 0.751\n",
      "Restoring best model from iteration 0 with score 0.751\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1     2      4    \n",
      " l=2    244    750   \n",
      "F1: 0.016\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.1)\n",
      "  )\n",
      "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[2 Testing {'n_epochs': 1, 'batchnorm': False, 'dropout': 0.1, 'layer_out_dims': [1000, 10, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.0004352789269567879}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.754\n",
      "[E:0]\tTrain Loss: 0.607\tDev score: 0.754\n",
      "Restoring best model from iteration 0 with score 0.754\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1     0      0    \n",
      " l=2    246    754   \n",
      "F1: 0.000\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.1)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[3 Testing {'n_epochs': 1, 'batchnorm': False, 'dropout': 0.1, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.000123454176325654}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.754\n",
      "[E:0]\tTrain Loss: 0.634\tDev score: 0.754\n",
      "Restoring best model from iteration 0 with score 0.754\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1     0      0    \n",
      " l=2    246    754   \n",
      "F1: 0.000\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[4 Testing {'n_epochs': 1, 'batchnorm': False, 'dropout': 0.3, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.9197451862527172}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.755\n",
      "[E:0]\tTrain Loss: 21.080\tDev score: 0.755\n",
      "Restoring best model from iteration 0 with score 0.755\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1     0      0    \n",
      " l=2    246    754   \n",
      "F1: 0.000\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.4)\n",
      "  )\n",
      "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[5 Testing {'n_epochs': 1, 'batchnorm': True, 'dropout': 0.4, 'layer_out_dims': [1000, 10, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 6.459779586288306e-05}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.634\n",
      "[E:0]\tTrain Loss: 0.652\tDev score: 0.634\n",
      "Restoring best model from iteration 0 with score 0.634\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    106    220   \n",
      " l=2    140    534   \n",
      "F1: 0.401\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.1)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[6 Testing {'n_epochs': 1, 'batchnorm': True, 'dropout': 0.1, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 7.425097452562551e-05}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.721\n",
      "[E:0]\tTrain Loss: 0.702\tDev score: 0.721\n",
      "Restoring best model from iteration 0 with score 0.721\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    226    260   \n",
      " l=2    20     494   \n",
      "F1: 0.616\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.5)\n",
      "  )\n",
      "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[7 Testing {'n_epochs': 1, 'batchnorm': True, 'dropout': 0.5, 'layer_out_dims': [1000, 10, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.051193459509736326}\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model at iteration 0 with best score 0.911\n",
      "[E:0]\tTrain Loss: 0.526\tDev score: 0.911\n",
      "Restoring best model from iteration 0 with score 0.911\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    165     0    \n",
      " l=2    81     754   \n",
      "F1: 0.814\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.5)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[8 Testing {'n_epochs': 1, 'batchnorm': True, 'dropout': 0.5, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.008687963391291976}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.967\n",
      "[E:0]\tTrain Loss: 0.505\tDev score: 0.967\n",
      "Restoring best model from iteration 0 with score 0.967\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    216     0    \n",
      " l=2    30     754   \n",
      "F1: 0.916\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[9 Testing {'n_epochs': 1, 'batchnorm': False, 'dropout': 0, 'layer_out_dims': [1000, 10, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.006235324635557636}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.985\n",
      "[E:0]\tTrain Loss: 0.514\tDev score: 0.985\n",
      "Restoring best model from iteration 0 with score 0.985\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    231     0    \n",
      " l=2    15     754   \n",
      "F1: 0.969\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.2)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[10 Testing {'n_epochs': 1, 'batchnorm': True, 'dropout': 0.2, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.0010815460964208876}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.986\n",
      "[E:0]\tTrain Loss: 0.585\tDev score: 0.986\n",
      "Restoring best model from iteration 0 with score 0.986\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    242    12    \n",
      " l=2     4     742   \n",
      "F1: 0.968\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[11 Testing {'n_epochs': 1, 'batchnorm': False, 'dropout': 0.5, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.0012466175605103217}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.983\n",
      "[E:0]\tTrain Loss: 0.524\tDev score: 0.983\n",
      "Restoring best model from iteration 0 with score 0.983\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    229     0    \n",
      " l=2    17     754   \n",
      "F1: 0.949\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[12 Testing {'n_epochs': 1, 'batchnorm': False, 'dropout': 0, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.0068101239577057}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.982\n",
      "[E:0]\tTrain Loss: 0.486\tDev score: 0.982\n",
      "Restoring best model from iteration 0 with score 0.982\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    228     0    \n",
      " l=2    18     754   \n",
      "F1: 0.962\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.1)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[13 Testing {'n_epochs': 1, 'batchnorm': True, 'dropout': 0.1, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.01751209712582007}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.898\n",
      "[E:0]\tTrain Loss: 0.499\tDev score: 0.898\n",
      "Restoring best model from iteration 0 with score 0.898\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    144     0    \n",
      " l=2    102    754   \n",
      "F1: 0.754\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.3)\n",
      "  )\n",
      "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[14 Testing {'n_epochs': 1, 'batchnorm': True, 'dropout': 0.3, 'layer_out_dims': [1000, 10, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.001266399031265807}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.987\n",
      "[E:0]\tTrain Loss: 0.573\tDev score: 0.987\n",
      "Restoring best model from iteration 0 with score 0.987\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    240     6    \n",
      " l=2     6     748   \n",
      "F1: 0.973\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3)\n",
      "  )\n",
      "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[15 Testing {'n_epochs': 1, 'batchnorm': False, 'dropout': 0.3, 'layer_out_dims': [1000, 10, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.00031143445068504736}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.768\n",
      "[E:0]\tTrain Loss: 0.658\tDev score: 0.768\n",
      "Restoring best model from iteration 0 with score 0.768\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    18     13    \n",
      " l=2    228    741   \n",
      "F1: 0.074\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.3)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[16 Testing {'n_epochs': 1, 'batchnorm': True, 'dropout': 0.3, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.002831832397076143}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.965\n",
      "[E:0]\tTrain Loss: 0.535\tDev score: 0.965\n",
      "Restoring best model from iteration 0 with score 0.965\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    213     0    \n",
      " l=2    33     754   \n",
      "F1: 0.919\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.4)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[17 Testing {'n_epochs': 1, 'batchnorm': True, 'dropout': 0.4, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.22011083143351787}\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model at iteration 0 with best score 0.819\n",
      "[E:0]\tTrain Loss: 0.939\tDev score: 0.819\n",
      "Restoring best model from iteration 0 with score 0.819\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    87      0    \n",
      " l=2    159    754   \n",
      "F1: 0.450\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.1)\n",
      "  )\n",
      "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[18 Testing {'n_epochs': 1, 'batchnorm': True, 'dropout': 0.1, 'layer_out_dims': [1000, 10, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.14221205603963122}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.960\n",
      "[E:0]\tTrain Loss: 0.500\tDev score: 0.960\n",
      "Restoring best model from iteration 0 with score 0.960\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    212     0    \n",
      " l=2    34     754   \n",
      "F1: 0.909\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[19 Testing {'n_epochs': 1, 'batchnorm': True, 'dropout': 0, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.02065427424933474}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.961\n",
      "[E:0]\tTrain Loss: 0.508\tDev score: 0.961\n",
      "Restoring best model from iteration 0 with score 0.961\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    208     1    \n",
      " l=2    38     753   \n",
      "F1: 0.914\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.1)\n",
      "  )\n",
      "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[20 Testing {'n_epochs': 1, 'batchnorm': True, 'dropout': 0.1, 'layer_out_dims': [1000, 10, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.008620172967532237}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.959\n",
      "[E:0]\tTrain Loss: 0.536\tDev score: 0.959\n",
      "Restoring best model from iteration 0 with score 0.959\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    214     0    \n",
      " l=2    32     754   \n",
      "F1: 0.926\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.1)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[21 Testing {'n_epochs': 1, 'batchnorm': True, 'dropout': 0.1, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.5653701249875115}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.797\n",
      "[E:0]\tTrain Loss: 3.487\tDev score: 0.797\n",
      "Restoring best model from iteration 0 with score 0.797\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    57     20    \n",
      " l=2    189    734   \n",
      "F1: 0.366\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[22 Testing {'n_epochs': 1, 'batchnorm': False, 'dropout': 0, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.09631669699978214}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.754\n",
      "[E:0]\tTrain Loss: 0.888\tDev score: 0.754\n",
      "Restoring best model from iteration 0 with score 0.754\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1     0      0    \n",
      " l=2    246    754   \n",
      "F1: 0.000\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5)\n",
      "  )\n",
      "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[23 Testing {'n_epochs': 1, 'batchnorm': False, 'dropout': 0.5, 'layer_out_dims': [1000, 10, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 4.403733721064476e-05}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.256\n",
      "[E:0]\tTrain Loss: 0.745\tDev score: 0.256\n",
      "Restoring best model from iteration 0 with score 0.256\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    244    748   \n",
      " l=2     2      6    \n",
      "F1: 0.392\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2)\n",
      "  )\n",
      "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[24 Testing {'n_epochs': 1, 'batchnorm': False, 'dropout': 0.2, 'layer_out_dims': [1000, 10, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.011247087902522112}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.949\n",
      "[E:0]\tTrain Loss: 0.497\tDev score: 0.949\n",
      "Restoring best model from iteration 0 with score 0.949\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    193     1    \n",
      " l=2    53     753   \n",
      "F1: 0.854\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[25 Testing {'n_epochs': 1, 'batchnorm': True, 'dropout': 0, 'layer_out_dims': [1000, 10, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 3.47130935423862e-05}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.682\n",
      "[E:0]\tTrain Loss: 0.658\tDev score: 0.682\n",
      "Restoring best model from iteration 0 with score 0.682\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    139    211   \n",
      " l=2    107    543   \n",
      "F1: 0.466\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[26 Testing {'n_epochs': 1, 'batchnorm': False, 'dropout': 0.5, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.013045643151841427}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.950\n",
      "[E:0]\tTrain Loss: 0.496\tDev score: 0.950\n",
      "Restoring best model from iteration 0 with score 0.950\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    191     2    \n",
      " l=2    55     752   \n",
      "F1: 0.893\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.3)\n",
      "  )\n",
      "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[27 Testing {'n_epochs': 5, 'batchnorm': True, 'dropout': 0.3, 'layer_out_dims': [1000, 10, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.001266399031265807}\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model at iteration 0 with best score 0.987\n",
      "[E:0]\tTrain Loss: 0.573\tDev score: 0.987\n",
      "Saving model at iteration 1 with best score 0.989\n",
      "[E:4]\tTrain Loss: 0.438\tDev score: 0.941\n",
      "Restoring best model from iteration 1 with score 0.989\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    238     1    \n",
      " l=2     8     753   \n",
      "F1: 0.984\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[28 Testing {'n_epochs': 5, 'batchnorm': False, 'dropout': 0, 'layer_out_dims': [1000, 10, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.006235324635557636}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.985\n",
      "[E:0]\tTrain Loss: 0.514\tDev score: 0.985\n",
      "Saving model at iteration 1 with best score 0.999\n",
      "[E:4]\tTrain Loss: 0.432\tDev score: 0.978\n",
      "Restoring best model from iteration 1 with score 0.999\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    246     1    \n",
      " l=2     0     753   \n",
      "F1: 0.998\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.2)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[29 Testing {'n_epochs': 5, 'batchnorm': True, 'dropout': 0.2, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.0010815460964208876}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.986\n",
      "[E:0]\tTrain Loss: 0.585\tDev score: 0.986\n",
      "[E:4]\tTrain Loss: 0.338\tDev score: 0.926\n",
      "Restoring best model from iteration 0 with score 0.986\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    242    11    \n",
      " l=2     4     743   \n",
      "F1: 0.974\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[30 Testing {'n_epochs': 5, 'batchnorm': False, 'dropout': 0, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.0068101239577057}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.982\n",
      "[E:0]\tTrain Loss: 0.486\tDev score: 0.982\n",
      "Saving model at iteration 1 with best score 0.988\n",
      "[E:4]\tTrain Loss: 0.380\tDev score: 0.933\n",
      "Restoring best model from iteration 1 with score 0.988\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    235     1    \n",
      " l=2    11     753   \n",
      "F1: 0.975\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[31 Testing {'n_epochs': 5, 'batchnorm': False, 'dropout': 0.5, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.0012466175605103217}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.983\n",
      "[E:0]\tTrain Loss: 0.524\tDev score: 0.983\n",
      "Saving model at iteration 1 with best score 0.989\n",
      "[E:4]\tTrain Loss: 0.435\tDev score: 0.970\n",
      "Restoring best model from iteration 1 with score 0.989\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    237     1    \n",
      " l=2     9     753   \n",
      "F1: 0.979\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.1)\n",
      "  )\n",
      "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[32 Testing {'n_epochs': 5, 'batchnorm': True, 'dropout': 0.1, 'layer_out_dims': [1000, 10, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.008620172967532237}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.959\n",
      "[E:0]\tTrain Loss: 0.536\tDev score: 0.959\n",
      "[E:4]\tTrain Loss: 0.418\tDev score: 0.919\n",
      "Restoring best model from iteration 0 with score 0.959\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    211     0    \n",
      " l=2    35     754   \n",
      "F1: 0.921\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.3)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[33 Testing {'n_epochs': 5, 'batchnorm': True, 'dropout': 0.3, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.002831832397076143}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.965\n",
      "[E:0]\tTrain Loss: 0.535\tDev score: 0.965\n",
      "[E:4]\tTrain Loss: 0.353\tDev score: 0.924\n",
      "Restoring best model from iteration 0 with score 0.965\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    214     1    \n",
      " l=2    32     753   \n",
      "F1: 0.931\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.5)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[34 Testing {'n_epochs': 5, 'batchnorm': True, 'dropout': 0.5, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.008687963391291976}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.967\n",
      "[E:0]\tTrain Loss: 0.505\tDev score: 0.967\n",
      "Saving model at iteration 1 with best score 0.974\n",
      "[E:4]\tTrain Loss: 0.403\tDev score: 0.929\n",
      "Restoring best model from iteration 1 with score 0.974\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    216     1    \n",
      " l=2    30     753   \n",
      "F1: 0.929\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[35 Testing {'n_epochs': 5, 'batchnorm': True, 'dropout': 0, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.02065427424933474}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.961\n",
      "[E:0]\tTrain Loss: 0.508\tDev score: 0.961\n",
      "[E:4]\tTrain Loss: 0.357\tDev score: 0.913\n",
      "Restoring best model from iteration 0 with score 0.961\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    208     1    \n",
      " l=2    38     753   \n",
      "F1: 0.914\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[36 Testing {'n_epochs': 17, 'batchnorm': False, 'dropout': 0, 'layer_out_dims': [1000, 10, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.006235324635557636}\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model at iteration 0 with best score 0.985\n",
      "[E:0]\tTrain Loss: 0.514\tDev score: 0.985\n",
      "Saving model at iteration 1 with best score 0.999\n",
      "[E:5]\tTrain Loss: 0.423\tDev score: 0.953\n",
      "[E:10]\tTrain Loss: 0.393\tDev score: 0.904\n",
      "[E:15]\tTrain Loss: 0.381\tDev score: 0.892\n",
      "[E:16]\tTrain Loss: 0.379\tDev score: 0.888\n",
      "Restoring best model from iteration 1 with score 0.999\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    246     1    \n",
      " l=2     0     753   \n",
      "F1: 0.998\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.3)\n",
      "  )\n",
      "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[37 Testing {'n_epochs': 17, 'batchnorm': True, 'dropout': 0.3, 'layer_out_dims': [1000, 10, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.001266399031265807}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.987\n",
      "[E:0]\tTrain Loss: 0.573\tDev score: 0.987\n",
      "Saving model at iteration 1 with best score 0.989\n",
      "[E:5]\tTrain Loss: 0.429\tDev score: 0.932\n",
      "[E:10]\tTrain Loss: 0.404\tDev score: 0.913\n",
      "[E:15]\tTrain Loss: 0.390\tDev score: 0.910\n",
      "[E:16]\tTrain Loss: 0.390\tDev score: 0.890\n",
      "Restoring best model from iteration 1 with score 0.989\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    237     3    \n",
      " l=2     9     751   \n",
      "F1: 0.971\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[38 Testing {'n_epochs': 17, 'batchnorm': False, 'dropout': 0.5, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.0012466175605103217}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.983\n",
      "[E:0]\tTrain Loss: 0.524\tDev score: 0.983\n",
      "Saving model at iteration 1 with best score 0.989\n",
      "[E:5]\tTrain Loss: 0.427\tDev score: 0.954\n",
      "[E:10]\tTrain Loss: 0.394\tDev score: 0.935\n",
      "[E:15]\tTrain Loss: 0.365\tDev score: 0.940\n",
      "[E:16]\tTrain Loss: 0.363\tDev score: 0.926\n",
      "Restoring best model from iteration 1 with score 0.989\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    234     0    \n",
      " l=2    12     754   \n",
      "F1: 0.971\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[39 Testing {'n_epochs': 52, 'batchnorm': False, 'dropout': 0, 'layer_out_dims': [1000, 10, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.006235324635557636}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.985\n",
      "[E:0]\tTrain Loss: 0.514\tDev score: 0.985\n",
      "Saving model at iteration 1 with best score 0.999\n",
      "[E:5]\tTrain Loss: 0.423\tDev score: 0.953\n",
      "[E:10]\tTrain Loss: 0.393\tDev score: 0.904\n",
      "[E:15]\tTrain Loss: 0.381\tDev score: 0.892\n",
      "[E:20]\tTrain Loss: 0.370\tDev score: 0.887\n",
      "[E:25]\tTrain Loss: 0.359\tDev score: 0.880\n",
      "[E:30]\tTrain Loss: 0.349\tDev score: 0.876\n",
      "[E:35]\tTrain Loss: 0.341\tDev score: 0.887\n",
      "[E:40]\tTrain Loss: 0.330\tDev score: 0.873\n",
      "[E:45]\tTrain Loss: 0.327\tDev score: 0.873\n",
      "[E:50]\tTrain Loss: 0.324\tDev score: 0.873\n",
      "[E:51]\tTrain Loss: 0.324\tDev score: 0.875\n",
      "Restoring best model from iteration 1 with score 0.999\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    246     1    \n",
      " l=2     0     753   \n",
      "F1: 0.998\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[40 Testing {'n_epochs': 5, 'batchnorm': False, 'dropout': 0.2, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.13006494070302638}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.754\n",
      "[E:0]\tTrain Loss: 0.947\tDev score: 0.754\n",
      "Saving model at iteration 1 with best score 0.764\n",
      "Saving model at iteration 2 with best score 0.825\n",
      "Saving model at iteration 3 with best score 0.892\n",
      "Saving model at iteration 4 with best score 0.898\n",
      "[E:4]\tTrain Loss: 0.531\tDev score: 0.898\n",
      "Restoring best model from iteration 4 with score 0.898\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    153     6    \n",
      " l=2    93     748   \n",
      "F1: 0.756\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[41 Testing {'n_epochs': 5, 'batchnorm': True, 'dropout': 0, 'layer_out_dims': [1000, 10, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 5.00210569411948e-05}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.650\n",
      "[E:0]\tTrain Loss: 0.671\tDev score: 0.650\n",
      "Saving model at iteration 1 with best score 0.722\n",
      "Saving model at iteration 2 with best score 0.791\n",
      "Saving model at iteration 3 with best score 0.844\n",
      "Saving model at iteration 4 with best score 0.880\n",
      "[E:4]\tTrain Loss: 0.626\tDev score: 0.880\n",
      "Restoring best model from iteration 4 with score 0.880\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    218    92    \n",
      " l=2    28     662   \n",
      "F1: 0.784\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.1)\n",
      "  )\n",
      "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[42 Testing {'n_epochs': 5, 'batchnorm': True, 'dropout': 0.1, 'layer_out_dims': [1000, 10, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 5.78054494914214e-05}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.542\n",
      "[E:0]\tTrain Loss: 0.696\tDev score: 0.542\n",
      "Saving model at iteration 1 with best score 0.617\n",
      "Saving model at iteration 2 with best score 0.685\n",
      "Saving model at iteration 3 with best score 0.732\n",
      "Saving model at iteration 4 with best score 0.774\n",
      "[E:4]\tTrain Loss: 0.642\tDev score: 0.774\n",
      "Restoring best model from iteration 4 with score 0.774\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    224    209   \n",
      " l=2    22     545   \n",
      "F1: 0.660\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.2)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[43 Testing {'n_epochs': 5, 'batchnorm': True, 'dropout': 0.2, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.009569584288831269}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.957\n",
      "[E:0]\tTrain Loss: 0.506\tDev score: 0.957\n",
      "[E:4]\tTrain Loss: 0.362\tDev score: 0.904\n",
      "Restoring best model from iteration 0 with score 0.957\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    198     0    \n",
      " l=2    48     754   \n",
      "F1: 0.912\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[44 Testing {'n_epochs': 5, 'batchnorm': False, 'dropout': 0.3, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.0012277056223655815}\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model at iteration 0 with best score 0.990\n",
      "[E:0]\tTrain Loss: 0.524\tDev score: 0.990\n",
      "[E:4]\tTrain Loss: 0.428\tDev score: 0.968\n",
      "Restoring best model from iteration 0 with score 0.990\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    238     0    \n",
      " l=2     8     754   \n",
      "F1: 0.986\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5)\n",
      "  )\n",
      "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[45 Testing {'n_epochs': 5, 'batchnorm': False, 'dropout': 0.5, 'layer_out_dims': [1000, 10, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.00015799041294640756}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.350\n",
      "[E:0]\tTrain Loss: 0.743\tDev score: 0.350\n",
      "Saving model at iteration 1 with best score 0.651\n",
      "Saving model at iteration 2 with best score 0.729\n",
      "Saving model at iteration 3 with best score 0.758\n",
      "Saving model at iteration 4 with best score 0.767\n",
      "[E:4]\tTrain Loss: 0.578\tDev score: 0.767\n",
      "Restoring best model from iteration 4 with score 0.767\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    32     21    \n",
      " l=2    214    733   \n",
      "F1: 0.228\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.3)\n",
      "  )\n",
      "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[46 Testing {'n_epochs': 5, 'batchnorm': True, 'dropout': 0.3, 'layer_out_dims': [1000, 10, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 1.127398333866827e-05}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.592\n",
      "[E:0]\tTrain Loss: 0.717\tDev score: 0.592\n",
      "Saving model at iteration 1 with best score 0.606\n",
      "Saving model at iteration 2 with best score 0.610\n",
      "Saving model at iteration 3 with best score 0.629\n",
      "Saving model at iteration 4 with best score 0.642\n",
      "[E:4]\tTrain Loss: 0.689\tDev score: 0.642\n",
      "Restoring best model from iteration 4 with score 0.642\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    96     209   \n",
      " l=2    150    545   \n",
      "F1: 0.342\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.4)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[47 Testing {'n_epochs': 5, 'batchnorm': True, 'dropout': 0.4, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.0022778368385345613}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.979\n",
      "[E:0]\tTrain Loss: 0.560\tDev score: 0.979\n",
      "[E:4]\tTrain Loss: 0.363\tDev score: 0.926\n",
      "Restoring best model from iteration 0 with score 0.979\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    229     1    \n",
      " l=2    17     753   \n",
      "F1: 0.949\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.4)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[48 Testing {'n_epochs': 5, 'batchnorm': False, 'dropout': 0.4, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.01728641164179744}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.968\n",
      "[E:0]\tTrain Loss: 0.505\tDev score: 0.968\n",
      "Saving model at iteration 1 with best score 0.972\n",
      "[E:4]\tTrain Loss: 0.434\tDev score: 0.966\n",
      "Restoring best model from iteration 1 with score 0.972\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    226     5    \n",
      " l=2    20     749   \n",
      "F1: 0.947\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[49 Testing {'n_epochs': 17, 'batchnorm': False, 'dropout': 0.3, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.0012277056223655815}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.990\n",
      "[E:0]\tTrain Loss: 0.524\tDev score: 0.990\n",
      "[E:5]\tTrain Loss: 0.420\tDev score: 0.956\n",
      "[E:10]\tTrain Loss: 0.368\tDev score: 0.925\n",
      "[E:15]\tTrain Loss: 0.339\tDev score: 0.941\n",
      "[E:16]\tTrain Loss: 0.336\tDev score: 0.944\n",
      "Restoring best model from iteration 0 with score 0.990\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    238     0    \n",
      " l=2     8     754   \n",
      "F1: 0.986\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.4)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[50 Testing {'n_epochs': 17, 'batchnorm': True, 'dropout': 0.4, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.0022778368385345613}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.979\n",
      "[E:0]\tTrain Loss: 0.560\tDev score: 0.979\n",
      "[E:5]\tTrain Loss: 0.352\tDev score: 0.925\n",
      "[E:10]\tTrain Loss: 0.333\tDev score: 0.927\n",
      "[E:15]\tTrain Loss: 0.326\tDev score: 0.924\n",
      "[E:16]\tTrain Loss: 0.324\tDev score: 0.938\n",
      "Restoring best model from iteration 0 with score 0.979\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    227     2    \n",
      " l=2    19     752   \n",
      "F1: 0.964\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.4)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[51 Testing {'n_epochs': 17, 'batchnorm': False, 'dropout': 0.4, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.01728641164179744}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.968\n",
      "[E:0]\tTrain Loss: 0.505\tDev score: 0.968\n",
      "Saving model at iteration 1 with best score 0.972\n",
      "[E:5]\tTrain Loss: 0.426\tDev score: 0.962\n",
      "[E:10]\tTrain Loss: 0.398\tDev score: 0.945\n",
      "[E:15]\tTrain Loss: 0.378\tDev score: 0.936\n",
      "[E:16]\tTrain Loss: 0.373\tDev score: 0.931\n",
      "Restoring best model from iteration 1 with score 0.972\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    226     5    \n",
      " l=2    20     749   \n",
      "F1: 0.943\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[52 Testing {'n_epochs': 52, 'batchnorm': False, 'dropout': 0.3, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.0012277056223655815}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.990\n",
      "[E:0]\tTrain Loss: 0.524\tDev score: 0.990\n",
      "[E:5]\tTrain Loss: 0.420\tDev score: 0.956\n",
      "[E:10]\tTrain Loss: 0.368\tDev score: 0.925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E:15]\tTrain Loss: 0.339\tDev score: 0.941\n",
      "[E:20]\tTrain Loss: 0.329\tDev score: 0.939\n",
      "[E:25]\tTrain Loss: 0.324\tDev score: 0.925\n",
      "[E:30]\tTrain Loss: 0.321\tDev score: 0.931\n",
      "[E:35]\tTrain Loss: 0.316\tDev score: 0.934\n",
      "[E:40]\tTrain Loss: 0.315\tDev score: 0.934\n",
      "[E:45]\tTrain Loss: 0.314\tDev score: 0.930\n",
      "[E:50]\tTrain Loss: 0.313\tDev score: 0.933\n",
      "[E:51]\tTrain Loss: 0.313\tDev score: 0.930\n",
      "Restoring best model from iteration 0 with score 0.990\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    240     0    \n",
      " l=2     6     754   \n",
      "F1: 0.986\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[53 Testing {'n_epochs': 17, 'batchnorm': False, 'dropout': 0, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.0010313792236254435}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.969\n",
      "[E:0]\tTrain Loss: 0.539\tDev score: 0.969\n",
      "Saving model at iteration 1 with best score 0.992\n",
      "[E:5]\tTrain Loss: 0.420\tDev score: 0.966\n",
      "[E:10]\tTrain Loss: 0.363\tDev score: 0.941\n",
      "[E:15]\tTrain Loss: 0.322\tDev score: 0.934\n",
      "[E:16]\tTrain Loss: 0.317\tDev score: 0.927\n",
      "Restoring best model from iteration 1 with score 0.992\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    239     1    \n",
      " l=2     7     753   \n",
      "F1: 0.984\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.2)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[54 Testing {'n_epochs': 17, 'batchnorm': True, 'dropout': 0.2, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.01737363125045847}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.928\n",
      "[E:0]\tTrain Loss: 0.495\tDev score: 0.928\n",
      "Saving model at iteration 2 with best score 0.932\n",
      "[E:5]\tTrain Loss: 0.365\tDev score: 0.930\n",
      "[E:10]\tTrain Loss: 0.338\tDev score: 0.877\n",
      "[E:15]\tTrain Loss: 0.327\tDev score: 0.909\n",
      "[E:16]\tTrain Loss: 0.325\tDev score: 0.900\n",
      "Restoring best model from iteration 2 with score 0.932\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    188     6    \n",
      " l=2    58     748   \n",
      "F1: 0.831\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.4)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[55 Testing {'n_epochs': 17, 'batchnorm': False, 'dropout': 0.4, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.0001041930378079509}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.757\n",
      "[E:0]\tTrain Loss: 0.651\tDev score: 0.757\n",
      "Saving model at iteration 3 with best score 0.772\n",
      "Saving model at iteration 4 with best score 0.832\n",
      "Saving model at iteration 5 with best score 0.904\n",
      "[E:5]\tTrain Loss: 0.478\tDev score: 0.904\n",
      "Saving model at iteration 6 with best score 0.951\n",
      "Saving model at iteration 7 with best score 0.964\n",
      "Saving model at iteration 8 with best score 0.977\n",
      "Saving model at iteration 10 with best score 0.979\n",
      "[E:10]\tTrain Loss: 0.454\tDev score: 0.979\n",
      "Saving model at iteration 14 with best score 0.982\n",
      "[E:15]\tTrain Loss: 0.448\tDev score: 0.980\n",
      "[E:16]\tTrain Loss: 0.448\tDev score: 0.976\n",
      "Restoring best model from iteration 14 with score 0.982\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    222     1    \n",
      " l=2    24     753   \n",
      "F1: 0.953\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5)\n",
      "  )\n",
      "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[56 Testing {'n_epochs': 17, 'batchnorm': False, 'dropout': 0.5, 'layer_out_dims': [1000, 10, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.026427964397103633}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.865\n",
      "[E:0]\tTrain Loss: 0.505\tDev score: 0.865\n",
      "[E:5]\tTrain Loss: 0.463\tDev score: 0.851\n",
      "[E:10]\tTrain Loss: 0.460\tDev score: 0.849\n",
      "[E:15]\tTrain Loss: 0.454\tDev score: 0.839\n",
      "[E:16]\tTrain Loss: 0.457\tDev score: 0.820\n",
      "Restoring best model from iteration 0 with score 0.865\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    131     1    \n",
      " l=2    115    753   \n",
      "F1: 0.695\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.4)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[57 Testing {'n_epochs': 17, 'batchnorm': False, 'dropout': 0.4, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.010117513700062997}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.962\n",
      "[E:0]\tTrain Loss: 0.493\tDev score: 0.962\n",
      "[E:5]\tTrain Loss: 0.402\tDev score: 0.897\n",
      "[E:10]\tTrain Loss: 0.379\tDev score: 0.905\n",
      "[E:15]\tTrain Loss: 0.365\tDev score: 0.904\n",
      "[E:16]\tTrain Loss: 0.365\tDev score: 0.896\n",
      "Restoring best model from iteration 0 with score 0.962\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    192     0    \n",
      " l=2    54     754   \n",
      "F1: 0.902\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2)\n",
      "  )\n",
      "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[58 Testing {'n_epochs': 17, 'batchnorm': False, 'dropout': 0.2, 'layer_out_dims': [1000, 10, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 1.1402467595826461e-05}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.754\n",
      "[E:0]\tTrain Loss: 0.632\tDev score: 0.754\n",
      "[E:5]\tTrain Loss: 0.620\tDev score: 0.754\n",
      "[E:10]\tTrain Loss: 0.607\tDev score: 0.754\n",
      "[E:15]\tTrain Loss: 0.594\tDev score: 0.754\n",
      "[E:16]\tTrain Loss: 0.592\tDev score: 0.754\n",
      "Restoring best model from iteration 0 with score 0.754\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1     0      0    \n",
      " l=2    246    754   \n",
      "F1: 0.000\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[59 Testing {'n_epochs': 52, 'batchnorm': False, 'dropout': 0, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.0010313792236254435}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.969\n",
      "[E:0]\tTrain Loss: 0.539\tDev score: 0.969\n",
      "Saving model at iteration 1 with best score 0.992\n",
      "[E:5]\tTrain Loss: 0.420\tDev score: 0.966\n",
      "[E:10]\tTrain Loss: 0.363\tDev score: 0.941\n",
      "[E:15]\tTrain Loss: 0.322\tDev score: 0.934\n",
      "[E:20]\tTrain Loss: 0.307\tDev score: 0.928\n",
      "[E:25]\tTrain Loss: 0.304\tDev score: 0.920\n",
      "[E:30]\tTrain Loss: 0.302\tDev score: 0.926\n",
      "[E:35]\tTrain Loss: 0.301\tDev score: 0.920\n",
      "[E:40]\tTrain Loss: 0.298\tDev score: 0.920\n",
      "[E:45]\tTrain Loss: 0.297\tDev score: 0.918\n",
      "[E:50]\tTrain Loss: 0.297\tDev score: 0.919\n",
      "[E:51]\tTrain Loss: 0.297\tDev score: 0.919\n",
      "Restoring best model from iteration 1 with score 0.992\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    239     1    \n",
      " l=2     7     753   \n",
      "F1: 0.984\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.4)\n",
      "  )\n",
      "  (2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[60 Testing {'n_epochs': 52, 'batchnorm': False, 'dropout': 0.4, 'layer_out_dims': [1000, 100, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.0001041930378079509}\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model at iteration 0 with best score 0.757\n",
      "[E:0]\tTrain Loss: 0.651\tDev score: 0.757\n",
      "Saving model at iteration 3 with best score 0.772\n",
      "Saving model at iteration 4 with best score 0.832\n",
      "Saving model at iteration 5 with best score 0.904\n",
      "[E:5]\tTrain Loss: 0.478\tDev score: 0.904\n",
      "Saving model at iteration 6 with best score 0.951\n",
      "Saving model at iteration 7 with best score 0.964\n",
      "Saving model at iteration 8 with best score 0.977\n",
      "Saving model at iteration 10 with best score 0.979\n",
      "[E:10]\tTrain Loss: 0.454\tDev score: 0.979\n",
      "Saving model at iteration 14 with best score 0.982\n",
      "[E:15]\tTrain Loss: 0.448\tDev score: 0.980\n",
      "[E:20]\tTrain Loss: 0.443\tDev score: 0.974\n",
      "[E:25]\tTrain Loss: 0.439\tDev score: 0.977\n",
      "[E:30]\tTrain Loss: 0.434\tDev score: 0.971\n",
      "[E:35]\tTrain Loss: 0.430\tDev score: 0.963\n",
      "[E:40]\tTrain Loss: 0.426\tDev score: 0.963\n",
      "[E:45]\tTrain Loss: 0.424\tDev score: 0.952\n",
      "[E:50]\tTrain Loss: 0.420\tDev score: 0.960\n",
      "[E:51]\tTrain Loss: 0.420\tDev score: 0.957\n",
      "Restoring best model from iteration 14 with score 0.982\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    224     0    \n",
      " l=2    22     754   \n",
      "F1: 0.953\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[61 Testing {'n_epochs': 53, 'batchnorm': False, 'dropout': 0, 'layer_out_dims': [1000, 10, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.021847019520478485}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.967\n",
      "[E:0]\tTrain Loss: 0.485\tDev score: 0.967\n",
      "Saving model at iteration 1 with best score 0.985\n",
      "[E:5]\tTrain Loss: 0.397\tDev score: 0.906\n",
      "[E:10]\tTrain Loss: 0.376\tDev score: 0.904\n",
      "[E:15]\tTrain Loss: 0.357\tDev score: 0.889\n",
      "[E:20]\tTrain Loss: 0.346\tDev score: 0.875\n",
      "[E:25]\tTrain Loss: 0.335\tDev score: 0.878\n",
      "[E:30]\tTrain Loss: 0.321\tDev score: 0.893\n",
      "[E:35]\tTrain Loss: 0.318\tDev score: 0.890\n",
      "[E:40]\tTrain Loss: 0.315\tDev score: 0.889\n",
      "[E:45]\tTrain Loss: 0.314\tDev score: 0.886\n",
      "[E:50]\tTrain Loss: 0.313\tDev score: 0.886\n",
      "[E:52]\tTrain Loss: 0.313\tDev score: 0.886\n",
      "Restoring best model from iteration 1 with score 0.985\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    234     3    \n",
      " l=2    12     751   \n",
      "F1: 0.969\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.1)\n",
      "  )\n",
      "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[62 Testing {'n_epochs': 53, 'batchnorm': False, 'dropout': 0.1, 'layer_out_dims': [1000, 10, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.0001489729360963513}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.246\n",
      "[E:0]\tTrain Loss: 0.770\tDev score: 0.246\n",
      "Saving model at iteration 1 with best score 0.427\n",
      "Saving model at iteration 2 with best score 0.754\n",
      "Saving model at iteration 3 with best score 0.771\n",
      "[E:5]\tTrain Loss: 0.593\tDev score: 0.766\n",
      "Saving model at iteration 7 with best score 0.774\n",
      "Saving model at iteration 8 with best score 0.791\n",
      "Saving model at iteration 9 with best score 0.802\n",
      "Saving model at iteration 10 with best score 0.841\n",
      "[E:10]\tTrain Loss: 0.513\tDev score: 0.841\n",
      "Saving model at iteration 11 with best score 0.904\n",
      "Saving model at iteration 12 with best score 0.929\n",
      "Saving model at iteration 13 with best score 0.939\n",
      "Saving model at iteration 14 with best score 0.949\n",
      "[E:15]\tTrain Loss: 0.475\tDev score: 0.945\n",
      "Saving model at iteration 16 with best score 0.953\n",
      "Saving model at iteration 17 with best score 0.954\n",
      "Saving model at iteration 18 with best score 0.958\n",
      "Saving model at iteration 19 with best score 0.966\n",
      "[E:20]\tTrain Loss: 0.464\tDev score: 0.954\n",
      "Saving model at iteration 24 with best score 0.975\n",
      "[E:25]\tTrain Loss: 0.460\tDev score: 0.964\n",
      "[E:30]\tTrain Loss: 0.457\tDev score: 0.970\n",
      "[E:35]\tTrain Loss: 0.455\tDev score: 0.969\n",
      "[E:40]\tTrain Loss: 0.453\tDev score: 0.967\n",
      "[E:45]\tTrain Loss: 0.451\tDev score: 0.967\n",
      "[E:50]\tTrain Loss: 0.449\tDev score: 0.958\n",
      "[E:52]\tTrain Loss: 0.450\tDev score: 0.967\n",
      "Restoring best model from iteration 24 with score 0.975\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    217     1    \n",
      " l=2    29     753   \n",
      "F1: 0.933\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.4)\n",
      "  )\n",
      "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[63 Testing {'n_epochs': 53, 'batchnorm': False, 'dropout': 0.4, 'layer_out_dims': [1000, 10, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.00023246249897636526}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.716\n",
      "[E:0]\tTrain Loss: 0.708\tDev score: 0.716\n",
      "Saving model at iteration 1 with best score 0.767\n",
      "Saving model at iteration 3 with best score 0.783\n",
      "Saving model at iteration 4 with best score 0.837\n",
      "Saving model at iteration 5 with best score 0.892\n",
      "[E:5]\tTrain Loss: 0.505\tDev score: 0.892\n",
      "Saving model at iteration 6 with best score 0.917\n",
      "Saving model at iteration 7 with best score 0.933\n",
      "Saving model at iteration 8 with best score 0.947\n",
      "Saving model at iteration 9 with best score 0.956\n",
      "Saving model at iteration 10 with best score 0.968\n",
      "[E:10]\tTrain Loss: 0.476\tDev score: 0.968\n",
      "Saving model at iteration 12 with best score 0.976\n",
      "[E:15]\tTrain Loss: 0.471\tDev score: 0.968\n",
      "Saving model at iteration 18 with best score 0.977\n",
      "[E:20]\tTrain Loss: 0.468\tDev score: 0.976\n",
      "Saving model at iteration 25 with best score 0.982\n",
      "[E:25]\tTrain Loss: 0.467\tDev score: 0.982\n",
      "[E:30]\tTrain Loss: 0.465\tDev score: 0.974\n",
      "[E:35]\tTrain Loss: 0.464\tDev score: 0.970\n",
      "[E:40]\tTrain Loss: 0.463\tDev score: 0.962\n",
      "[E:45]\tTrain Loss: 0.457\tDev score: 0.969\n",
      "[E:50]\tTrain Loss: 0.459\tDev score: 0.971\n",
      "[E:52]\tTrain Loss: 0.459\tDev score: 0.971\n",
      "Restoring best model from iteration 25 with score 0.982\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1    223     2    \n",
      " l=2    23     752   \n",
      "F1: 0.934\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3)\n",
      "  )\n",
      "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "[64 Testing {'n_epochs': 53, 'batchnorm': False, 'dropout': 0.3, 'layer_out_dims': [1000, 10, 2], 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.9878179960337325}\n",
      "============================================================\n",
      "Saving model at iteration 0 with best score 0.754\n",
      "[E:0]\tTrain Loss: 3.829\tDev score: 0.754\n",
      "[E:5]\tTrain Loss: 0.576\tDev score: 0.754\n",
      "[E:10]\tTrain Loss: 0.577\tDev score: 0.754\n",
      "[E:15]\tTrain Loss: 0.577\tDev score: 0.754\n",
      "[E:20]\tTrain Loss: 0.576\tDev score: 0.754\n",
      "[E:25]\tTrain Loss: 0.577\tDev score: 0.754\n",
      "[E:30]\tTrain Loss: 0.575\tDev score: 0.754\n",
      "[E:35]\tTrain Loss: 0.576\tDev score: 0.754\n",
      "[E:40]\tTrain Loss: 0.575\tDev score: 0.754\n",
      "[E:45]\tTrain Loss: 0.575\tDev score: 0.754\n",
      "[E:50]\tTrain Loss: 0.575\tDev score: 0.754\n",
      "[E:52]\tTrain Loss: 0.575\tDev score: 0.754\n",
      "Restoring best model from iteration 0 with score 0.754\n",
      "Finished Training\n",
      "Confusion Matrix (Dev)\n",
      "        y=1    y=2   \n",
      " l=1     0      0    \n",
      " l=2    246    754   \n",
      "F1: 0.000\n",
      "============================================================\n",
      "[SUMMARY]\n",
      "Best model: [28]\n",
      "Best config: {'n_epochs': 52, 'batchnorm': False, 'dropout': 0, 'layer_out_dims': [1000, 10, 2], 'print_every': 5, 'data_loader_config': {'batch_size': 256, 'num_workers': 1}, 'lr': 0.006235324635557636, 'seed': 132}\n",
      "Best score: 0.9979716024340771\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "best_rs_model_harder = rs_tuner_harder.search(search_space, X_dev, Y_dev, train_args=train_args, max_search=20, metric='f1', verbose=True)\n",
    "best_hb_model_harder =  hb_tuner_harder.search(search_space, X_dev, Y_dev, train_args=train_args, metric='f1', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And extract and plot our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hb_stats_harder = hb_tuner_harder.get_run_stats()\n",
    "rs_stats_harder = rs_tuner_harder.get_run_stats()\n",
    "plot_score_vs_time(rs_stats_harder, hb_stats_harder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! Generally it seems Hyperband is better in regimes with a large search space and a long search time (which is the typical scenario). \n",
    "\n",
    "This seems to make intuitive sense: \n",
    "- with a larger search space Hyperband's resource allocation becomes more useful in culling bad configuration\n",
    "- with a longer search time Hyperband is able to start with a larger pool of configurations, enabling a better balance of exploration / exploitation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that wraps up the hyperparameter tuning tutorial! We hope that MeTaL's hyperparameter tuners are useful for your applications and make hyperparameter tuning enjoyable. Happy tuning!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
